{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbf1aba-f0c4-460e-810f-9574624ccd48",
   "metadata": {},
   "source": [
    "# DSAN5650 Homework 4: \"Cross-Prediction\" of Attitudes and Behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03292b-a552-4c23-9f48-05f58b154f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:14:28.619885Z",
     "iopub.status.busy": "2025-08-01T08:14:28.619575Z",
     "iopub.status.idle": "2025-08-01T08:14:28.751021Z",
     "shell.execute_reply": "2025-08-01T08:14:28.750616Z",
     "shell.execute_reply.started": "2025-08-01T08:14:28.619865Z"
    }
   },
   "outputs": [],
   "source": [
    "import corrections\n",
    "corrections.fetch(\"HW4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f10e6-809d-4ba4-9b2e-02a974c598c0",
   "metadata": {},
   "source": [
    "# [Part 2] Modeling *Behaviors* with Experimental Audit Data\n",
    "\n",
    "In this part, we'll start to see the issue with conflating attitudes and behavior (so, in other words, the dangers that can arise from assuming that **survey responses** can be used as a \"mirror\" for real-world **behavior**), which will motivate the move in Part 3 below to *merge* the survey and experimental-audit data and analyze this discrepancy itself.\n",
    "\n",
    "But, don't worry! This part won't involve another 7 tedious steps of doing the same thing you did in Part 1! Instead, we'll use it as an opportunity to explore a package called [**Bambi**](https://bambinos.github.io/bambi/), which is essentially a wrapper around more in-the-weeds Bayesian model-building tools like PyMC.\n",
    "\n",
    "> *The **social contract** here, though, is that you promise to **keep your Bayesian modeling skills sharp**, the skills you've built in HW2 and in Part 1 above!*\n",
    ">\n",
    "> *I say that here because, using Bambi essentially takes us *away from* the PyMC modeling approach---the **\"learning a modeling *language*\"** approach---and back towards just choosing from a collection of pre-made, \"off-the-shelf\" algorithms: the approach of using `lm()` or `statsmodels` for example.*\n",
    "\n",
    "So yeah, in general I want you to avoid seeing `lm()` or `statsmodels` as \"default\" approaches, and instead see them as tools you can take advantage of **after** you've gone through the modeling steps and determined that the assumptions underlying e.g. logistic regression are appropriate for your scenario. *But*, since you just trooped through the non-off-the-shelf \"hard mode\" approach in Part 1, and \"arrived at\" the use of logistic regression in Part 1.5, in this part we'll basically just skip those hard parts and ask Bambi to run a Bayesian logistic regression for us (with PyMC still running \"under the hood\"!)\n",
    "\n",
    "Since this part is similar to Part 1---it's the same analysis, just using the **experimental audit** data with the `dohire` variable rather than the survey data with the `sayhire` dependent variable---there will be less wordy instructions here. So, if you get stuck, you can look back at the equivalent portion of Part 1 for more details!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ddece-57e6-4eaa-802c-def61af76881",
   "metadata": {},
   "source": [
    "**Python Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bb42986f-ce2d-4fe6-8337-7ff69a989b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T04:13:17.149621Z",
     "iopub.status.busy": "2025-08-01T04:13:17.149330Z",
     "iopub.status.idle": "2025-08-01T04:13:17.158220Z",
     "shell.execute_reply": "2025-08-01T04:13:17.157729Z",
     "shell.execute_reply.started": "2025-08-01T04:13:17.149604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap');\n",
       ".jp-RenderedHTMLCommon {\n",
       "    font-family: \"Roboto\", sans-serif;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run jupyter_fixes.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import patchworklib as pw\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d61c1b-c8dd-496d-8d22-167f3f5f5811",
   "metadata": {},
   "source": [
    "**Loading the Data**\n",
    "\n",
    "The following code cell loads the **experimental-audit-level** dataset, `pager_matched_experiments.csv`, where the auditor in each row is uniquely identified by `audit_id`. For each auditor, we have the following information:\n",
    "\n",
    "* `firm_id`: The firm (from the previous dataset) whose application process the auditor went through\n",
    "* `con`: Has the value `0` if the auditor did **not** list/mention a prior criminal conviction in their application, and `1` if the auditor **did** list such a prior conviction\n",
    "* `race_str`: A string variable which is `\"White\"` for the recruited self-reported white auditors and `\"Black\"` for the recruited self-reported black auditors\n",
    "* `race` Same as `race_str`, but with **`\"White\"`** mapped to the int value **`0`** and **`\"Black\"`** mapped to the int value **`1`**\n",
    "* `sayhire`: Has the value **`1`** if the firm said they would \"likely\" hire an applicant (Chad from the survey vignettes) with the same race and conviction-status as the auditor\n",
    "* `dohire`: Has the value **`1`** if the auditor ended up getting a callback from the firm, and **`0`** otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b07378-7bb6-4151-86a2-6132b9c2b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv(\"pager_matched_experiments.csv\")\n",
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf02b86-fee3-4f5b-8274-0844d86347cc",
   "metadata": {},
   "source": [
    "**Computing and Visualizing Summary Statistics**\n",
    "\n",
    "To see how the dynamics of **behavior** in this part are drastically different from the dynamics of **attitudes** you estimated in Part 1, the following code cells generate numeric and visual summaries of the experimental audit results (the plot here is the same as the plot from the beginning of HW3A).\n",
    "\n",
    "First, as a nice built-in Pandas function you can use to quickly generate summary statistics, the following cell uses `pd.crosstab()` with the additional `values=` and `aggfunc=` arguments to generate a **two-way cross-tabulation** of the `dohire` rates by race (since `dohire` is a `0`/`1` binary variable, computing the `mean` of this column gives us the proportion of rows containing `1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a624386-5505-4fe8-9e15-0b4a3ec6665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(exp_df['race_str'], exp_df['con'], values=exp_df['dohire'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab6d4c-aa3c-4115-8aed-13f9f2f96b7a",
   "metadata": {},
   "source": [
    "As you may already know if you've taken DSAN5200 for example, the `seaborn` library works better with \"long\" data than with the 2x2 structure produced by `pd.crosstab()`. So,  to plot this information more easily, the following code cell generates a 4-row dataset of rates, one row per possible `race_str` x `con` combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c240a1-1509-4f4b-80a6-6b8e185ffa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rate_df = exp_df.groupby(['race_str','con'])['dohire'].mean().to_frame().reset_index()\n",
    "exp_rate_df.rename(columns={'dohire': 'dohire_rate'}, inplace=True)\n",
    "exp_rate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fd885-84c3-4ae9-9019-5d96f6d37a8b",
   "metadata": {},
   "source": [
    "Which we can now just plug into Seaborn to produce the plot you saw at the beginning of HW3A!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a648995-411b-425f-8920-5d605db47fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pw.Brick(figsize=(3.5, 2.25));\n",
    "sns.barplot(\n",
    "    x=\"race_str\", y='dohire_rate', hue='con', data=exp_rate_df,\n",
    "    alpha=0.85, order=['White','Black'], ax=ax\n",
    ");\n",
    "ax.set_title(\"Experimental Audit Callback Rates\")\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f273a0-3f59-4225-b0bd-ae5713c50d0f",
   "metadata": {},
   "source": [
    "**The Train-Test Split We'll Use Throughout HW3B**\n",
    "\n",
    "The following code cell uses `scikit-learn`'s `train_test_split()` function, as in HW3A, with `random_state=5650` included to ensure comparability of your implementations with our solutions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4a775-4328-4789-a1bf-dd958a94105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(exp_df, test_size=0.2, random_state=5650)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e715c2ad-43d9-49e0-ad09-451443dceb0f",
   "metadata": {},
   "source": [
    "And finally, we'll create an `OrderedDict` object like we did in HW3A, for collecting the test AUC values which we'll compare at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3badbce-ef24-43ef-bf05-14611d32f963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T02:17:41.007054Z",
     "iopub.status.busy": "2025-08-01T02:17:41.006813Z",
     "iopub.status.idle": "2025-08-01T02:17:41.010009Z",
     "shell.execute_reply": "2025-08-01T02:17:41.009523Z",
     "shell.execute_reply.started": "2025-08-01T02:17:41.007037Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "exp_model_aucs = OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb41a0-9aa2-41fe-88df-b3919c6cb37d",
   "metadata": {},
   "source": [
    "## [Part 2.0] Baseline Model: Intercept Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e7c6-725a-4ff8-a06f-aa49f518da6c",
   "metadata": {},
   "source": [
    "As your first Bambi model (and as the first model you should construct in pretty much **any** ML setting!), let's construct the **baseline model** the same way we did in HW3: a model that just \"learns\" the overall mean of `dohire`, and always guesses that mean value as the probability of being hired, regardless of the applicant's characteristics.\n",
    "\n",
    "**Writing the Model in R's Formula Notation**\n",
    "\n",
    "The weird-ish way to do this with Bambi becomes less weird if you keep in mind how **R's formula syntax** (which is also used by Bambi) works. If you ask `glm()` in R to estimate a logistic regression model using a formula like:\n",
    "\n",
    "``` {.r}\n",
    "glm(\"y ~ x1 + x2 + x3\", data = my_df, family = \"binomial\")\n",
    "```\n",
    "\n",
    "R will interpret this as you asking it to estimate the $\\beta$ coefficients of the following regression model:\n",
    "\n",
    "$$\n",
    "\\log\\left[ \\frac{\\Pr(Y = 1)}{1 - \\Pr(Y = 1)} \\right] = \\beta_0 \\cdot 1 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3\n",
    "$$\n",
    "\n",
    "Where $\\beta_0$ is just multiplied by 1 since we want R to estimate this as the **intercept** for the model.\n",
    "\n",
    "So, if we want a model that **just** learns a single parameter, and uses that parameter value to generate the same guess for every observation regardless of characteristics... we want the above formula but without the `x1`, `x2`, and `x3` terms!\n",
    "\n",
    "That's super close to the answer, but, R doesn't actually accept a formula like `\"y ~ \"`, with nothing on the right-hand side, as valid syntax. So what do we do? We look at the above formula, and notice how the intercept we want to estimate is the **coefficient that is just multiplied by 1**. And, the missing piece in `\"y ~ \"` that would make it valid syntax is exactly this `1`. So, to modify the above R code to only estimate an intercept, we'd change it to:\n",
    "\n",
    "``` {.r}\n",
    "glm(\"y ~ 1\", data = my_df, family = \"binomial\")\n",
    "```\n",
    "\n",
    "So, run the code cells in this section the see estimation with Bambi in action (you'll implement your own Bambi models starting in Part 2.3), and notice how:\n",
    "\n",
    "* (a) Bambi uses the **same formula syntax as R**, but\n",
    "* (b) Bambi uses `family=\"bernoulli\"` in place of R's `family=\"binomial\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d4be09e-77f8-4cf9-b2f3-301629fe697a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T02:42:33.968780Z",
     "iopub.status.busy": "2025-08-01T02:42:33.968538Z",
     "iopub.status.idle": "2025-08-01T02:42:33.976001Z",
     "shell.execute_reply": "2025-08-01T02:42:33.975494Z",
     "shell.execute_reply.started": "2025-08-01T02:42:33.968763Z"
    }
   },
   "outputs": [],
   "source": [
    "import bambi as bmb\n",
    "nofeats_model = bmb.Model('dohire ~ 1', data=train_df, family='bernoulli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87473c-acf0-48a3-b8d2-18eae2bf4ad5",
   "metadata": {},
   "source": [
    "Everything from this point onwards will start to feel more like PyMC! Which makes sense since Bambi is mainly intended as a \"wrapper\" around estimation libraries like PyMC which eases the pain of having to manually choose prior distributions.\n",
    "\n",
    "For example, the following two steps serve as Bambi's equivalent to PyMC's `pm.model_to_graphviz()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1a2c8-283e-4e83-93b7-c93e9f654981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step doesn't really have an equivalent in PyMC, since, it's Bambi's\n",
    "# signal to *pair* the variables you specified in the previous code cell with\n",
    "# appropriate *prior* distributions:\n",
    "nofeats_model.build()\n",
    "\n",
    "# Once the model has been built, however, the following becomes Bambi's direct\n",
    "# equivalent of PyMC's pm.model_to_graphviz():\n",
    "nofeats_model.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4425e6b-e7a8-4685-ba59-24d19d20b541",
   "metadata": {},
   "source": [
    "**Posterior Estimation**\n",
    "\n",
    "The next cell produces the same **result** as the posterior-estimation step in PyMC (the step where you call `pm.Sample()`). But, notice how:\n",
    "\n",
    "* (a) We use `.fit()` rather than `.sample()` (since Bambi also \"shifts\" the syntax more towards `scikit-learn`'s `fit()`-`transform()` setup), and\n",
    "* (b) We no longer need to use PyMC's indented `with my_model:` syntax!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b094a64-6c39-4e8e-b4b1-0353f39b2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_idata = nofeats_model.fit(random_seed=5650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa98818-e6ae-4c01-b57f-eec3c79a68de",
   "metadata": {},
   "source": [
    "If the call to `fit()` ran successfully (which it should!), `nofeats_idata` will now have a `.posterior` attribute you can use to access the $N = 4000$ samples of `Intercept` values from the posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e2b17-2a27-4c0c-8a87-2d7a9515d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_idata.posterior['Intercept']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8501788-50d3-4fe0-aad4-9d876a9b4453",
   "metadata": {},
   "source": [
    "And, like you've done with PyMC before, if we want a **point estimate** for the Intercept we can use `.mean(dim=['chain','draw'])` to compute the average value of this parameter over all $N = 4000$ samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe32f6-b145-48e8-a5fc-b6302382b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_mean = float(nofeats_idata.posterior['Intercept'].mean(dim=['chain','draw']))\n",
    "intercept_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253921a-c088-472d-96e3-54fb2621cb78",
   "metadata": {},
   "source": [
    "Keep in mind once again that this coefficient value **isn't a probability on its own**, but a \"log-odds\" value. The model we're estimating here is:\n",
    "\n",
    "$$\n",
    "\\log\\left[ \\frac{\\Pr(Y = 1)}{1 - \\Pr(Y = 1)} \\right] = \\alpha\n",
    "$$\n",
    "\n",
    "Meaning that we need to apply our friend the `expit()` function to transform this point estimate of the intercept into a human-interpretable probability value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8610ee6-fa20-424e-9796-75d941d3c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "expit(intercept_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6788cf1-184c-4b06-9fc1-4fd1183501ec",
   "metadata": {},
   "source": [
    "Which is very close to the actual observed **mean** value for `dohire` (the \"empirical\" $\\Pr(Y = 1)$ value), just pulled slightly down towards **0** because of the **prior** that Bambi automatically places on the Intercept coefficient in a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc72c6-4288-4c7a-9e59-ab196435b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df['dohire'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5638bb-1233-4f2e-a669-e5e4583b5f55",
   "metadata": {},
   "source": [
    "*(If you're interested in what specific priors Bambi is choosing, you can use the following syntax to check. For somewhat weird reasons, it uses a standard-normal $\\mathcal{N}(\\mu = 0, \\sigma = 1)$ prior for all of the $\\beta$ coefficients **except for** the intercept, which instead will have a $\\mathcal{N}(\\mu = 0, \\sigma = 1.5)$ prior by default)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfffe37-3823-43ec-9496-8e9650a63696",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_model.components['p'].terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0642d-96ba-4f85-969d-da9c9033e7c9",
   "metadata": {},
   "source": [
    "**Posterior-Predictive Estimation**\n",
    "\n",
    "The syntax in Bambi that replaces PyMC's `pm.sample_posterior_predictive()` also takes a step towards mirroring `scikit-learn`, by replacing that function with just `.predict()`\n",
    "\n",
    "...However, in a setup that I personally find very confusing, calling `.predict()` on its own does not produce **any** visual indication that anything has happened! Things are happening \"under the hood\", though, don't worry -- to see what `.predict()` does, let's first look at what attributes are stored in `nofeats_idata` right now, *before* we call `.predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf187e2f-5bd7-44a7-bdf3-2874206e537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_idata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8d3a8-a0df-4af6-9bad-5a17e6ca8e30",
   "metadata": {},
   "source": [
    "You should see that the only **distribution** currently stored is the **posterior** distribution (`sample_stats` just contains information relevant for debugging the Markov Chain Monte Carlo run which produced this distribution, and `observed_data` just \"carries along\" the `train_df` data we provided to `bmb.Model()` above). This is the distribution that was generated via our call to `.fit()` above.\n",
    "\n",
    "So, now let's run `.predict()`, where we'll jump right to **predictive performance on the *test* dataset** by including `data=test_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37823611-11e7-42bb-bdc6-4cb3db5caa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_model.predict(nofeats_idata, data=test_df, kind='response')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5446f-d689-4cf5-b60c-22afd639043a",
   "metadata": {},
   "source": [
    "Notice how nothing happened, as expected! However, if it ran without any errors, `nofeats_idata` will now **also** have a `posterior_predictive` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55bad49-6239-4f9f-ac12-b0c5838487c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_idata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756c157-164f-4fc9-95cd-400404315479",
   "metadata": {},
   "source": [
    "Which we can now use to compute **mean** values for `dohire` for each test observation, like we did in HW3A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519b2af-c61a-44ae-8547-6beda79af858",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeats_test_dohiremeans = nofeats_idata.posterior_predictive['dohire'].mean(dim=['chain','draw'])\n",
    "nofeats_test_dohiremeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567868c1-e49f-4096-8263-49d97683ba0e",
   "metadata": {},
   "source": [
    "And we can wrap up the baseline model by plotting the test ROC curve and storing the resulting AUC score in `exp_model_aucs`, for comparison at the end! (Note: this is the exact same `plot_roc()` function from HW3A, which you should use so the autograder can autograde pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79b1fe-2335-43f3-bceb-c35a8bc65c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc, roc_curve\n",
    "def plot_roc(true_labels, pred_p_hire, plot_title=\"ROC Curve\"):\n",
    "    ax = pw.Brick(figsize=(3, 3))\n",
    "    model_fpr, model_tpr, model_thresholds = roc_curve(\n",
    "        y_true=true_labels, y_score=pred_p_hire, pos_label=1, drop_intermediate=True\n",
    "    )\n",
    "    model_auc = auc(model_fpr, model_tpr)\n",
    "    roc_display = RocCurveDisplay(fpr=model_fpr, tpr=model_tpr, roc_auc=model_auc)\n",
    "    roc_display = roc_display.plot(ax=ax, marker=\"o\", markersize=2, plot_chance_level=True)\n",
    "    ax.set_title(plot_title);\n",
    "    ax.legend(fontsize=10);\n",
    "    display(ax.savefig())\n",
    "    return model_auc\n",
    "\n",
    "exp_model_aucs['nofeats'] = plot_roc(\n",
    "    test_df['dohire'], nofeats_test_dohiremeans,\n",
    "    \"Test ROC: Audit Outcomes Only\"\n",
    ")\n",
    "exp_model_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278edb7c-db4f-4566-9d88-9b5f4e1e45f0",
   "metadata": {},
   "source": [
    "And thus we see that, by learning only the overall mean `dohire` value, we do only slightly better than random chance. In the next 3 parts, it's your turn to estimate the non-baseline models which actually incorporate the information we have for each auditor!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f23942-7587-46ad-9fa0-b6125db8f7f8",
   "metadata": {},
   "source": [
    "## [Part 2.1] Model With Just Conviction Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544af60b-a9fc-4b3a-a469-f3afe48bda39",
   "metadata": {},
   "source": [
    "### [Question 2.1.1] Write and Fit Model with Bambi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2fd60-87cf-45c8-b76f-eb648d3ea785",
   "metadata": {},
   "source": [
    "Use what you learned in Part 2.2 to write a new Bambi model, a logistic regression model like before but this time incorporating the auditor's `con` value as the sole predictor (the model should still have an **intercept**, though!). Store the model object itself as `con_model`.\n",
    "\n",
    "Then, use the `.fit()` function to estimate the posterior distribution over the two parameters (the `Intercept` and `con` coefficients), storing the result in `con_idata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "dcccbf33-45c9-45fd-bcd8-d26b68cab688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T04:25:23.310247Z",
     "iopub.status.busy": "2025-08-01T04:25:23.310008Z",
     "iopub.status.idle": "2025-08-01T04:25:23.313582Z",
     "shell.execute_reply": "2025-08-01T04:25:23.313070Z",
     "shell.execute_reply.started": "2025-08-01T04:25:23.310228Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Q2.1.1-response\n",
    "con_model = None # Your code here: replace with Bambi model as described above\n",
    "con_idata = None # Your code here: estimate posterior distribution of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6142a-54fb-427c-a7f7-96c9ec76e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.1.1-public-tests\n",
    "q2_1_1_public_tests = {\n",
    "    'con_model defined': '✅ Passed!' if 'con_model' in globals() else \"🔲 No variable named 'con_model' exists in Python memory\",\n",
    "    'con_idata defined': '✅ Passed!' if 'con_idata' in globals() else \"🔲 No variable named 'con_idata' exists in Python memory\",\n",
    "}\n",
    "q2_1_1_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755cd761-d26a-44e5-9d17-ded12e0e4c93",
   "metadata": {},
   "source": [
    "If all went well, you should be able to run the following cell to generate the visual PGM representation of `con_model`:\n",
    "\n",
    "*(Note that you do **not** have to call `.build()` if you've already run `.fit()`, which you should have done in the previous response cell! `.fit()` automatically calls `.build()` as a first step under the hood)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279e131-de4f-4f83-bf94-6ebe0d488f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_model.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d0760-68ed-44d7-a4eb-676fa6b17f23",
   "metadata": {},
   "source": [
    "And it should look similar to the following:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/e0a5c5efa29a25fae1959ff09871196d21f20397/2025-sum-dsan5650/hw3/bambi_conmodel.svg\" width=\"30%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d743c40f-4e16-4ad0-8f37-453d8b05b95b",
   "metadata": {},
   "source": [
    "### [Question 2.1.2] Extract and Interpret Point Estimates for Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e18ed2-f7e3-4abf-b8fa-2374c44bc695",
   "metadata": {},
   "source": [
    "Next, extract *point* estimates for our two coefficients in the same way that we computed a point estimate for the `Intercept` coefficient in the baseline model.\n",
    "\n",
    "Then, whereas for that model we computed a **single** probability estimate (our estimate of $\\Pr(Y = 1)$, which we derived using `expit()`), here since we have an intercept **and** a coefficient estimate for `con`, you will need to derive and then store **two** probability values:\n",
    "\n",
    "* (a) Store the estimated value of $\\Pr(\\texttt{dohire} = 1 \\mid \\texttt{con} = 0)$ in `pr_dohire_nocon`, and then\n",
    "* (b) Store the estimated value of $\\Pr(\\texttt{dohire} = 1 \\mid \\texttt{con} = 1)$ in `pr_dohire_con`,\n",
    "\n",
    "as indicated in the comments within the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347506c-d70a-4084-b482-4c8b7e9ac39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.1.2-response\n",
    "\n",
    "# (Step 1) Extract point estimates for coefficients on 'Intercept' and 'con'\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) Use the extracted point estimates to fill in the probability values\n",
    "\n",
    "pr_dohire_nocon = None # Your code here: replace the None\n",
    "pr_dohire_con = None # Your code here: replace the None\n",
    "print(pr_dohire_nocon, pr_dohire_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ac142-ff5b-47f0-b6a4-4d3cd963f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.1.2-public-tests\n",
    "q2_1_2_public_tests = {\n",
    "    'pr_dohire_nocon filled': '✅ Passed!' if 'pr_dohire_nocon' is not None else \"🔲 Value of 'pr_dohire_nocon' should not be None\",\n",
    "    'pr_dohire_con filled': '✅ Passed!' if 'pr_dohire_con' is not None else \"🔲 Value of 'pr_dohire_con' should not be None\",\n",
    "}\n",
    "q2_1_2_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7ddd9-1b7c-4301-ab35-21e823425e29",
   "metadata": {},
   "source": [
    "As a quick sanity check, the two estimates that get printed out at the end of your response should be very close to the following two **group means** of the `dohire` variable, for auditors without and with prior convictions (respectively):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88352207-965b-4d15-860f-7d0eb75a9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('con')['dohire'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9d73a-3e48-4eb7-90fe-0990819ffea8",
   "metadata": {},
   "source": [
    "**Moving Beyond Point Estimates**\n",
    "\n",
    "I know the reading is painful, but there is a **super important** caveat here: what we just did in Parts 2.2 and 2.3, where we derived probability estimates as **single numbers** by \"plugging in\" `con = 0` and `con = 1` into a formula like `pr_value = expit(Intercept_coef + con_coef * con)`... This is for **sanity-checking purposes only!** Meaning, the above derivation of the two point estimates `pr_dohire_nocon` and `pr_dohire_con` does **not** represent the \"final result\" for your model!\n",
    "\n",
    "It's not the final result because, it **throws away 99.999% of the information that the Bayesian model gives you!** As I've emphasized in the instructions for HW3 especially, PyMC/Bambi give us entire **distributions over coefficients**, rather than just single point estimates. The following code cell will help illustrate the difference.\n",
    "\n",
    "By calling `.predict()` with **`kind='response_params'`**, instead of the `kind='response'` argument used in Part 2.2 above, we generate an entire **distribution** of estimates for $\\Pr(Y_i = 1)$, for each row $i$ in the training data, conditional on values of `con`.\n",
    "\n",
    "We can then use `az.summary()` to generate a table where each row $i$ is a **summary** of distribution $i$ out of the $N_{\\text{train}} = 139$ total distributions, which defaults to the `train_df` data provided at the beginning of this part since we don't use the optional `data=` argument here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc76570-dab6-4e21-afe9-5dbc8ede4088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title generate-posterior-distributions\n",
    "con_model.predict(con_idata, kind='response_params')\n",
    "az.summary(con_idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c54b5-49b6-438c-8385-d01ab5e11b3c",
   "metadata": {},
   "source": [
    "### [Question 2.1.3] Evaluate Predictive Performance on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbeab5-8842-4eed-b43a-438257b21087",
   "metadata": {},
   "source": [
    "With this distinction between **point estimates** (from frequentist statistics) and **distributions over estimates** (from Bayesian statistics) in mind, let's move on to generating our ROC curve and AUC score.\n",
    "\n",
    "Here, another good reason to read that quick rant about distributions is because it contains some starter code for this question 😉! Whereas in Part 2.2 we jumped straight to calling `.predict()` with the `kind='response'` argument, without explanation. You now know from the previous code cell, though, how this `kind` parameter operates in Bambi:\n",
    "\n",
    "* Calling `.predict()` with **`kind='response_params'`** produces a summary table of the **posterior distribution**, while\n",
    "* Calling `.predict()` with **`kind='response'`** produces a summary table of the **posterior predictive distribution**.\n",
    "\n",
    "So, in the following code cell, you should be able to draw on the code provided in the previous code cell, but with the `kind='response_params'` option changed to `kind='response'`. Since we're skipping the training-set evaluation here, you should also provide a value for the `data=` argument to `.predict()` (which you did in a code cell near the end of Part 2.2)\n",
    "\n",
    "Then, to finish this part, you just need to write one more line of code! Because, after calling `.predict()`, all that's left is to use the `.mean(dim=['chain','draw'])` approach to extract the **mean** `dohire` values for each observation in the **test** set ($N_{\\text{test}} = 35$ values total), storing these means in a variable named `con_train_dohiremeans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96450ea-7d0d-40a1-811f-0ad9c69e30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.1.3-response\n",
    "\n",
    "# (Step 1) Call con_model.predict() with appropriate arguments.\n",
    "# Remember that this function won't produce any output, but if it runs without\n",
    "# visible errors, that should indicate that everything worked as expected!\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) Extract the mean of each distribution over dohire, storing the result\n",
    "# in a variable named con_test_dohiremeans\n",
    "\n",
    "# Your code here\n",
    "con_test_dohiremeans = None # Replace the None\n",
    "\n",
    "# The following line will display the posterior predictive means for dohire\n",
    "# values (the mean of Pr(dohire_i = 1) for i = 1, 2, ..., n_test), if your code\n",
    "# above has been implemented correctly\n",
    "con_test_dohiremeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf51771-1976-4520-b815-eb72ba5b7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.1.3-public-tests\n",
    "q2_1_3_public_tests = {\n",
    "    'con_test_dohiremeans defined': '✅ Passed!' if 'con_test_dohiremeans' in globals() else \"🔲 No variable named 'con_test_dohiremeans' exists in Python memory\",\n",
    "}\n",
    "q2_1_3_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7b7e0-9613-4cc3-9625-e7205ec6798a",
   "metadata": {},
   "source": [
    "**ROC Curve and AUC Score**\n",
    "\n",
    "Finally, as a thank you for trudging through this part, the code for generating the ROC curve and storing the AUC score is provided for you in the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96857185-d156-463b-8602-4e66f24c52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_model_aucs['con_only'] = plot_roc(\n",
    "    test_df['dohire'], con_test_dohiremeans,\n",
    "    \"Test ROC: Audits with Conviction Only\"\n",
    ")\n",
    "exp_model_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7399146-2f81-4f65-910c-a689f3f345a0",
   "metadata": {},
   "source": [
    "If all is working as expected, you should observe an increase in AUC score, relative to the baseline model (`nofeats`), result from the new inclusion of `con` as a feature.\n",
    "\n",
    "And, to reiterate the `kind='response_params'` vs. `kind='response'` distinction one last time, before you move to the last 2 models:\n",
    "\n",
    "* The code you just wrote, using `kind='response'`, generated (predictive) distributions over the $Y_i$ values **themselves**, the **outcomes** in the model, in contrast to\n",
    "* The code provided to you immediately beforehand (in the code cell with title `generate-posterior-distributions`) generated distributions over values of the **parameters** $p = \\Pr(Y_i = 1)$.\n",
    "\n",
    "Using the `kind='response'` option therefore plays the same role in Bambi as the `.sample_posterior_predictive()` function plays in base PyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b7c42-079c-4cf6-bf11-8dcbf6e42fe1",
   "metadata": {},
   "source": [
    "## [Part 2.2] Model With Race Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ae71d-c2f5-4a89-a08a-8b1acd2dad0b",
   "metadata": {},
   "source": [
    "Here, so that you can get a feel for carrying out the full Bambi workflow without interruption, the only instruction is to follow the same steps as in Part 2.1, but this time with a model that **only includes `race` as a predictor** (though it should still have an intercept!)\n",
    "\n",
    "You can use the public tests, after each `response` cell, for guidance on the names of the variables you should be producing in the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d4280-0143-4745-9409-ac6ec0b19cae",
   "metadata": {},
   "source": [
    "### [Question 2.2.1] Write and Fit the Model with Bambi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d315897-f4dc-480a-b322-d9966ca65747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2.1-response\n",
    "race_model = None # Your code here: replace the None\n",
    "race_idata = None # Your code here: replace the None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba37ae1-8c71-4422-af9a-0a0565e55e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2.1-public-tests\n",
    "q2_2_1_public_tests = {\n",
    "    'race_model defined': '✅ Passed!' if 'race_model' in globals() else \"🔲 No variable named 'race_model' exists in Python memory\",\n",
    "    'race_idata defined': '✅ Passed!' if 'race_idata' in globals() else \"🔲 No variable named 'race_idata' exists in Python memory\",\n",
    "}\n",
    "q2_2_1_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41698978-0e07-4019-85fe-eb107eec04de",
   "metadata": {},
   "source": [
    "### [Question 2.2.2] Extract and Interpret Point Estimates for Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f234e3-d46e-4a33-b446-dadd9900a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2.2-response\n",
    "\n",
    "# (Step 1) Extract point estimates for coefficients on 'Intercept' and 'con'\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) Use the extracted point estimates to fill in the probability values\n",
    "\n",
    "pr_dohire_white = None # Your code here: replace the None\n",
    "pr_dohire_black = None # Your code here: replace the None\n",
    "\n",
    "print(pr_dohire_white, pr_dohire_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e69c1-3aa4-4b84-b29e-07258ae11b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2.2-public-tests\n",
    "q2_2_2_public_tests = {\n",
    "    'pr_dohire_white filled': '✅ Passed!' if 'pr_dohire_white' is not None else \"🔲 Value of 'pr_dohire_white' should not be None\",\n",
    "    'pr_dohire_black filled': '✅ Passed!' if 'pr_dohire_black' is not None else \"🔲 Value of 'pr_dohire_black' should not be None\",\n",
    "}\n",
    "q2_2_2_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f9e81-60be-4d3f-a26b-fd871064a323",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-29T06:50:30.803903Z",
     "iopub.status.idle": "2025-07-29T06:50:30.804097Z",
     "shell.execute_reply": "2025-07-29T06:50:30.804010Z",
     "shell.execute_reply.started": "2025-07-29T06:50:30.804002Z"
    }
   },
   "source": [
    "As a sanity check: your \"summary\" point estimates for `pr_dohire_white` and `pr_dohire_black`, printed out at the end of the previous cell, should be close to the group means computed and displayed by the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781f0bd-ff30-4620-a466-dfb8b14bdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('race')['dohire'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e035fc2-0508-48a1-a80f-eefe483742b1",
   "metadata": {},
   "source": [
    "### [Question 2.2.3] Evaluate Predictive Performance on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf9014-99f4-4394-80c0-b77ea6cd0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2.3-response\n",
    "\n",
    "# (Step 1) Call race_model.predict() with appropriate arguments\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) Extract the mean of each distribution over dohire, storing the result\n",
    "# in a variable named race_test_dohiremeans\n",
    "\n",
    "race_test_dohiremeans = None # Your code here: replace the None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229ed6f-68b8-4241-a163-fff59c38a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2.3-public-tests\n",
    "q2_2_3_public_tests = {\n",
    "    'race_test_dohiremeans defined': '✅ Passed!' if 'race_test_dohiremeans' in globals() else \"🔲 No variable named 'race_test_dohiremeans' exists in Python memory\",\n",
    "}\n",
    "q2_1_3_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59252ce0-68ab-46fe-8151-fb0a5799b5c2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-29T06:50:30.806899Z",
     "iopub.status.idle": "2025-07-29T06:50:30.807087Z",
     "shell.execute_reply": "2025-07-29T06:50:30.807005Z",
     "shell.execute_reply.started": "2025-07-29T06:50:30.806997Z"
    }
   },
   "source": [
    "And, as before, we provide the final piece of code in the following cell, which displays the ROC curve for your model, stores the corresponding AUC score, and displays our running list of AUC scores for the three models we've estimated thus far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf12c72-0e91-414d-86fa-48a92cc8e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_model_aucs['race_only'] = plot_roc(\n",
    "    test_df['dohire'], race_test_dohiremeans,\n",
    "    \"Test ROC: Audits with Race Only\"\n",
    ")\n",
    "exp_model_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c86a4-13b4-4ce4-91b3-e4bf532d34ac",
   "metadata": {},
   "source": [
    "## [Part 2.3] Multivariate Logistic Regression Model\n",
    "\n",
    "Now, the payoff for using Bambi! Whereas the multivariable setting was probably a bit daunting in Part 1, since we had to write out a multivariate Logistic Regression model \"from scratch\" (and thus had to think about, for example, which specific priors to put on each coefficient), here we can extend the prior two single-variable models in a \"natural\" way, which should be familiar if you've estimated regressions in R for example.\n",
    "\n",
    "The main complexity here, relative to the previous two parts, is just that we again want to include an **interaction term** between `race` and `con`, like you did in HW3A. Since Bambi fully imports R's formula syntax, this interaction term can be written in the formula string itself as either **`race * con`** or **`race:con`**. Since the \"standard\" representation is `race:con`, regardless of which you choose you should see a `race:con` node in the PGM if your interaction term is implemented correctly! In our solutions, the PGM looks as follows:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/6d575669ede3be71b2a7bc983d2c110c406fa11b/2025-sum-dsan5650/hw3/bambi_multivar.svg\" width=\"60%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47783f9a-8b2d-4af9-ab8f-b5a9305a8fb0",
   "metadata": {},
   "source": [
    "### [Question 2.3.1] Write and Fit the Model with Bambi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2d37c-0f2a-44a2-8c67-936f6fb078f5",
   "metadata": {},
   "source": [
    "As you did in Parts 2.1 and 2.2, implement the multivariate logistic regression model (with `race:con` interaction term) in Bambi, storing the model object in a variable named `mvb_model`, then estimate the posterior distribution via `.fit()`, storing the inference data in a variable named `mvb_idata`.\n",
    "\n",
    "The included line of code at the end displays the PGM for the model, so that you can compare with the image included above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb52e98-760c-431a-8804-5878d213155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.3.1-response\n",
    "\n",
    "# (Step 1) Write the model using R's formula syntax in Bambi\n",
    "mvb_model = None # Your code here: replace the None\n",
    "\n",
    "# (Step 2) Use .fit() to infer posterior distribution\n",
    "mvb_idata = None # Your code here: Replace the None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84c7eb-875e-4923-b8ac-30f2c4bbf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.3.1-public-tests\n",
    "q2_3_1_public_tests = {\n",
    "    'mvb_model defined': '✅ Passed!' if 'mvb_model' in globals() else \"🔲 No variable named 'mvb_model' exists in Python memory\",\n",
    "    'mvb_idata defined': '✅ Passed!' if 'mvb_idata' in globals() else \"🔲 No variable named 'mvb_idata' exists in Python memory\",\n",
    "}\n",
    "q2_3_1_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a31cc-ea62-4b56-a8d6-ff41b6003c52",
   "metadata": {},
   "source": [
    "### [Question 2.3.2] Extract and Interpret Point Estimates for Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d780ad5-5c7f-4dd0-9d48-36d54cfa2ae7",
   "metadata": {},
   "source": [
    "Since we now have a multivariable model, with two binary variable `race` and `con`, there are **four** different probability estimates we can derive from our coefficients:\n",
    "\n",
    "* $\\Pr(\\texttt{dohire}_i = 1 \\mid \\texttt{race}_i = \\text{White}, \\texttt{con}_i = 0)$\n",
    "* $\\Pr(\\texttt{dohire}_i = 1 \\mid \\texttt{race}_i = \\text{Black}, \\texttt{con}_i = 0)$\n",
    "* $\\Pr(\\texttt{dohire}_i = 1 \\mid \\texttt{race}_i = \\text{White}, \\texttt{con}_i = 1)$\n",
    "* $\\Pr(\\texttt{dohire}_i = 1 \\mid \\texttt{race}_i = \\text{Black}, \\texttt{con}_i = 1)$\n",
    "\n",
    "In the following code cell, use the `mvb_idata` variable you created above to compute these conditional probabilities, then replace the `None` values near the end of the code cell with the appropriate values as indicated.\n",
    "\n",
    "*(Here we use fancy stuff like `Enum`, `dataclass`, and `namedtuple`, not for the sake of being fancy, but because I've found this combination genuinely useful for creating mini-data structures like this to represent joint probability distributions as the number of possible values starts to become larger than, like, 2 or 3!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b2d78e37-c63a-4024-b315-abeb381075a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:34:02.924033Z",
     "iopub.status.busy": "2025-08-01T08:34:02.923801Z",
     "iopub.status.idle": "2025-08-01T08:34:02.930340Z",
     "shell.execute_reply": "2025-08-01T08:34:02.929873Z",
     "shell.execute_reply.started": "2025-08-01T08:34:02.924015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TesterProfile(race='White', conviction=0): None,\n",
       " TesterProfile(race='White', conviction=1): None,\n",
       " TesterProfile(race='Black', conviction=0): None,\n",
       " TesterProfile(race='Black', conviction=1): None}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Q2.3.2-response\n",
    "# Setup code: Data structures for joint distribution\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Race(Enum):\n",
    "    White = 0\n",
    "    Black = 1\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TesterProfile:\n",
    "    race: Race\n",
    "    conviction: bool\n",
    "\n",
    "# (Step 1) derive posterior estimates using mvb_idata, storing the result in\n",
    "# a variable named mvb_estimates\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) extract posterior point estimates from the mvb_estimates object just\n",
    "# created\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 3) Use the posterior point estimates to compute the four probability\n",
    "# values (or, if you prefer, you can skip this and just replace the None values\n",
    "# below directly)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Once they're computed, replace None values below with estimated probabilities\n",
    "q2_3_2_response = {\n",
    "    TesterProfile(race=\"White\", conviction=0): None,\n",
    "    TesterProfile(race=\"White\", conviction=1): None,\n",
    "    TesterProfile(race=\"Black\", conviction=0): None,\n",
    "    TesterProfile(race=\"Black\", conviction=1): None,\n",
    "}\n",
    "q2_3_2_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "541eade1-064e-40a6-8184-8bbf4d1564ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:34:03.726046Z",
     "iopub.status.busy": "2025-08-01T08:34:03.725834Z",
     "iopub.status.idle": "2025-08-01T08:34:03.731914Z",
     "shell.execute_reply": "2025-08-01T08:34:03.731351Z",
     "shell.execute_reply.started": "2025-08-01T08:34:03.726028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q2_3_2_response defined': '✅ Passed!',\n",
       " 'No None values': \"🔲 One or more of the values in 'q2_3_2_response' is None\"}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Q2.3.2-public-tests\n",
    "def all_none(response_dict):\n",
    "    response_vals = list(response_dict.values())\n",
    "    return all([v is None for v in response_vals])\n",
    "q2_3_2_public_tests = {\n",
    "    'q2_3_2_response defined': '✅ Passed!' if 'q2_3_2_response' in globals() else \"🔲 No variable named 'q2_3_2_response' exists in Python memory\",\n",
    "    'No None values': '✅ Passed!' if ('q2_3_2_response' in globals()) and (not all_none(q2_3_2_response)) else \"🔲 One or more of the values in 'q2_3_2_response' is None\",\n",
    "}\n",
    "q2_3_2_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71677dd-742a-44c9-a397-458d8b7cae72",
   "metadata": {},
   "source": [
    "### [Question 2.3.3] Evaluate Predictive Performance on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3d74ae26-6207-45e8-b6b3-907d5af3d90a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:10:29.245689Z",
     "iopub.status.busy": "2025-08-01T08:10:29.245346Z",
     "iopub.status.idle": "2025-08-01T08:10:29.248736Z",
     "shell.execute_reply": "2025-08-01T08:10:29.248262Z",
     "shell.execute_reply.started": "2025-08-01T08:10:29.245669Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Q2.3.3-response\n",
    "\n",
    "# (Step 1) Use .predict(), with appropriate arguments, to generate the posterior\n",
    "# predictive distribution (which will be stored in mvb_idata automatically)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) Derive the mean dohire values from `mvb_idata.posterior_predictive`,\n",
    "# storing the results in a variable named mvb_test_dohiremeans\n",
    "\n",
    "mvb_test_dohiremeans = None # Your code here: replace the None\n",
    "\n",
    "mvb_test_dohiremeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126c3ae-236a-493e-8bc1-24e9271c03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.3.3-public-tests\n",
    "q2_3_3_public_tests = {\n",
    "    'mvb_test_dohiremeans defined': '✅ Passed!' if 'mvb_test_dohiremeans' in globals() else \"🔲 No variable named 'mvb_test_dohiremeans' exists in Python memory\",\n",
    "}\n",
    "q2_3_3_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba36c5b-1d0f-4293-bb57-74cf029a95ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-29T06:50:30.819324Z",
     "iopub.status.idle": "2025-07-29T06:50:30.819551Z",
     "shell.execute_reply": "2025-07-29T06:50:30.819462Z",
     "shell.execute_reply.started": "2025-07-29T06:50:30.819453Z"
    }
   },
   "source": [
    "And we can now display the ROC curve and store the AUC score for our final behavior model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017426a4-aa3b-4a00-8943-9f0053f8725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_model_aucs['multivar'] = plot_roc(\n",
    "    test_df['dohire'], mvb_test_dohiremeans,\n",
    "    \"Test ROC: Multivariate Model\"\n",
    ")\n",
    "exp_model_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f4a01-e08f-42b3-8d14-024c8c2463f3",
   "metadata": {},
   "source": [
    "Here you can ponder on whether/why the multivariate model may have failed to perform best out of all models in Part 2 (though, it will likely be close between `multivar` and `con_only`, and, in a full-on modeling scenario we'd use **regularizing priors** to constrain the multivariate model's ability to overfit, and it would then likely come out on top unambiguously!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6706c-0029-4a01-b25b-8bde798165c9",
   "metadata": {},
   "source": [
    "# [Part 3] Modeling Attitudes *and* Behaviors *and* Their Connection(s)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95ff61-9804-4229-a608-5fe1ab371044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T04:57:30.585463Z",
     "iopub.status.busy": "2025-08-01T04:57:30.585200Z",
     "iopub.status.idle": "2025-08-01T04:57:30.592922Z",
     "shell.execute_reply": "2025-08-01T04:57:30.592281Z",
     "shell.execute_reply.started": "2025-08-01T04:57:30.585443Z"
    }
   },
   "source": [
    "**Overview: One Model, One Multiple-Choice Question**\n",
    "\n",
    "This part will be almost entirely **reading** and **running pre-written code** because... well, I was trying to come up with a way to make this attitude-behavior cross-prediction model as interactive and step-by-step as Parts 1 and 2, but... in the end I'd rather that you focus on the concepts! Meaning, focus on how you can model **indidvidual \"pieces\" of your problem** like you did in the previous two parts, and then **fuse** them together to model the dynamics of how the two pieces interrelate, going back and tweaking the individual pieces as needed.\n",
    "\n",
    "This turns out to be one of the three or four most game-changing aspects of the **modular** PGM approach (along with the missing-data-imputation-for-free and the distributions-rather-than-point-estimates features I've ranted about thus far): to see it in action, it's so so worth reading [Lee and Wagenmakers (2013), *Bayesian Cognitive Modeling*](https://www.dropbox.com/scl/fi/7flgs68gpesokk3xpn2dw/Bayesian-cognitive-modeling-_-a-practical-course.pdf?rlkey=504q33aqpeldz7go0x4kicjqe&st=o3548lkc&dl=1), from cover-to-cover, since it builds step-by-step from the simplest possible PGMs to PGMs used in modern cognitive science research!\n",
    "\n",
    "So, your task is to read the following, implement one final model in Part 3.1 (the only part! That I walk you through as quickly as possible!), and then answer one last **multiple-choice question** at the end of that part where you just **promise to... at least scroll through** the [**\"HW3 Grand Finale\" writeup**](https://jjacobs.me/dsan5650/writeups/birthday-instrument/) on the website.\n",
    "\n",
    "The reason it's called the \"HW3 Grand Finale\" is because, it takes the model from Part 3.1 below and extends it into a full-on **joint-inferential** model of attitudes and behaviors. Meaning, in other words, a model **optimized for prediction of behaviors from attitudes, and vice-versa**, by just \"turning the crank\" of Bayes' rule as carried out by PyMC 🤓 Onwards and upwards..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579c3b4-24ab-49e3-9e36-6def66dbc813",
   "metadata": {},
   "source": [
    "## Context for Part 3: Attitude-Behavior Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933f7e3-e1d4-4c93-839e-86be3930b8c5",
   "metadata": {},
   "source": [
    "The lack of consistency between your results from Part 1 and from Part 2 hopefully helps point towards why social psychologists have been studying [**Attitude-Behavior Consistency (ABC)**](https://en.wikipedia.org/wiki/Attitude-behavior_consistency) for many decades now! C. Wright Mills, for example (who is apparently the [fourth-most-cited sociologist of all time](https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:sociology)), posited back in 1940 that\n",
    "\n",
    "> *Perhaps the central methodological problem of the social sciences [comes from the] disparity between lingual and social-motor types of behavior.*\n",
    ">\n",
    "> &mdash;[Mills (1940)](https://www.jstor.org/stable/2769572?seq=1)\n",
    "\n",
    "Thankfully for us, as **computational social scientists**, we have the modeling language of **Probabilistic Graphical Models**, within which we can explicitly differentiate between **latent** and **observable** variables<sup>[1]</sup>. The logic underlying the model in this section, then, is as follows:\n",
    "\n",
    "* We can model **\"Attitudes\" $A$** as latent variables which **do not determine observed behavior on their own!**\n",
    "* Instead, they lead to **different behavior in different Contexts $C$**.\n",
    "* We'll thus define two contexts, $\\textsf{Saying}$ and $\\textsf{Doing}$, as two possible values for $C$.\n",
    "* The telephone survey you modeled in **Part 1** will represent the **Value-Reporting** context $\\textsf{Saying}$, while\n",
    "* The experimental audit you modeled in **Part 2** will represent the **Decision-Making** context $\\textsf{Doing}$\n",
    "\n",
    "The point, however, is to approach this problem with the same kind of testing-rather-than-assuming framework that the **multilevel models** you looked at in HW2 allow us to take. The analogy between multilevel models and the model in this part (and thus between HW2 and HW3) is summarized in the following table:\n",
    "\n",
    "| | Possible Multilevel Models | Possible Attitude-Behavior Models |\n",
    "| - | - | - |\n",
    "| **No-Pooling** | **The assumption**: Within Africa, learning the views of someone in country $x$ tells us nothing about the views of someone in country $y$<br><br>**Methodological result**: We just fit $N$ different regressions for the $N$ countries in Africa<br><br>**The issue**: Think of e.g. Sudan vs. South Sudan---some people in South Sudan went to sleep on [8 July 2011](https://www.bbc.com/news/world-africa-14069082) as Sudanese citizens and woke up the next day as South Sudanese citizens. So, we can probably infer at least *something* about South Sudanese attitudes by e.g. learning the views of Sudanese citizens near the southern border! | **The assumption**: Learning someone's views from a survey gives us no useful information about their behavior<br><br>**Methodological result**: We have survey data from a set of people $S$, alongside experimental results from that same set of people, but no way to connect them (which would massively increase the statistical power of our inferences about $S$)<br><br>**The issue**: People, at least under Festinger's theory of [cognitive dissonance](https://www.jstor.org/stable/24936719), sometimes go to great pains to bring their *behavior* in line with their *values*. So, if this theory holds even a little bit, we can usually at least learn *something* about people's behavior from their stated beliefs/attitudes (allowing us to predict it better than random guessing!) |\n",
    "| **Full-Pooling** | **The assumption**: The difference between person $i$'s country and person $j$'s country is not salient to understanding their views<br><br>**Methodological result**: We estimate one big regression, throwing away the `country` variable<br><br>**The issue**: People within a country often have shared \"norms\", which give rise to correlations across their individual values (something we could actually try to measure with the data!) | **The assumption**: The views professed by someone in a survey gives us all the information we need about their behavioral proclivities<br><br>**Methodological result**: We don't need to conduct an experiment at all!<br><br>**The issue**: People often behave in a way that conflicts with their professed values, so we may be \"assuming away\" an important aspect of whatever social phenomenon we're trying to study (hiring decisions, voting, etc.) |\n",
    "| **Adaptive Pooling** | **The assumption**: We can explicitly **incorporate** the degree of similarity/discrepancy between views of people in country $x$ and country $y$ as a part of our model<br><br>**Methodological result**: We can then use this estimated degree of similarity/discrepancy to e.g. develop better estimates for countries with limited data availability | **The assumption**: We can explicitly **incorporate** the degree of similarity/discrepancy between professed behavior in hypothetical scenarios and observed behavior in real-world scenarios<br><br>**Methodological result**: We can then use this estimated degree of similarity/discrepancy to e.g. develop better estimates for people's behavior given only information on their professed views, and vice-versa! |\n",
    "\n",
    "Hopefully those details drive home the point made at the end of the same article quoted earlier:\n",
    "\n",
    "> While survey and interview methods may offer a window into \"attitudinal frames,\" it is important that they\n",
    "also demonstrate, rather than assume, the impact of these frames upon activities in the world\n",
    ">\n",
    "> &mdash;[Jerolmack and Khan (2014)](https://doi.org/10.1177/0049124114523396)\n",
    "\n",
    "If our model \"succeeds\", then, we should be able to use it as essentially a \"bullshit-calibrator\": a way to take people's professed beliefs and derive useful estimates of their behavior, and vice-versa... Let's get to it!\n",
    "\n",
    "---\n",
    "\n",
    "<small>\n",
    "\n",
    "1. Sadly, I only was able to find [\\[two\\]](https://www.sciencedirect.com/science/article/pii/S0010027709001607) [\\[articles\\]](https://www.research.ed.ac.uk/en/publications/predicting-actions-using-an-adaptive-probabilistic-model-of-human) which mention probabilistic models as a possible approach to studying Attitude-Behavior Consistency, so... I made this footnote to link them and encourage yall to pursue these questions! 😜\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039a403-e9f1-428d-b625-ad7e7b244481",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "df525789-e8c7-43a0-acf6-6c516e51253f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T05:19:41.293864Z",
     "iopub.status.busy": "2025-08-01T05:19:41.293519Z",
     "iopub.status.idle": "2025-08-01T05:19:41.309419Z",
     "shell.execute_reply": "2025-08-01T05:19:41.308925Z",
     "shell.execute_reply.started": "2025-08-01T05:19:41.293847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap');\n",
       ".jp-RenderedHTMLCommon {\n",
       "    font-family: \"Roboto\", sans-serif;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run jupyter_fixes.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import patchworklib as pw\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f4ed7-cd34-436b-9cac-28377d6ad716",
   "metadata": {},
   "source": [
    "**Firm-Level Data**\n",
    "\n",
    "The following code cell loads the first, **firm-level** dataset used in this part, `pager_matched_firms.csv`. The firms in each row are uniquely identified by `firm_id`, and for each firm we have the following information:\n",
    "\n",
    "* `region_str`: A string variable which is `\"Urban\"` for firms within the city of Milwaukee itself, and `\"Suburban\"` for firms located outside of the city (but within the [Milwaukee metropolitan area](https://en.wikipedia.org/wiki/Milwaukee_metropolitan_area))\n",
    "* `region`: The same information as `region_str`, but where **Urban** firms have value `0` and **Suburban** firms have value `1` (for easier use with our ML libraries)\n",
    "* `industry`: A categorical string variable, not used here but, it came with the dataset and you can think about how the analysis could be expanded to incorporate this info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6b70d10a-944f-423f-a088-9a7b6d210074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T06:57:48.183988Z",
     "iopub.status.busy": "2025-08-01T06:57:48.183704Z",
     "iopub.status.idle": "2025-08-01T06:57:48.192443Z",
     "shell.execute_reply": "2025-08-01T06:57:48.191966Z",
     "shell.execute_reply.started": "2025-08-01T06:57:48.183968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>region_str</th>\n",
       "      <th>industry</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firm_id region_str      industry  region\n",
       "0        0      Urban  Retail Trade       0\n",
       "1        1      Urban  Retail Trade       0\n",
       "2        2   Suburban  Retail Trade       1\n",
       "3        3      Urban  Retail Trade       0\n",
       "4        4      Urban  Retail Trade       0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_df = pd.read_csv(\"pager_matched_firms.csv\")\n",
    "firm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf92adb-374d-40c1-8c57-884db08b87ad",
   "metadata": {},
   "source": [
    "**Auditor-Level Data**\n",
    "\n",
    "Then, the following code cell loads a new, expanded-via-imputation version of the **auditor** data from Part 2<sup>[1]</sup>. It has the same variables, but a greater number of audits per firm, thus introducing **within-firm variation** for given (race, conviction-status) values, ensuring that the model in this section is **identifiable** despite its greater number of parameters.\n",
    "\n",
    "---\n",
    "\n",
    "<small>\n",
    "\n",
    "1.  *Why is there a new, expanded version? What was wrong with the Part 2 dataset?* The dataset you just used had **four audits per firm**: one for each possible (race, conviction-status) pair. This made things more manageable, for wrapping-mind-around purposes, but also means that we had the minimum possible **within-firm variation** for an estimable model. To make it possible to estimate the **additional** parameters in this section's model, therefore, I drew additional samples from the overall joint distribution of variables from the original dataset (using PyMC's `pm.sample_posterior_predictive()` function!) This ensures that the **summary statistics** (and findings of their study) remain approximately the same as before, but that we now have **40 (simulated) audits per firm** (ten per possible race x conviction-status pair)) rather than just 4.\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f42c16fe-bd6c-4d56-90a8-78baf7839ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T06:57:51.347006Z",
     "iopub.status.busy": "2025-08-01T06:57:51.346676Z",
     "iopub.status.idle": "2025-08-01T06:57:51.354702Z",
     "shell.execute_reply": "2025-08-01T06:57:51.354137Z",
     "shell.execute_reply.started": "2025-08-01T06:57:51.346980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auditor_id</th>\n",
       "      <th>firm_id</th>\n",
       "      <th>con</th>\n",
       "      <th>race</th>\n",
       "      <th>race_str</th>\n",
       "      <th>dohire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   auditor_id  firm_id  con  race race_str  dohire\n",
       "0           0        0    0     0    White       0\n",
       "1           1        0    1     0    White       1\n",
       "2           2        0    0     1    Black       0\n",
       "3           3        0    1     1    Black       0\n",
       "4           4        1    0     0    White       1"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_df = pd.read_csv(\"pager_matched_auditors.csv\")\n",
    "audit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fa9fa-8549-48f3-9f6f-9edf8c0fa8b7",
   "metadata": {},
   "source": [
    "## Summary Statistics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e0950-4031-451d-a2fb-a8479531604d",
   "metadata": {},
   "source": [
    "By computing the same summary statistics we computed in Part 2, we can see how the expansion-via-imputation has preserved many substantive aspects of the dataset (for example, the high-to-low ordering of groups in terms of `dohire` rates). Because of how Bayesian imputation works, though, it *has* brought the group rates closer together -- for the same reason that the estimates for the low-data-availability \"Zudan\" country from HW2 were \"shrunk\" down to be closer to the overall (pooled) mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "96e0d60f-5377-4684-a666-076215fdce5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T06:57:52.915832Z",
     "iopub.status.busy": "2025-08-01T06:57:52.915592Z",
     "iopub.status.idle": "2025-08-01T06:57:52.924388Z",
     "shell.execute_reply": "2025-08-01T06:57:52.923938Z",
     "shell.execute_reply.started": "2025-08-01T06:57:52.915814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_str</th>\n",
       "      <th>con</th>\n",
       "      <th>callback_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  race_str  con  callback_rate\n",
       "0    Black    0       0.302326\n",
       "1    Black    1       0.248837\n",
       "2    White    0       0.400000\n",
       "3    White    1       0.330233"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_rate_df = audit_df.groupby(['race_str','con'])['dohire'].mean().to_frame().reset_index()\n",
    "audit_rate_df.rename(columns={'dohire': 'callback_rate'}, inplace=True)\n",
    "audit_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8220939e-3b6b-4d74-a5c4-7db1c8ab74c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T06:57:53.605643Z",
     "iopub.status.busy": "2025-08-01T06:57:53.605398Z",
     "iopub.status.idle": "2025-08-01T06:57:53.756808Z",
     "shell.execute_reply": "2025-08-01T06:57:53.756326Z",
     "shell.execute_reply.started": "2025-08-01T06:57:53.605625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 2 Axes>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = pw.Brick(figsize=(5, 3));\n",
    "sns.barplot(\n",
    "    x=\"race_str\", y='callback_rate', hue='con', data=audit_rate_df,\n",
    "    alpha=0.9, order=['White','Black'], ax=ax\n",
    ");\n",
    "ax.set_title(\"Callback Rates for Imputed Dataset\")\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9278c66-45d7-47f3-98c5-817d0c991f5e",
   "metadata": {},
   "source": [
    "This \"smoothing out\" of inter-group differences is, sadly, the price that must be paid if we want a dataset with **greater** within-firm variation but **approximately-similar** group effects, unless we're willing to bring additional assumptions to this procedure (it turns out to be very similar to the [\"differential privacy\" approach](https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/process/disclosure-avoidance/differential-privacy.html) utilized by the US Census starting in 2020, and if you took DSAN5450 with me you may also be able to see the connection between the two!).\n",
    "\n",
    "With all that said, let's build our model **connecting** attitudes and behaviors! Your job is just to answer the multiple-choice questions at the end of each sub-part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa970275-3a9c-416b-9784-049f2d364163",
   "metadata": {},
   "source": [
    "## [Part 3.1] *(The Only Sub-Part!)* A Multilevel Model of Attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1af6bc09-cf99-429e-bb33-7bd61240f7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T06:59:58.626808Z",
     "iopub.status.busy": "2025-08-01T06:59:58.626536Z",
     "iopub.status.idle": "2025-08-01T06:59:58.635845Z",
     "shell.execute_reply": "2025-08-01T06:59:58.635456Z",
     "shell.execute_reply.started": "2025-08-01T06:59:58.626788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap');\n",
       ".jp-RenderedHTMLCommon {\n",
       "    font-family: \"Roboto\", sans-serif;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run jupyter_fixes.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import patchworklib as pw\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e100bfb-5c67-4249-bfb3-7fbffdc18e78",
   "metadata": {},
   "source": [
    "First, in addition to re-including the imports above (so that you can work on this part independently of Part 2), we'll also re-load the **survey** data just in case, since it's the main data we'll be using to model **attitudes** at both the **region** and **firm** level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "02565ff1-14c4-42c0-bea0-bea4b49e70a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T06:58:37.830627Z",
     "iopub.status.busy": "2025-08-01T06:58:37.830360Z",
     "iopub.status.idle": "2025-08-01T06:58:37.839182Z",
     "shell.execute_reply": "2025-08-01T06:58:37.838723Z",
     "shell.execute_reply.started": "2025-08-01T06:58:37.830610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey_id</th>\n",
       "      <th>firm_id</th>\n",
       "      <th>con</th>\n",
       "      <th>race</th>\n",
       "      <th>race_str</th>\n",
       "      <th>sayhire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survey_id  firm_id  con  race race_str  sayhire\n",
       "0          0        0    0     0    White        1\n",
       "1          1        0    1     0    White        0\n",
       "2          2        0    0     1    Black        1\n",
       "3          3        0    1     1    Black        0\n",
       "4          4        1    0     0    White        1"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df = pd.read_csv(\"pager_matched_surveys.csv\")\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89285f96-c3d9-4c42-86b2-a7bf5b2cbc19",
   "metadata": {},
   "source": [
    "### [Question 3.1.1] Write and Fit Model with PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a463d-68f0-4a46-8119-0f728a68e550",
   "metadata": {},
   "source": [
    "Your job now is just to implement 1/3 of the full cross-predictive model! (The next 1/3 would be a multilevel model of **behaviors**, and then the final 1/3 would be the **latent ABC variable** linking these first two models)\n",
    "\n",
    "Writing it out in the step-by-step, generative form that you saw all the way back in HW1, the key **Parameter RVs** of the model (as in, this does not yet account for how the observed data gets \"plugged in\", which will be covered by the PGM image below this table):\n",
    "\n",
    "| | | | | |\n",
    "| - | - | - | - | - |\n",
    "| 1. | `ascore_city` | $\\sim$ | $\\mathcal{N}(0, 1.5)$ | Generate an \"attitude score\" -- called that because it plays a role in determining $\\Pr(\\texttt{sayhire})$, but is a **log-odds** score rather than a probability (so it can range from $-\\infty$ to $\\infty$, and we can put this nice Normal distribution prior on it, then convert it into a probability further down the line) |\n",
    "| 2. | `ascore_region` | $\\sim$ | $(\\mathcal{N}(0, 1), \\mathcal{N}(0, 1))$ | I know this notation is confusing, but it is written this way to indicate that you should implement this variable as a 2-element **vector** of `pm.Normal()` RVs.<br><br>This will allows you to straightforwardly use a given firm's **`region_obs` value** as an **index** into this vector, in Step 3. This also means that you no don't need to use `pm.math.switch()` anywhere in this model! (Though you won't be penalized for using that approach instead of this indexing approach) |\n",
    "| 3. | `ascore_firm` | $\\sim$ | $\\mathcal{N}(\\texttt{ascore\\_region[region\\_obs]}, 1)$ | This is the \"final\" attitude score, the attitude score at the **firm** level, which is the lowest level in the multilevel model with an \"attitude score\" property |\n",
    "| 4. | `p_sayhire` | $\\leftarrow$ | $\\text{logit}^{-1}(\\texttt{ascore\\_firm})$ | This is the payoff from using attitude **scores** (in log-odds units) in Steps 1-3 rather than attitude **probabilities**: the **regional** attitude scores vary around the city mean via the \"natural\" choice of the Normal distribution, then the **firm** attitude scores vary around the mean of their regions again via the \"natural\" Normal distribution, until finally at this point we **convert** from log-odds scores into human-interpretable **probabilities of saying \"likely hire\"** in response to the Chad vignette. |\n",
    "| 5. | `sayhire` | $\\sim$ | $\\text{Bern}(\\texttt{p\\_sayhire[survey\\_firm\\_ids]})$ | This is the \"outcome\" variable, in the same general form you've implemented a bunch of times now (so, for example, this is where you should include the `observed=` argument to `pm.Bernoulli()`).<br><br>The only slightly-fancier thing now is that, we need to generate **multiple** Bernoulli outcomes for **each** firm (one Bernoulli outcome for each **auditor** who was assigned to a given firm). That's your final challenge: to figure out how to use the `dims=` argument to handle this \"mismatch\" between the number of **firms** and the number of **auditors** in this Part 3 dataset. |\n",
    "\n",
    "Steps 1-4 thus represent the four main **parameters** of the model, and Step 5 represents the **outcome** (which is why this \"final step\" variable is often referred to as the **likelihood link**: it serves as a kind of \"interface\" between the observed data and the hypothesized model parameters when the MCMC algorithm is... \"churning\" back and forth between the two, with the aim of maximizing the model's log-likelihood function).\n",
    "\n",
    "When it's all put together, the model should look something like the following, which also makes explicit where exactly the **data** nodes enter the model:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/132f79397ffb46cc21ef9ceb15eb520d2600a03e/2025-sum-dsan5650/hw3/multilevel_attitude.svg\" width=\"40%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58eb9da-e0e1-41c8-99d0-267fff68f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.1.1-response\n",
    "mla_coords = {\n",
    "    'region': ['Urban','Suburban'],\n",
    "    'audit_id': audit_df.index.values,\n",
    "    'survey_id': survey_df.index.values,\n",
    "    'firm_id': firm_df.index.values,\n",
    "}\n",
    "survey_firm_ids = survey_df['firm_id'].values\n",
    "\n",
    "# Your code here: Implement the model, as described above, giving it the name\n",
    "# mla_model (for MultiLevel Attitude model)\n",
    "\n",
    "\n",
    "\n",
    "# Once you've implemented the model, uncomment the following line to display\n",
    "# it in PGM form -- then you can compare it with the image included above, as\n",
    "# a sanity check!\n",
    "\n",
    "# pm.model_to_graphviz(mla_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382deb3-6893-4678-b88c-6e04a8c551bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.1.1-public-tests\n",
    "q3_1_1_public_tests = {\n",
    "    'mla_model defined': '✅ Passed!' if 'mla_model' in globals() else \"🔲 No variable named 'mla_model' exists in Python memory\",\n",
    "}\n",
    "q3_1_1_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530eb2e7-0ffe-4d45-88c7-a0ba26c634c0",
   "metadata": {},
   "source": [
    "### [Question 3.1.2] Extract Point Estimates for `ascore_region`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca13948-d683-42bb-88cb-b817d1cdd3e0",
   "metadata": {},
   "source": [
    "Now that your model is ready to go, in the following code cell, use the `pm.sample()` function to estimate the posterior distributions for the parameters in `mla_model`.\n",
    "\n",
    "Though `pm.sample()` estimates this distribution for **all** parameters, here we'll focus in specifically on **`ascore_region`**. The idea is that, even with just this \"piece\" of the full cross-predictive model, we can **compare the posterior distributions** of **`ascore_region[Urban]`** and **`ascore_region[Suburban]`** to get a sense for **which subset of firms in the Milwaukee area are more likely to respond positively to applicants, overall!** This was the original purpose of this whole part of the assignment: a Bayesian model allowing yall to \"input\" characteristics and get back predicted $\\Pr(`sayhire` = 1)$ values **and** predicted $\\Pr(`dohire` = 1)$ values. As it stands, the writeup mentioned above is now where that magic model lives!\n",
    "\n",
    "As a final detail on the included code: Since the `az.summary()` tables can start to look cluttered once you add more and more variables to your model, here the included code uses its optional `var_names=` argument to ensure that the table only summarizes the posterior distributions for `ascore_region`.\n",
    "\n",
    "The following table was copied directly from our solutions (with the cell values removed), so you can see exactly the form that the results take on if your model implementation uses `region_obs` as an index into the 2-element vector RV `ascore_region`.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align:right\">\n",
    "      <th></th>\n",
    "      <th>mean</th>\n",
    "      <th>sd</th>\n",
    "      <th>hdi_3%</th>\n",
    "      <th>hdi_97%</th>\n",
    "      <th>mcse_mean</th>\n",
    "      <th>mcse_sd</th>\n",
    "      <th>ess_bulk</th>\n",
    "      <th>ess_tail</th>\n",
    "      <th>r_hat</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>ascore_region[Urban]</th>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ascore_region[Suburban]</th>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f6027d8c-5351-47ca-8022-03681feb0ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T07:40:37.266980Z",
     "iopub.status.busy": "2025-08-01T07:40:37.266701Z",
     "iopub.status.idle": "2025-08-01T07:40:37.269876Z",
     "shell.execute_reply": "2025-08-01T07:40:37.269489Z",
     "shell.execute_reply.started": "2025-08-01T07:40:37.266962Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Q3.1.2-response\n",
    "\n",
    "# Use pm.sample(random_seed=5650) to estimate the posterior\n",
    "# distributions of the parameters in mla_model, storing the result in a variable\n",
    "# named mla_idata\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# If implemented correctly (and using region_obs as the index for ascore_region),\n",
    "# uncommenting the following line should generate a table that looks like the\n",
    "# above skeleton table, but with the cell values filled in!\n",
    "\n",
    "# az.summary(mla_idata, var_names=['ascore_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef47f4-5403-41dd-b37e-b2a33d2377f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.1.2-public_tests\n",
    "q3_1_2_public_tests = {\n",
    "    'mla_idata defined': '✅ Passed!' if 'mla_idata' in globals() else \"🔲 No variable named 'mla_idata' exists in Python memory\",\n",
    "}\n",
    "q3_1_2_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb93cb-4576-4663-ad8d-be59ef66dc40",
   "metadata": {},
   "source": [
    "### [Question 3.1.3] Interpret `ascore_region` Point Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0547e-7754-415b-8e4f-c59bc925ab5d",
   "metadata": {},
   "source": [
    "This is the final coding question on HW3 (besides the multiple choice and pinky promise questions below)!\n",
    "\n",
    "There is one step left, which you saw in Parts 1 and 2 as well: though we can already see from the `az.summary()` table above which of the regions has a **higher** $\\Pr(\\texttt{sayhire} = 1)$ value, we don't yet know **what this value is** for the two regions!\n",
    "\n",
    "So, in the following code cell, use the `expit()` function (that was sneakily imported at the beginning of Part 3) to compute the two **probabilities**\n",
    "\n",
    "* $\\Pr(\\texttt{sayhire}_j = 1 \\mid \\text{Region}_j = \\text{Urban})$ and\n",
    "* $\\Pr(\\texttt{sayhire}_j = 1 \\mid \\text{Region}_j = \\text{Suburban})$,\n",
    "\n",
    "where $j$ indexes **firms** in this case, then store these values in `pr_sayhire_urban` and `pr_sayhire_suburban`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa9bb1-6cc8-4e27-bb8c-866c5006a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.1.3-response\n",
    "\n",
    "# (Step 1) Extract point estimates for ascore_region from mla_idata.posterior\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# (Step 2) Use these point estimates, along with expit(), to derive the\n",
    "# probability point estimates mentioned above\n",
    "\n",
    "pr_sayhire_urban = None # Your code here: replace the None\n",
    "pr_sayhire_suburban = None # Your code here: replace the None\n",
    "\n",
    "print(pr_sayhire_urban, pr_sayhire_suburban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "377705f8-e0b5-4a3f-a347-1d27e74a9e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:38:46.151535Z",
     "iopub.status.busy": "2025-08-01T08:38:46.151217Z",
     "iopub.status.idle": "2025-08-01T08:38:46.156622Z",
     "shell.execute_reply": "2025-08-01T08:38:46.156106Z",
     "shell.execute_reply.started": "2025-08-01T08:38:46.151517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pr_sayhire_urban defined': '✅ Passed!',\n",
       " 'pr_sayhire_suburban defined': '✅ Passed!'}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Q3.1.3-public-tests\n",
    "q3_1_3_public_tests = {\n",
    "    'pr_sayhire_urban defined': '✅ Passed!' if 'pr_sayhire_urban' in globals() else \"🔲 No variable named 'pr_sayhire_urban' exists in Python memory\",\n",
    "    'pr_sayhire_suburban defined': '✅ Passed!' if 'pr_sayhire_suburban' in globals() else \"🔲 No variable named 'pr_sayhire_suburban' exists in Python memory\",\n",
    "}\n",
    "q3_1_3_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9ea32-a7b2-43bb-8453-15f9eb89ffaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T07:00:13.146654Z",
     "iopub.status.busy": "2025-08-01T07:00:13.146376Z",
     "iopub.status.idle": "2025-08-01T07:00:13.150313Z",
     "shell.execute_reply": "2025-08-01T07:00:13.149931Z",
     "shell.execute_reply.started": "2025-08-01T07:00:13.146638Z"
    }
   },
   "source": [
    "### [Question 3.1.4] Log-Odds $\\rightarrow$ Interpretable Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cefa1-7739-4643-bf88-81addbc95d0d",
   "metadata": {},
   "source": [
    "Answer this question based on what you found in the previous two sub-parts.\n",
    "\n",
    "Say your name is Chad, and you're searching for a job in the Milwaukee metro area. You only have the pieces of information derived above at your disposal, and you're about to fall asleep, so you only have time to perform one job search on [milwaukeejobs.com](https://www.milwaukeejobs.com/). Consider the following two searches, where (as can be seen on [this page](https://www.milwaukeejobs.com/jobs/location) \"Milwaukee\" on this site refers to jobs within the \"official\" urban city limits of Milwaukee proper:\n",
    "\n",
    "* (a) [Jobs with Location = \"Milwaukee\"](https://www.milwaukeejobs.com/j/l-Milwaukee,-WI-jobs-l31.html)\n",
    "* (b) [Jobs with Location $\\neq$ \"Milwaukee\"](https://www.milwaukeejobs.com/jobs/location)\n",
    "\n",
    "Which search would be **more likely** to lead you to an employer who expresses a positive attitude towards hiring? ***(Choose one option by replacing the `\"\"` with the letter for your answer)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a88f4b45-7b3e-4e05-9de5-900f8d33382a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:03:51.651828Z",
     "iopub.status.busy": "2025-08-01T08:03:51.651509Z",
     "iopub.status.idle": "2025-08-01T08:03:51.654830Z",
     "shell.execute_reply": "2025-08-01T08:03:51.654319Z",
     "shell.execute_reply.started": "2025-08-01T08:03:51.651809Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Q3.1.4-response\n",
    "q3_1_4_reponse = \"\" # Replace with \"a\" for option (a), \"b\" for option (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "981255e6-b29b-43f5-99ca-3f9828923223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:06:38.453291Z",
     "iopub.status.busy": "2025-08-01T08:06:38.453018Z",
     "iopub.status.idle": "2025-08-01T08:06:38.457480Z",
     "shell.execute_reply": "2025-08-01T08:06:38.457060Z",
     "shell.execute_reply.started": "2025-08-01T08:06:38.453273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q3_1_4_response defined': \"🔲 No variable named 'q3_1_4_response' exists in Python memory\"}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Q3.1.4-public-tests\n",
    "q3_1_4_public_tests = {\n",
    "    'q3_1_4_response defined': '✅ Passed!' if 'q3_1_4_response' in globals() else \"🔲 No variable named 'q3_1_4_response' exists in Python memory\",\n",
    "}\n",
    "q3_1_4_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57e23c-98f5-418d-873d-636c9c9bfcb7",
   "metadata": {},
   "source": [
    "### [Question 3.1.5] The Pinky-Promise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588982f0-aac8-4922-ba41-84195fc12f40",
   "metadata": {},
   "source": [
    "Do you pinky-promise to at least scroll through the [**\"HW3 Grand Finale\" writeup**](https://jjacobs.me/dsan5650/writeups/abc-cross-prediction/), extending this model to full cross-prediction of attitudes and behaviors?\n",
    "\n",
    "* (a) Yes\n",
    "* (b) Double Yes\n",
    "* (c) Only lowercase yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b598e253-9bd4-4e2e-99a8-44ecebc50176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:42:33.097217Z",
     "iopub.status.busy": "2025-08-01T08:42:33.096969Z",
     "iopub.status.idle": "2025-08-01T08:42:33.101373Z",
     "shell.execute_reply": "2025-08-01T08:42:33.100886Z",
     "shell.execute_reply.started": "2025-08-01T08:42:33.097200Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Q3.1.5-response\n",
    "q3_1_5_response = \"\" # Replace with \"a\" for choice (a), \"b\" for choice (b), \"c\" for choice (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "181fb2b3-af57-431f-8dcf-a053a15bdc6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T08:43:20.881612Z",
     "iopub.status.busy": "2025-08-01T08:43:20.881348Z",
     "iopub.status.idle": "2025-08-01T08:43:20.885719Z",
     "shell.execute_reply": "2025-08-01T08:43:20.885237Z",
     "shell.execute_reply.started": "2025-08-01T08:43:20.881594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q3_1_5_response defined': '✅ Passed!'}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Q3.1.5-public-tests\n",
    "q3_1_5_public_tests = {\n",
    "    'q3_1_5_response defined': '✅ Passed!' if 'q3_1_5_response' in globals() else \"🔲 No variable named 'q3_1_5_response' exists in Python memory\",\n",
    "}\n",
    "q3_1_5_public_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b05657-1605-40cf-89c5-74c08a3be595",
   "metadata": {},
   "source": [
    "Thank you for your patience! And, if it helps, here is the PGM for the full model in the writeup, that I have benevolently spared you from having to write! 😇👼🤗 Though it looks scary at first, you can think about how it could be \"built up\" from the piece of it that you just created in Part 3.1!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/2d66bec8877046fbaac4350bd8295c4c334a8a69/2025-sum-dsan5650/hw3/multilevel_abc.svg\" width=\"60%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90167554-a950-456c-b46d-33ebbb5e6e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01d9377b753d4e139b97a000aef42ec8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "04220ae40fa4437ba98bfd441b5afd5f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_f763d40df0ad4c4f8638fb06ad5296f8",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.60        3            2742.03 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.85        1            2566.96 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.05        3            2343.00 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.86        1            1857.82 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.60        3            2742.03 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.85        1            2566.96 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.05        3            2343.00 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.86        1            1857.82 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "49cc4ead524c4422a16ce078ec2c9159": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_a2565d84fff94915bc2af349c8c563f1",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.53        3            1403.67 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.90        7            1500.42 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.94        3            1426.64 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.88        7            1393.63 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.53        3            1403.67 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.90        7            1500.42 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.94        3            1426.64 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.88        7            1393.63 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "4f2830b77d294244a99d2437c10388ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "610f20843d114aa1b832d51c3e34ea9a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_723c777c1ee544c9a9a0409f8622be4b",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.54        7            1179.98 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.60        7            1128.42 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.54        7            1159.33 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.63        7            1106.70 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.54        7            1179.98 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.60        7            1128.42 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.54        7            1159.33 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.63        7            1106.70 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "61c5de5cc65a4864b4c6dd0e1a32ef5d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_b342c3685d7b4a719f732e9c7ba118a9",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.25        1            2183.32 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.73        1            2221.53 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.95        3            2132.31 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.29        3            1994.33 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.25        1            2183.32 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.73        1            2221.53 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.95        3            2132.31 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.29        3            1994.33 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "68a4e8f7baa9499b80f3298a32d24be9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6a529863b3874624ad97981bafcff219": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f9c7282fb484cdeb1c9b0f8da5732f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "723c777c1ee544c9a9a0409f8622be4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7e841edd90cb409d9e1441a6b049fbba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8062c81d03e04f1495522a7a7056d9f7": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_c1fb3c56c0a14081a437c8178694f466",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.53        3            1450.62 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.90        7            1502.90 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.94        3            1393.42 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.88        7            1430.24 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.53        3            1450.62 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.90        7            1502.90 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.94        3            1393.42 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.88        7            1430.24 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "85a4074c174e4eb286cde2c74491bde2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c155a7ab71c427c994a35f714b0466a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_90dbdcf4113a40dbabab1c3aa8e80229",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.60        3            2749.75 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.85        1            2632.97 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.05        3            2384.07 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.86        1            1887.99 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.60        3            2749.75 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.85        1            2632.97 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.05        3            2384.07 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.86        1            1887.99 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "90dbdcf4113a40dbabab1c3aa8e80229": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "939679bbe502437999d4da314113af31": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_7e841edd90cb409d9e1441a6b049fbba",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.13        3            1852.32 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.64        3            1904.60 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.94        3            1791.22 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.99        7            1636.19 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.13        3            1852.32 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.64        3            1904.60 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.94        3            1791.22 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.99        7            1636.19 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "a2565d84fff94915bc2af349c8c563f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b342c3685d7b4a719f732e9c7ba118a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf0122a783ba4912965597d1a46aa83b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_01d9377b753d4e139b97a000aef42ec8",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.13        3            2059.97 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.64        3            2120.02 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.94        3            2014.28 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.99        7            1839.18 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.13        3            2059.97 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.64        3            2120.02 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.94        3            2014.28 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.99        7            1839.18 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "c130f04928c34ec7909bdea464c3dd1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c1fb3c56c0a14081a437c8178694f466": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c5288f8c38a34762a1d2008ce7c0e667": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_85a4074c174e4eb286cde2c74491bde2",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.25        1            1976.90 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.73        1            2174.66 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.95        3            2049.85 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.29        3            1812.13 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.25        1            1976.90 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.73        1            2174.66 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.95        3            2049.85 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.29        3            1812.13 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "cc2b8f369e164fe1b89df3ca9065c625": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_68a4e8f7baa9499b80f3298a32d24be9",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.25        1            2193.21 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.73        1            2275.86 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.95        3            2105.32 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.29        3            1919.07 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.25        1            2193.21 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.73        1            2275.86 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.95        3            2105.32 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.29        3            1919.07 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "cc6d6b692d1e41ffbebc1803dcac4091": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_c130f04928c34ec7909bdea464c3dd1f",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.60        3            2680.94 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.85        1            2554.71 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.05        3            2313.73 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.86        1            1809.06 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.60        3            2680.94 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.85        1            2554.71 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.05        3            2313.73 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.86        1            1809.06 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "cca280338fd24debb26a397c45fb9209": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce3373662b0d4df6a0b0f010ab883f0c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_6f9c7282fb484cdeb1c9b0f8da5732f1",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.13        3            1876.90 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.64        3            2147.26 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.94        3            1964.18 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.99        7            1697.84 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.13        3            1876.90 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.64        3            2147.26 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.94        3            1964.18 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.99        7            1697.84 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "cf3d95534d154864804fd90d3271a629": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_4f2830b77d294244a99d2437c10388ad",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.60        3            2856.11 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.85        1            2635.88 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.05        3            2436.89 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.86        1            2064.67 draws/s   0:00:00   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.60        3            2856.11 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.85        1            2635.88 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.05        3            2436.89 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.86        1            2064.67 draws/s   0:00:00   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "d48552f6fa6b4588a45cdc5f96b22f21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dc3460ed908c451e9d741472b3703036": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_dd0e748d169947e2a31b4aba98da23af",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.25        1            1971.48 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.73        1            2050.93 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.95        3            2189.56 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.29        3            1792.79 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.25        1            1971.48 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.73        1            2050.93 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.95        3            2189.56 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.29        3            1792.79 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "dd0e748d169947e2a31b4aba98da23af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e316eb8b6cdd4d28904b688cabfdee05": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_d48552f6fa6b4588a45cdc5f96b22f21",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.25        1            1970.86 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.73        1            2031.39 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.95        3            2127.56 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.29        3            1835.60 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.25        1            1970.86 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.73        1            2031.39 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.95        3            2127.56 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.29        3            1835.60 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "ee9851b5ba09433d8b78f38bd35e4a18": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_fa312884e83b4187af857b8c1c21d604",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.54        7            1147.75 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.60        7            1160.19 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.54        7            1179.31 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.63        7            1097.77 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.54        7            1147.75 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.60        7            1160.19 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.54        7            1179.31 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.63        7            1097.77 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "f0c47153d3504f32b321e3e6522a24bd": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_cca280338fd24debb26a397c45fb9209",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.54        7            1168.73 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.60        7            1101.76 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.54        7            1243.67 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.63        7            1141.70 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.54        7            1168.73 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.60        7            1101.76 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.54        7            1243.67 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.63        7            1141.70 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "f273d5aafcb2412bae66e21d82741e35": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_6a529863b3874624ad97981bafcff219",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.25        1            2039.20 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.73        1            2141.81 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.95        3            2088.14 draws/s   0:00:00   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.29        3            1843.03 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n</pre>\n",
          "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.25        1            2039.20 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.73        1            2141.81 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             0.95        3            2088.14 draws/s   0:00:00   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2000    0             1.29        3            1843.03 draws/s   0:00:01   0:00:00    \n                                                                                                                   \n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "f763d40df0ad4c4f8638fb06ad5296f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa312884e83b4187af857b8c1c21d604": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
