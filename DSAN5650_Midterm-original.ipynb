{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ab0682-8305-444c-add0-a6df2e8ef986",
   "metadata": {},
   "source": [
    "## DSAN5650 Midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9d0e3-51a9-4d9d-b004-cd64cdbbe9ec",
   "metadata": {},
   "source": [
    "The following cell just runs an external file called `jupyter_fixes.ipynb`, which should have also been copied into your \"Midterm\" folder -- it applies a few changes that are required e.g. to prevent `matplotlib`'s warning about caching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5ec253-ef00-4573-a9fd-4b36cd7adad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap');\n",
       ".jp-RenderedHTMLCommon {\n",
       "    font-family: \"Roboto\", sans-serif;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run jupyter_fixes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab231d6a-874e-45ab-af5c-cacb26aa0432",
   "metadata": {},
   "source": [
    "## [Part 1: Social Science] Modeling Social Phenomena with PGMs: The Selective Transmission of Historical Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07720a-52e0-452c-8daf-98e230ecbc54",
   "metadata": {},
   "source": [
    "### Loading and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68099833-3037-4629-9780-a2da09f115f7",
   "metadata": {},
   "source": [
    "This question is going to feel a bit \"in the weeds\" at first -- because it is -- but points to the importance of the [library of missing datasets](https://github.com/MimiOnuoha/missing-datasets) which lurks behind any actually-existing dataset you may find! It also relates to Berkson's Paradox, which will be the subject of Part 2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4726bdec-cbc5-4344-89b9-893c0f65a96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import patchworklib as pw;\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884d5d3a-3d61-4f5b-b2f7-fcfd09177d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village_name</th>\n",
       "      <th>published</th>\n",
       "      <th>huguenot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARRAS (ARTOIS)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AURAY, REUNI A VANNES (SEN)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTUN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOULAY, REUNI A SARREGUEMINES</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALAIS</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    village_name  published  huguenot\n",
       "0                 ARRAS (ARTOIS)       True     False\n",
       "1    AURAY, REUNI A VANNES (SEN)       True     False\n",
       "2                          AUTUN       True      True\n",
       "3  BOULAY, REUNI A SARREGUEMINES       True      True\n",
       "4                         CALAIS       True     False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_url = \"https://raw.githubusercontent.com/jpowerj/dsan-content/refs/heads/main/2025-sum-dsan5650/cahiers_official.csv\"\n",
    "pub_df = pd.read_csv(pub_url)\n",
    "pub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487af29-604b-4dfb-aff9-00de366dbd8a",
   "metadata": {},
   "source": [
    "As the following cell shows, there were 32 villages whose *cahiers* were deemed \"exemplary\" of the grievances of France as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612a95db-1caa-469b-a159-b503ee7627b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3cf6b-a21f-4f2f-92b6-9348c5cf4e6f",
   "metadata": {},
   "source": [
    "And, as the following cell makes clear, over 40% of these \"exemplary\" *cahiers* contained grievances about the treatment of French Protestants (Huguenots):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d631506f-18cb-44fd-8782-2b3a511bc1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "huguenot\n",
       "False    0.59375\n",
       "True     0.40625\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_df['huguenot'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2ee93-35bc-4c99-84e9-0e78131bd95d",
   "metadata": {},
   "source": [
    "### [Question 1.1] Modeling the Published Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58506b5b-d016-4a3f-9504-df1abe6faa71",
   "metadata": {},
   "source": [
    "In the following code cell, use PyMC to create a generative model of the published *cahiers* as follows:\n",
    "\n",
    "* First, the model should include a variable `p_hug`, representing the overall probability that a given *cahier* contains a grievance related to treatment of Huguenots\n",
    "* Then, the model should include a *village-specific* variable `huguenot`, a binary variable which has the value 1 for villages whose cahier contains a grievance related to treatment of Huguenots, and 0 for villages whose cahier does not contain such a grievance.\n",
    "\n",
    "`p_hug` and `huguenot` should be **linked** such that the probability of `huguenot` taking the value 1 is exactly `p_hug` -- the included line of code at the end of the cell prints the model as a PGM, where there should be an arrow from the `p_hug` node to the `huguenot` node!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38632595-fa65-490f-be8e-ccc51c6930b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q1.1-response\n",
    "village_idx, village_name = pub_df['village_name'].factorize()\n",
    "hug_values = pub_df['huguenot']\n",
    "coords = {'village': village_idx}\n",
    "with pm.Model(coords=coords) as pub_model:\n",
    "    # Your code here: model the two random variables p_hug and huguenot as\n",
    "    # described above\n",
    "    pass # Remove this pass statement once you've started coding your model!\n",
    "if pub_model is not None:\n",
    "    display(pm.model_to_graphviz(pub_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55928ecd-8cc6-479b-9cf5-30e73547f6a8",
   "metadata": {},
   "source": [
    "### [Question 1.2] Sampling from the Prior Distribution\n",
    "\n",
    "Now, in the following code cell, sample from the **prior predictive** distribution using PyMC's `sample_prior_predictive()` function, storing the result in a variable named `pub_prior_idata`. Once this variable is created correctly, the remaining provided code will construct a Pandas `DataFrame` and plot the distribution of `p_hug`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108b142-c603-4e43-86b4-1abb9a8da7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q1.2-response\n",
    "# Your code here: create a variable pub_prior_idata containing the predictive prior\n",
    "# distribution\n",
    "\n",
    "# Convert to DataFrame\n",
    "pub_prior_df = pub_prior_idata.prior.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "\n",
    "# And plot\n",
    "ax = pw.Brick(figsize=(4, 2.5));\n",
    "sns.histplot(\n",
    "    x=\"p_hug\", data=pub_prior_df, binwidth=0.05, ax=ax\n",
    ");\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f9419-ef50-4744-933e-66e90bc492f3",
   "metadata": {},
   "source": [
    "### Inferring the *Number* of *Cahiers* Containing Huguenot Grievances\n",
    "\n",
    "If the above code worked as intended, the following code cell should just take the `pub_prior_idata` variable you created and use it to infer the **number** of published cahiers (out of the 32 total that were chosen) containing Huguenot grievances (demonstrating how we can use your model to \"jump\" to a more coarse-grained level of \"cahiers corpus\" rather than just individual *cahiers*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa0bf3-a735-4574-8e40-3ce1da88100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q1.2-infer-num-cahiers\n",
    "pub_prior_pred_df = pub_prior_idata.prior_predictive.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "sum_df = pub_prior_pred_df.groupby('draw')['huguenot'].sum().to_frame().reset_index()\n",
    "sum_df.rename(columns={'huguenot': 'num_huguenot'}, inplace=True)\n",
    "true_num_hug = len(pub_df[pub_df['huguenot']])\n",
    "\n",
    "ax = pw.Brick(figsize=(4,2.5));\n",
    "sns.histplot(\n",
    "    x=\"num_huguenot\", data=sum_df, ax=ax,\n",
    "    discrete=True\n",
    ");\n",
    "ax.axvline(x=true_num_hug, ls='dashed', color='black', alpha=0.9);\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79c77f-262e-4b1c-8cb4-08e3c62cf7d7",
   "metadata": {},
   "source": [
    "### [Question 1.3] Sampling from the Posterior Distribution\n",
    "\n",
    "Now, let's **estimate** the model parameters using the actual data! In the following code cell, use `sample()` (rather than `sample_prior_predictive()` to draw the actual Bayesian-optimized parameter values, storing the result in a variable named `pub_post_idata`.\n",
    "\n",
    "If sampled correctly, the plot of the posterior distribution of `p_hug` generated by the included code should be centered around the true value of about 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019765f-5490-4b7f-b708-5fc545832ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q1.3-response\n",
    "# Your code here: use pm.sample() to estimate the *posterior* distribution from\n",
    "# the data in pub_df\n",
    "\n",
    "# Convert to DataFrame\n",
    "pub_post_df = pub_post_idata.posterior.to_dataframe().reset_index()\n",
    "pub_post_df = pub_post_df.groupby('draw')['p_hug'].mean().to_frame()\n",
    "# And plot\n",
    "ax = pw.Brick(figsize=(4, 2.5));\n",
    "sns.kdeplot(\n",
    "    x=\"p_hug\", data=pub_post_df, ax=ax,\n",
    "    fill=True\n",
    ");\n",
    "ax.axvline(x=pub_post_df['p_hug'].mean(), lw=1, ls='dashed', alpha=0.9);\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6934d-2ada-42d3-bbe5-ce76889a43e8",
   "metadata": {},
   "source": [
    "### [Question 1.4] Sampling from the Posterior Predictive Distribution\n",
    "\n",
    "Now, drawing on the example code above which performed this coarse-graining on the **prior** predictive distribution (the code cell titled `Q1.2-infer-num-cahiers`), first use PyMC's `sample_posterior_predictive()` function to sample the model's posterior predictive distribution, then use it to generate a plot of the **posterior predictive** distribution of a variable you should name `num_huguenot`: the estimated **number** of *cahiers* mentioning Huguenot grievances given the learned parameters of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0df3b-2655-40b5-92ef-bf86eb9eade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q1.4-response\n",
    "with pub_model:\n",
    "    pub_post_pred_idata = pm.sample_posterior_predictive(pub_post_idata, random_seed=5650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6eaa8-fc0c-42d5-84b2-179fa6a80e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_post_pred_df = pub_post_pred_idata.posterior_predictive.to_dataframe().reset_index()\n",
    "pub_post_pred_df = pub_post_pred_df[pub_post_pred_df['chain'] == 0].drop(columns=\"chain\")\n",
    "pub_post_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66abbe-52af-4e0b-80a6-f85188ab85b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sum_df = pub_post_pred_df.groupby('draw')['huguenot'].sum().to_frame().reset_index()\n",
    "post_sum_df.rename(columns={'huguenot': 'num_huguenot'}, inplace=True)\n",
    "post_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f853cd6-9913-46ec-aff3-ba589a4581e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_num_hug = len(pub_df[pub_df['huguenot']])\n",
    "\n",
    "ax = pw.Brick(figsize=(4,2.5));\n",
    "sns.histplot(\n",
    "    x=\"num_huguenot\", data=post_sum_df, ax=ax,\n",
    "    discrete=True\n",
    ");\n",
    "ax.axvline(x=true_num_hug, ls='dashed', color='black', alpha=0.9);\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb597a-4291-41e2-8a47-c49b20b25b45",
   "metadata": {},
   "source": [
    "### [Question 1.5] Accounting for Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f23b6e-6ae1-449f-8af4-e56a05615f12",
   "metadata": {},
   "source": [
    "However, this is where **domain knowledge** can come into play. To condense a long story into a nice neat narrative for this exam (since this is not a class about the French Revolution!), here are four quick stylized facts:\n",
    "\n",
    "1. A popular interpretation of the French Revolution argues that it was a \"bourgeois revolution\", meaning that it was in essence the seizure of power by budding capitalists away from the French monarchy.\n",
    "2. For a bunch of reasons (like their connections with rich Germans who had adopted Protestantism centuries earlier), wealthy Huguenots were seen as possible \"replacements\" for the Catholic allies whom French Revolutionaries had alienated (e.g., by nationalizing all Church property and forcing Catholic priests to sign an oath of loyalty to the nation of France over Rome). However, many of them had fled in \n",
    "3. In addition to the ~700,000 Huguenots, there was a mass [influx of ~40,000 Protestants](https://en.wikipedia.org/wiki/Patriottentijd#Aftermath) from the Netherlands, who were also among the wealthy elites of that country.\n",
    "4. There was a guy named [Jean-Paul Rabaut](https://en.wikipedia.org/wiki/Jean-Paul_Rabaut_Saint-%C3%89tienne) who you can think of as a \"spokesman\" for the Huguenot community of France during the crucial first 4 years of the French Revolution (until he was guillotined in 1793). Rabaut put Huguenot rights \"on the agenda\" as the **president** of the French National Assembly in 1790, and more generally could use his power to put Huguenot\n",
    "\n",
    "These four facts put together hopefully help motivate the hypothesis that the French Revolutionaries -- especially those involved in shaping the \"public image\" of the Revolution -- had an interest in **emphasizing the freedom that Protestants now had**. Concretely, this led to the following law passed in December of 1790:\n",
    "\n",
    "> All persons born in a foreign country and descending in any degree of a French man or woman **expatriated for religious reasons** are declared French nationals (naturels français) and will benefit from rights attached to that quality if they come back to France, establish their domicile there and take the civic oath.\n",
    "\n",
    "And so, the hypothesis just becomes that: the same collection of people who organized around Huguenot rights to push laws like this into being, also pushed to ensure that **narratives of the French Revolution** such as those **embodied in document collections** would emphasize the Huguenot struggle as much as possible.\n",
    "\n",
    "Given all this, your job in this part is to **model the possible bias in representation** arising from this push: rather than modeling the distribution $\\Pr(\\textsf{Huguenot})$ as **independent of** the distribution $\\Pr(\\textsf{Published})$, you should now model an **inflation factor** representing **how much the proportion of *published cahiers* mentioning Huguenots was inflated (or deflated!) relative to the total collection of *cahiers*.**\n",
    "\n",
    "In other words, your new model should have a variable named `p_pub_nohug` representing the probability of a *cahier* being published given that it does **not** contain a Huguenot-related grievance, and a variable named `p_pub_hug` representing the probability of a *cahier* that **does** contain a Huguenot-related grievance is published. (If it helps, think about the HW2C problem where you estimated disaster rates before and after a given **change point** -- this problem should be a bit less complex than that, since you don't need to estimate a changepoint in this case, just two separate $\\Pr(\\textsf{Publish})$ distributions!)\n",
    "\n",
    "Run the following code cell to load the data for **all** villages, then (a) use the prior-predictive distribution to generate plots of `p_pub_nohug` and `p_pub_hug`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc3d5f-723c-4726-911c-9d88a4e02431",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_url = \"https://raw.githubusercontent.com/jpowerj/dsan-content/refs/heads/main/2025-sum-dsan5650/cahiers_all.csv\"\n",
    "full_df = pd.read_csv(full_url)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69518224-17ca-40b1-9d9b-c9aa60e0ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c82d1-8e01-4e6f-9622-693aeb8d35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hug_values = full_df['huguenot']\n",
    "pub_values = full_df['published']\n",
    "village_idx, village_names = full_df['village_name'].factorize()\n",
    "coords = {'village': village_idx}\n",
    "with pm.Model(coords=coords) as infl_model:\n",
    "    # Your code here: model the probability of publication p_pub *with* and\n",
    "    # *without* a Huguenot-related grievance, as described above!\n",
    "    pass # Remove this pass statement once you've started coding your model!\n",
    "if infl_model is not None:\n",
    "    display(pm.model_to_graphviz(infl_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b8727-f926-4161-80a5-e214fccc93c2",
   "metadata": {},
   "source": [
    "### [Question 1.6] The Prior Predictive Distribution for `p_pub_nohug` and `p_pub_hug`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a1a16-8124-4832-8115-a83264c73382",
   "metadata": {},
   "source": [
    "As in the published-only case from earlier, derive and plot the prior predictive distributions for these two parameters here. Name the derived prior data `infl_prior_idata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f1456-4664-4a84-b3bb-2177fd8d3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: store the prior data for the model as infl_prior_idata\n",
    "\n",
    "# Convert to DataFrame\n",
    "infl_prior_df = infl_prior_idata.prior.to_dataframe().reset_index().drop(columns='chain')\n",
    "# Melt DataFrame to plot both p_pub_nohug and p_pub_hug within the same plot\n",
    "infl_long_df = infl_prior_df[['draw','village','p_pub_nohug','p_pub_hug']].melt(id_vars=['draw','village'])\n",
    "# And plot\n",
    "ax = pw.Brick(figsize=(4, 2.5));\n",
    "sns.kdeplot(\n",
    "    x=\"value\", hue=\"variable\", data=infl_long_df, ax=ax,\n",
    "    fill=True, bw_adjust=2,\n",
    ");\n",
    "ax.axvline(x=infl_prior_df['p_hug'].mean(), lw=1, ls='dashed', alpha=0.9);\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6ee05-8fab-4b73-9e07-83fc04b8c3a2",
   "metadata": {},
   "source": [
    "### [Question 1.7] The Posterior Distribution\n",
    "\n",
    "You made it to the final step! Here, use PyMC's `sample()` function to estimate the **posterior** distribution from the data in `full_df` loaded above, storing it in a variable named `infl_post_idata`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69b388-2c37-41a6-9972-d6527ea7662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q1.7-response\n",
    "# Your code here: estimate the *posterior* and store it in a variable named\n",
    "# infl_post_idata\n",
    "\n",
    "# Convert to DataFrame\n",
    "infl_post_df = infl_post_idata.posterior.to_dataframe().reset_index()\n",
    "# Extract only the first chain\n",
    "infl_post_df = infl_post_df[infl_post_df['chain'] == 0]\n",
    "# Melt as before\n",
    "infl_post_long_df = infl_post_df[['draw','village','p_pub_nohug','p_pub_hug']].melt(id_vars=['draw','village'])\n",
    "# And plot!\n",
    "ax = pw.Brick(figsize=(4, 2.5));\n",
    "sns.kdeplot(\n",
    "    x=\"value\", hue=\"variable\", data=infl_post_long_df, ax=ax,\n",
    "    fill=True, bw_adjust=2,\n",
    ");\n",
    "ax.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77f7a6-ae84-4e5b-9ccd-b1a8956fe3ce",
   "metadata": {},
   "source": [
    "## [Part 2: Causality] Identifying and Blocking Backdoor Paths I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab12e85-c1f2-461c-a342-f96520025507",
   "metadata": {},
   "source": [
    "### The PGM $\\mathcal{G}_1$\n",
    "\n",
    "For the context of this part, assume that you are a researcher studying the relationship between $X$ and $Y$. Your ultimate goal is to estimate the **direct effect** of $X$ on $Y$, but you've identified two possible **confounders** $Z_1$ and $Z_2$ that may impact the direct effect you're hoping to estimate (since the **total effect** of $X$ on $Y$, which you can estimate via e.g. regression, will be the **sum** of the direct effect $X \\rightarrow Y$ and any indirect effects \"flowing\" through other paths from $X$ to $Y$).\n",
    "\n",
    "For Questions 2.1 through 2.5, assume that you've modeled the relationships among the four variables via the following PGM $\\mathcal{G}_1$:\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/311db9ef8099d0d530693cda59eab127b0b87b57/2025-sum-dsan5650/pgm_1.svg\" width=\"60%\"></img>\n",
    "<figcaption><i>The PGM $\\mathcal{G}_1$ (for Questions 2.1-2.5)</i></figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9da8eb-0abc-4ca7-b67c-7d74f821f17e",
   "metadata": {},
   "source": [
    "### [Question 2.1]\n",
    "\n",
    "$\\mathcal{G}_1$ has two paths from $X$ to $Y$, listed below. Which of them are **backdoor paths** from $X$ to $Y$? *(Check all that apply)*\n",
    "\n",
    "* (a) $X \\rightarrow Y$\n",
    "* (b) $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e4b6e-b674-4be0-98ac-d3fc2a45d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.1-response\n",
    "q2_1a_response = False # Replace with True to \"check\" option (a)\n",
    "q2_1b_response = False # Replace with True to \"check\" option (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681e4bc-6c5b-4999-b02f-73e347a917dc",
   "metadata": {},
   "source": [
    "### [Question 2.2]\n",
    "\n",
    "With respect to the triple $X \\leftarrow Z_1 \\rightarrow Z_2$ within $\\mathcal{G}_1$, the node $Z_1$ is a... *(Select one option)*\n",
    "\n",
    "* (a) Fork\n",
    "* (b) Pipe\n",
    "* (c) Collider\n",
    "* (d) Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99e726-78aa-43d2-9385-da39a076683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.2-response\n",
    "q2_2_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f93f2-67eb-43cf-a43a-7dce8be732bd",
   "metadata": {},
   "source": [
    "### [Question 2.3]\n",
    "\n",
    "With respect to the triple $Z_1 \\rightarrow Z_2 \\rightarrow Y$ within $\\mathcal{G}_1$, the node $Z_2$ is a... *(Select one option)*\n",
    "\n",
    "* (a) Fork\n",
    "* (b) Pipe\n",
    "* (c) Collider\n",
    "* (d) Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb65b9-2276-4f06-8e71-e175fde20072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.3-response\n",
    "q2_3_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d54f8-32ce-45d0-81a1-8f81a9a5ca1a",
   "metadata": {},
   "source": [
    "### [Question 2.4]\n",
    "\n",
    "Conditioning on $Z_1$ in $\\mathcal{G}_1$ will... *(Select one option)*\n",
    "\n",
    "* (a) Fully close the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (b) Fully open the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (c) Reduce the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%\n",
    "* (d) Increase the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b55c72-5b6d-493a-b36c-8e81ad1af05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.4-response\n",
    "q2_4_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b4277-08f6-48bd-8275-2da364f65896",
   "metadata": {},
   "source": [
    "### [Question 2.5]\n",
    "\n",
    "Conditioning on $Z_2$ in $\\mathcal{G}_1$ will... *(Select one option)*\n",
    "\n",
    "* (a) Fully close the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (b) Fully open the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (c) Reduce the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%\n",
    "* (d) Increase the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668677f-4ff3-4602-b8c8-c5843f501764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.5-response\n",
    "q2_5_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730c7dd-62e5-4435-a82d-999cb243751f",
   "metadata": {},
   "source": [
    "### The PGM $\\mathcal{G}_2$\n",
    "\n",
    "For Questions 2.6 and 2.7, refer to the following PGM $\\mathcal{G}_2$. Assume that the **correlation coefficient** between $Z_1$ and $A$ is **0.7** (i.e., if we know the value of $Z_1$, we can predict the value of $A$ with 70% accuracy, and vice-versa)\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/311db9ef8099d0d530693cda59eab127b0b87b57/2025-sum-dsan5650/pgm_2.svg\" width=\"60%\"></img>\n",
    "<figcaption><i>The PGM $\\mathcal{G}_2$ (for Questions 2.6 and 2.7)</i></figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84317885-c98f-4caa-95b2-0089131e9f57",
   "metadata": {},
   "source": [
    "### [Question 2.6]\n",
    "\n",
    "With respect to the triple $X \\leftarrow Z_1 \\rightarrow Z_2$ within $\\mathcal{G}_2$, the node $A$ is a... *(Select one option)*\n",
    "\n",
    "* (a) Fork\n",
    "* (b) Pipe\n",
    "* (c) Collider\n",
    "* (d) Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062b3ff-9cda-45ee-bc21-c78acda632a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.6-response\n",
    "q2_6_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87c41d-57bb-45e5-bb5d-fb80a6d076ff",
   "metadata": {},
   "source": [
    "### [Question 2.7]\n",
    "\n",
    "Conditioning on $A$ in $\\mathcal{G}_2$ will... *(Select one option)*\n",
    "\n",
    "* (a) Fully close the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (b) Fully open the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (c) Reduce the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%\n",
    "* (d) Increase the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12756e1b-e08d-40ad-9084-89ec70abe9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.7-response\n",
    "q2_7_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a311670-30e7-4c6a-9ccc-98ad0840d992",
   "metadata": {},
   "source": [
    "### The PGM $\\mathcal{G}_3$\n",
    "\n",
    "For Questions 2.8 and 2.9, refer to the following PGM $\\mathcal{G}_3$ (which is the same as $\\mathcal{G}_1$, but where the arrow between $Z_2$ and $Y$ has reversed direction!)\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/311db9ef8099d0d530693cda59eab127b0b87b57/2025-sum-dsan5650/pgm_3.svg\" width=\"60%\"></img>\n",
    "<figcaption><i>The PGM $\\mathcal{G}_3$ (for Questions 2.8 and 2.9)</i></figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2401e-0d05-46ea-9d49-971be5bb3a07",
   "metadata": {},
   "source": [
    "### [Question 2.8]\n",
    "\n",
    "With respect to the triple $Z_1 \\rightarrow Z_2 \\leftarrow Y$ within $\\mathcal{G}_3$, the node $Z_2$ is a... *(Select one option)*\n",
    "\n",
    "* (a) Fork\n",
    "* (b) Pipe\n",
    "* (c) Collider\n",
    "* (d) Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fa3f7-80fe-47d0-ba46-5402e2fd1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.8-response\n",
    "q2_8_response = \"\" # Replace with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846c49e-2c78-49f5-9fbd-520f3bce826c",
   "metadata": {},
   "source": [
    "### [Question 2.9]\n",
    "\n",
    "Conditioning on $Z_2$ in $\\mathcal{G}_3$ will... *(Select one option)*\n",
    "\n",
    "* (a) Fully close the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (b) Fully open the path $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$\n",
    "* (c) Reduce the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%\n",
    "* (d) Increase the indirect effect of $X$ on $Y$ by way of $X \\leftarrow Z_1 \\rightarrow Z_2 \\rightarrow Y$ by 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274218f-ab99-4eef-b1a7-c6916ba04ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q2.9-response\n",
    "q2_9_response = \"\" # Replae with e.g. \"a\" for option (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1e511-6486-47a3-9053-c7121984cc14",
   "metadata": {},
   "source": [
    "## [Part 3: Causality] One Observed Distribution, Three Possible DGPs\n",
    "\n",
    "In this question, we first simulate the outcomes from three different DGPs. Your task is then to implement them as fully-fledged PyMC models, so that you can obtain **causal** effects using PyMC's `do()` function, rather than just the **conditional** effects that the basic simulations provide.\n",
    "\n",
    "So, run through the following code cells, making sure you understand the workings of each DGP before you start on the cell titled `Q3.1a-response` below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad545d8-aca8-45a5-88da-1ac598d8054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=5650)\n",
    "import matplotlib.pyplot as plt\n",
    "import patchworklib as pw\n",
    "import seaborn as sns\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "N = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa6fbb-02ab-4944-b28b-b4a65f441c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T18:26:14.936337Z",
     "iopub.status.busy": "2025-07-02T18:26:14.936098Z",
     "iopub.status.idle": "2025-07-02T18:26:14.939124Z",
     "shell.execute_reply": "2025-07-02T18:26:14.938683Z",
     "shell.execute_reply.started": "2025-07-02T18:26:14.936319Z"
    }
   },
   "source": [
    "### DGP 1\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/824a359a5758eeaae925a3fabe213139c18008e3/2025-sum-dsan5650/dgp_1.svg\" width=\"30%\"></img>\n",
    "<figcaption><i>Graphical representation of the DGP $\\mathcal{P}_1$ for Part 3</i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th align=\"center\" colspan=\"4\">The DGP $\\mathcal{P}_1$ for Part 3</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>Step</th>\n",
    "    <th colspan=\"3\">Operation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td>$X$</td>\n",
    "    <td>$\\sim$</td>\n",
    "    <td>$\\mathcal{N}(0, 1)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>$Y$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$X + 1 + \\sqrt{3} \\cdot \\varepsilon_Y$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "where $\\varepsilon_Y \\sim \\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7294e-916e-4229-aeae-a83f7c8316d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dgp_result(df):\n",
    "    ax = pw.Brick(figsize=(3, 3));\n",
    "    sns.kdeplot(\n",
    "        x=\"x\", y=\"y\", fill=True, data=df, ax=ax,\n",
    "        levels=10, cmap=\"viridis\", bw_adjust=2\n",
    "    );\n",
    "    ax.set_xlim(-3.5, 3.5);\n",
    "    ax.set_ylim(-6, 8);\n",
    "    return ax\n",
    "\n",
    "# Run DGP\n",
    "x = rng.normal(size=N)\n",
    "y_noise = rng.normal(size=N)\n",
    "y = x + 1 + np.sqrt(3) * y_noise\n",
    "# Collect results into a DataFrame\n",
    "df1 = pd.DataFrame({'x': x, 'y': y, 'dgp': 1})\n",
    "# And plot\n",
    "ax1 = plot_dgp_result(df1)\n",
    "ax1.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf67a0-1c02-4dcc-8caf-c1690b0da97f",
   "metadata": {},
   "source": [
    "### DGP 2\n",
    "\n",
    "In the second DGP, $Y$ is generated first, then $X$ is derived from $Y$:\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/824a359a5758eeaae925a3fabe213139c18008e3/2025-sum-dsan5650/dgp_2.svg\" width=\"30%\"></img>\n",
    "<figcaption><i>Graphical representation of the DGP $\\mathcal{P}_2$ for Part 3</i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th align=\"center\" colspan=\"4\">The DGP $\\mathcal{P}_2$ for Part 3</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>Step</th>\n",
    "    <th colspan=\"3\">Operation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td>$Y$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$\\mathcal{N}(1, 2)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>$X$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$\\frac{Y - 1}{4} + \\frac{\\sqrt{3}}{2} \\cdot \\varepsilon_X$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "where $\\varepsilon_X \\sim \\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487909c4-b925-4bc8-8f97-869633efe25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X and Y\n",
    "y = rng.normal(1, 2, size=N)\n",
    "x_noise = rng.normal(size=N)\n",
    "x = (y - 1) / 4 + np.sqrt(3) * x_noise / 2\n",
    "# Collect into a DataFrame\n",
    "df2 = pd.DataFrame({'x': x, 'y': y, 'dgp': 2})\n",
    "# And plot\n",
    "ax2 = plot_dgp_result(df2)\n",
    "ax2.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ece04-ba12-4d41-adf1-116d0ea5348b",
   "metadata": {},
   "source": [
    "### DGP 3\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/824a359a5758eeaae925a3fabe213139c18008e3/2025-sum-dsan5650/dgp_3.svg\" width=\"30%\"></img>\n",
    "<figcaption><i>Graphical representation of the DGP $\\mathcal{P}_3$ for Part 3</i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th align=\"center\" colspan=\"4\">The DGP $\\mathcal{P}_3$ for Part 3</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>Step</th>\n",
    "    <th colspan=\"3\">Operation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td>$Z$</td>\n",
    "    <td>$\\sim$</td>\n",
    "    <td>$\\mathcal{N}(0, 1)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>$X$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$Z$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>3.</td>\n",
    "    <td>$Y$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$Z + 1 + \\sqrt{3} \\cdot \\varepsilon_Y$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "where $\\varepsilon_Y \\sim \\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903c1a1-774f-458f-a43d-698d6bd2bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DGP3\n",
    "z = rng.normal(size=N)\n",
    "x = z\n",
    "y = z + 1 + np.sqrt(3) * rng.normal(size=N)\n",
    "# Collect into a DataFrame\n",
    "df3 = pd.DataFrame({'x': x, 'y': y, 'z': z, 'dgp': 3})\n",
    "# And plot\n",
    "ax3 = plot_dgp_result(df3)\n",
    "ax3.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d642b-7e37-4bbb-a97e-90a75339fe67",
   "metadata": {},
   "source": [
    "### Plotted Side-By-Side\n",
    "\n",
    "The problem for us as [social] scientists, and the reason why we need to delve into the $\\textsf{do}()$ operator, is because all three of these DGPs -- despite their very different **causal** underpinnings! -- result in exactly the same **observed** joint distribution $\\Pr(X, Y)$, as we can see if we plot them side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a92a9-f41a-4eaa-9a18-68536f093577",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_all = ax1 | ax2 | ax3;\n",
    "ax_all.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f483dd-882c-4df7-9f7e-7764ffb206d7",
   "metadata": {},
   "source": [
    "### Conditional Distributions\n",
    "\n",
    "Now let's say we observe $X = 2$. Let's see, for each distribution, whether simply **conditioning on** this observation gives us the resulting **causal** impact of $X$ taking on the value 2!\n",
    "\n",
    "Unfortunately, since $X$ is a continuous distribution, we won't get any observations by \"scooping out\" only rows with $X$ exactly equal to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde05d0-d83a-4515-879f-d093f60f130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['x'] == 2.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347888f-6ad0-40a2-b1a2-2dad4e87abbf",
   "metadata": {},
   "source": [
    "So, instead, we'll define an \"epsilon ball\" $\\varepsilon = 0.05$, and \"scoop out\" rows where $X$ is within $\\epsilon$ of 2, for each of our three DGPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958002a-a373-4a0d-b4a4-09124d956c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.05\n",
    "df1_obs = df1[(2.0 - eps < df1['x']) & (df1['x'] < 2.0 + eps)].copy()\n",
    "df2_obs = df2[(2.0 - eps < df2['x']) & (df2['x'] < 2.0 + eps)].copy()\n",
    "df3_obs = df3[(2.0 - eps < df3['x']) & (df3['x'] < 2.0 + eps)].copy()\n",
    "ax1o = plot_dgp_result(df1_obs);\n",
    "ax2o = plot_dgp_result(df2_obs);\n",
    "ax3o = plot_dgp_result(df3_obs);\n",
    "axo = ax1o | ax2o | ax3o;\n",
    "axo.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917adfc1-a86e-4672-9c1c-189ac909a7ea",
   "metadata": {},
   "source": [
    "This way of plotting helps to remind us that the joint distribution evaluated at $x \\approx 2$, $f_{X,Y}(2, y)$, corresponds to a vertical \"slice\" from the full joint distribution $f_{X,Y}(x, y)$, but it isn't very helpful otherwise.\n",
    "\n",
    "Instead, let's plot the **marginal** distribution $f_{Y}(y \\mid x \\approx 2)$ on its own (keeping in mind that, since we've **observed** $X$, the $x$-axis here represents possible values of $Y$ in the distribution! In other words, we're plotting the vertical \"slice\" from the above plot, but rotated 90° left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac0206-5f75-4fb9-a944-22ab23299f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df1, df2, df3])\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e483cae-3fd1-48c1-b82f-592f80c908c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_all = pw.Brick(figsize=(3.5, 2.25));\n",
    "sns.kdeplot(\n",
    "    x=\"y\", hue=\"dgp\", data=df_all, ax=axo_all, bw_adjust=2\n",
    ");\n",
    "axo_all.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5cb6c-1244-4c68-8173-386eb2cbc19d",
   "metadata": {},
   "source": [
    "However, **we know something is wrong here**, in terms of capturing **causal** effects! We know, in particular, that \"forcing\" the value of $X$ to be 2 in $\\mathcal{P}_1$ **should have a causal impact on $Y$**, which is not true of $\\mathcal{P}_2$ or $\\mathcal{P}_3$ where $X$ and $Y$ are independent.\n",
    "\n",
    "So, your job is now to **use PyMC to implement these three DGPs as generative models**, then use PyMC's `do()` operator to obtain the **actual causal effect** that $X$ being forced to have the value 2 should have on $Y$, in terms of the conditional distribution $f_{Y}(y \\mid x = 2)$, for each DGP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626d355-be75-40a6-9508-4a0ef1f7dd1a",
   "metadata": {},
   "source": [
    "### [Question 3.1a] $\\mathcal{P}_1$ as a PyMC Model\n",
    "\n",
    "As a reminder, the graphical representation of $\\mathcal{P}_1$, along with its steps, are as follows:\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th align=\"center\" colspan=\"4\">The DGP $\\mathcal{P}_1$ for Part 3</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>Step</th>\n",
    "    <th colspan=\"3\">Operation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td>$X$</td>\n",
    "    <td>$\\sim$</td>\n",
    "    <td>$\\mathcal{N}(0, 1)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>$Y$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$X + 1 + \\sqrt{3} \\cdot \\varepsilon_Y$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "where $\\varepsilon_Y \\sim \\mathcal{N}(0, 1)$.\n",
    "\n",
    "Implement this DGP as a PyMC model named `dgp1` in the following cell (where the code we've included at the end will display your DGP as a PGM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50722bcd-573e-4fc0-8965-ccd984cc58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.1a-response\n",
    "with pm.Model() as dgp1:\n",
    "    # Your code here: implement a model linking variables named x,\n",
    "    # y_noise (for the random noise term epsilon in Step 2), and y\n",
    "    pass # Remove this pass statement once you've started coding your model!\n",
    "\n",
    "# Once your model is defined, the following lines will display the DGP as a PGM:\n",
    "if dgp1 is not None:\n",
    "    display(pm.model_to_graphviz(dgp1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751c959-7953-416c-8d03-625b36e8594f",
   "metadata": {},
   "source": [
    "### [Question 3.1b] Prior Predictive Distribution for $\\mathcal{P}_1$\n",
    "\n",
    "Now, in the following cell, use the `sample_prior_predictive()` function from PyMC to draw a sample from `dgp1`, calling the resulting InferenceData object `dgp1_idata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faa089-9d4f-4747-bb22-d139157f9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.1b-response\n",
    "# Your code here: create a dgp1_idata variable containing the predictive prior\n",
    "# distribution as derived from the dgp1 model from Question 3.1a\n",
    "\n",
    "# The following lines will convert your sample into a Pandas DataFrame, then\n",
    "# print the first five rows (so you can check that the result looks as expected)\n",
    "dgp1_df = dgp1_idata.prior.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "dgp1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09722f2-3676-4c6a-8b3e-5bdd95b29ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1_pymc = plot_dgp_result(dgp1_df)\n",
    "ax1_pymc.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded729a-922f-4e26-8274-a3cae1fbba84",
   "metadata": {},
   "source": [
    "### [Question 3.2a] $\\mathcal{P}_2$ as a PyMC Model\n",
    "\n",
    "As a reminder, the graphical representation of $\\mathcal{P}_2$, along with its steps, are as follows:\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/824a359a5758eeaae925a3fabe213139c18008e3/2025-sum-dsan5650/dgp_2.svg\" width=\"30%\"></img>\n",
    "<figcaption><i>Graphical representation of the DGP $\\mathcal{P}_2$ for Part 3</i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th align=\"center\" colspan=\"4\">The DGP $\\mathcal{P}_2$ for Part 3</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>Step</th>\n",
    "    <th colspan=\"3\">Operation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td align=\"center\">$Y$</td>\n",
    "    <td align=\"center\">$\\sim$</td>\n",
    "    <td>$\\mathcal{N}(1, 2)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>$X$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$\\frac{Y - 1}{4} + \\frac{\\sqrt{3}}{2} \\cdot \\varepsilon_X$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "where $\\varepsilon_X \\sim \\mathcal{N}(0, 1)$.\n",
    "\n",
    "\n",
    "Implement this DGP as a PyMC model named `dgp2` in the following cell (where the code we've included at the end will display your DGP as a PGM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5584a8e-7470-4060-aa29-b31a8275b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.2a-response\n",
    "with pm.Model() as dgp2:\n",
    "    # Your code here: implement a model linking variables named y, x, and\n",
    "    # x_noise (for the random noise term epsilon in Step 2)\n",
    "    pass # Remove this pass statement once you've started coding your model!\n",
    "\n",
    "if dgp2 is not None:\n",
    "    display(pm.model_to_graphviz(dgp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01656f-131d-4571-9383-cf7061c48a35",
   "metadata": {},
   "source": [
    "### [Question 3.2b] Prior Predictive Distribution for $\\mathcal{P}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef248a6-a4a9-4424-88bc-2508205c18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.2b-response\n",
    "# Your code here: create a dgp1_idata variable containing the predictive prior\n",
    "# distribution as derived from the dgp2 model from Question 3.2a\n",
    "\n",
    "# The following lines will convert your sample into a Pandas DataFrame, then\n",
    "# print the first five rows (so you can check that the result looks as expected)\n",
    "dgp2_df = dgp2_idata.prior.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "dgp2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a6a6b-bda8-4c61-b85c-4e83b2bf11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2_pymc = plot_dgp_result(dgp2_df)\n",
    "ax2_pymc.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c92747-9e66-4fad-8299-c20c6c6e0c49",
   "metadata": {},
   "source": [
    "### [Question 3.3a] $\\mathcal{P}_3$ as a PyMC Model\n",
    "\n",
    "As a reminder, the graphical representation of $\\mathcal{P}_3$, along with its steps, are as follows:\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/jpowerj/dsan-content/824a359a5758eeaae925a3fabe213139c18008e3/2025-sum-dsan5650/dgp_3.svg\" width=\"30%\"></img>\n",
    "<figcaption><i>Graphical representation of the DGP $\\mathcal{P}_3$ for Part 3</i></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th align=\"center\" colspan=\"4\">The DGP $\\mathcal{P}_3$ for Part 3</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>Step</th>\n",
    "    <th colspan=\"3\">Operation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td>1.</td>\n",
    "    <td>$Z$</td>\n",
    "    <td>$\\sim$</td>\n",
    "    <td>$\\mathcal{N}(0, 1)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2.</td>\n",
    "    <td>$X$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$Z$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>3.</td>\n",
    "    <td>$Y$</td>\n",
    "    <td>$\\leftarrow$</td>\n",
    "    <td>$Z + 1 + \\sqrt{3} \\cdot \\varepsilon_Y$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "where $\\varepsilon_Y \\sim \\mathcal{N}(0, 1)$.\n",
    "\n",
    "\n",
    "Implement this DGP as a PyMC model named `dgp3` in the following cell (where the code we've included at the end will display your DGP as a PGM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48388a-3be7-4de7-b080-29ff01422104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.3a-response\n",
    "with pm.Model() as dgp3:\n",
    "    # Your code here: implement a model linking variables named z, x, y, and\n",
    "    # y_noise (for the random noise term epsilon in Step 3)\n",
    "    pass # Remove this pass statement once you've started coding your model!\n",
    "    \n",
    "if dgp3 is not None:\n",
    "    display(pm.model_to_graphviz(dgp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119dfc41-5620-4ae8-9765-36d67d5699d9",
   "metadata": {},
   "source": [
    "### [Question 3.3b] Prior Predictive Distribution for $\\mathcal{P}_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab4d28-f312-4445-8b45-d39981a80ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.3b-response\n",
    "# Your code here: create a dgp3_idata variable containing the predictive prior\n",
    "# distribution as derived from the dgp3 model from Question 3.3a\n",
    "\n",
    "# The following lines will convert your sample into a Pandas DataFrame, then\n",
    "# print the first five rows (so you can check that the result looks as expected)\n",
    "dgp3_df = dgp3_idata.prior.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "dgp3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4e7fb-8710-45f2-b4ab-57a6f82b377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.3b-plot\n",
    "ax3_pymc = plot_dgp_result(dgp3_df)\n",
    "ax3_pymc.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783468e0-67de-41f6-b9d0-089393e3eeba",
   "metadata": {},
   "source": [
    "### Side-By-Side Plots\n",
    "\n",
    "Once you've implemented all three models in PyMC, run the following code cell to display the three joint distributions side-by-side. As in the beginning of the problem, you should find that they're nearly identical (besides some variation due to randomness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b1d32-46b8-4ae7-a643-97c09fbff481",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_all_pymc = ax1_pymc | ax2_pymc | ax3_pymc;\n",
    "ax_all_pymc.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae56de3-e17b-4cba-b83a-7ddf09b6f5c4",
   "metadata": {},
   "source": [
    "### [Question 3.4] Using the `do()` Operator\n",
    "\n",
    "Now, in the following code cell, create three new models `dgp1_do`, `dgp2_do`, and `dgp3_do`, where for each you use PyMC's implementation of `do()` (imported for you at the top of the code cell) to **force** the value of `x` in each to be exactly 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409dc042-f1b8-41b1-a2c9-3d90f73c096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.4-response\n",
    "from pymc.model.transform.conditioning import do\n",
    "# DGP 1\n",
    "dgp1_do = None # Your code here: replace with new model using do()\n",
    "if dgp1_do is not None:\n",
    "    print(\"dgp1_do:\")\n",
    "    display(pm.model_to_graphviz(dgp1_do))\n",
    "# DGP 2\n",
    "dgp2_do = None # Your code here: replace with new model using do()\n",
    "if dgp2_do is not None:\n",
    "    print(\"dgp2_do:\")\n",
    "    display(pm.model_to_graphviz(dgp2_do))\n",
    "# DGP 3\n",
    "dgp3_do = None # Your code here: replace with new model using do()\n",
    "if dgp3_do is not None:\n",
    "    print(\"dgp3_do:\")\n",
    "    display(pm.model_to_graphviz(dgp3_do))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84a084-7c1a-4d46-b817-7ebf3139a74e",
   "metadata": {},
   "source": [
    "### [Question 3.5] The Post-`do()` Predictive Distributions\n",
    "\n",
    "Now that you have the post-`do()` versions of each model, fill in the missing pieces of the following code cell as indicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3f4ad-1047-4fc5-9fc0-6cc659595443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.5-response\n",
    "# Your code here: create variables dgp1_do, dgp2_do, and dgp3_do containing the\n",
    "# prior predictive distributions for DGPs 1, 2, and 3\n",
    "\n",
    "# The following lines will convert your samples into Pandas DataFrames, then\n",
    "# print the first five rows for each (so you can check that the results looks as\n",
    "# expected)\n",
    "# dgp1_do\n",
    "dgp1_do_df = dgp1_do_idata.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "dgp1_do_df['dgp'] = 1\n",
    "print(\"dgp1_do_df:\")\n",
    "display(dgp1_do_df.head())\n",
    "# dgp2_do\n",
    "dgp2_do_df = dgp2_do_idata.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "dgp2_do_df['dgp'] = 2\n",
    "print(\"dgp2_do_df:\")\n",
    "display(dgp2_do_df.head())\n",
    "# dgp3_do\n",
    "dgp3_do_df = dgp3_do_idata.to_dataframe().reset_index().drop(columns=\"chain\")\n",
    "dgp3_do_df['dgp'] = 3\n",
    "print(\"dgp3_do_df:\")\n",
    "display(dgp3_do_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a59a7-568b-4f95-a85f-66bf7a6e01d9",
   "metadata": {},
   "source": [
    "Once you've derived the three prior predictive distributions, run the following final code cell to plot the three post-`do()` distributions. If it worked successfully, you should see that **$\\mathcal{P}_1$ indeed has a different distribution from $\\mathcal{P}_2$ and $\\mathcal{P}_3$!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dadace-7cb7-4f3f-bbb4-8ed036479bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.5-plot\n",
    "# Combining into a single DataFrame\n",
    "dgp_all_do_df = pd.concat([dgp1_do_df, dgp2_do_df, dgp3_do_df])\n",
    "display(dgp_all_do_df.head())\n",
    "axo_all = pw.Brick(figsize=(3.5, 2.25));\n",
    "sns.kdeplot(\n",
    "    x=\"y\", hue=\"dgp\", data=dgp_all_do_df, ax=axo_all, bw_adjust=2\n",
    ");\n",
    "axo_all.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aab9dd-8a9e-47d7-9bae-15f386783dd6",
   "metadata": {},
   "source": [
    "## You Did It!\n",
    "\n",
    "Congratulations on finishing the Midterm, habibi <3 There is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
