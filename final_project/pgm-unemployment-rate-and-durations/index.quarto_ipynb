{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Causal Inference of Labor Market Inequality Using PGM: A multidimensional analysis of unemployment rate and durations\"\n",
        "author:\n",
        "    name: Mengjia Wei\n",
        "    email: mw1296@georgetown.edu\n",
        "    affiliation: Georgetown University\n",
        "keywords:\n",
        "  - PGM\n",
        "  - Unemployment Rate\n",
        "  - Unemployment Durations\n",
        "  - Causal Inference\n",
        "abstract: |\n",
        "  This study investigates the causal relationships between age, occupation, race, and unemployment rates in the United States, applying probabilistic graphical modeling (PGM) to uncover latent dependency structures across demographic and industry variables. Using a PGM framework, we extend this approach to labor market data by constructing conditional dependence networks across two key dimensions: group attributes (age, race, and industry) and time (2015 - 2024 and 2025). Specifically, the study examines recent college graduates (ages 22–24) relative to older individuals (25+), comparing their unemployment rates by major across 2024 and 2025. A second dimension of analysis focuses on industry-specific unemployment rate dynamics from 2015 to 2025, particularly in [retail], [arts], and [technology] sectors. In addition to rate-based measures, the study explores how unemployment duration has evolved between 2015 and 2025. This analysis seeks to identify whether certain groups—such as Black labor force and [Retail Industry]—face higher or lower unemployment, providing a more comprehensive view of labor market hardship. The model estimates the strength and direction of probabilistic dependencies using Bayesian structure learning algorithms, based on labor force aggregated data from BLS CPS datasets. The results indicate that [conclusion1]. Additionally, the [retail], [arts], and [technology] industries experienced increased unemployment rates between 2015 and 2025, with respective changes of [ ], [ ], and [ ] percentage points. The findings also suggest that, consistent with earlier research, unemployment duration is negatively correlated with the unemployment rate by occupation, with industries exhibiting higher unemployment often associated with shorter average durations (Chien, Y., & Morris, P., 2016). The PGM framework reveals significant interactive effects between race and industry on unemployment, particularly among [e.g., Black or Hispanic workers] in the [e.g., retail or hospitality] sector. These findings contribute to the growing literature that leverages PGMs for social inference (e.g., Li et al., 2022), highlighting the model’s potential for uncovering structural labor inequalities over time and across population subgroups.\n",
        "plain-language-summary: |\n",
        "  TBD\n",
        "key-points:\n",
        "  - TBD\n",
        "  - TBD\n",
        "date: last-modified\n",
        "bibliography: references.bib\n",
        "citation:\n",
        "  container-title: Georgetown Univeristy DSAN 5650 Journal\n",
        "number-sections: true\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The interplay of demographic characteristics and labor market dynamics consistently reveals significant disparities in unemployment rates. Decades of research reveal a persistent relationship between race, gender, and unemployment, evident across diverse economic cycles. Though the Black unemployment rate fell to a historic low of 6.1% in 2019, it was still twice as high as the White unemployment rate of 3.0%, as @ValerieWilson2022 observed. These disparities are further magnified at the intersection of race and gender. For instance, Black men faced a 6.1% unemployment rate in February 2024, notably higher than Black women at 4.4%. Similarly, Hispanic women's unemployment rate increased to 5.0% in February 2024, while Hispanic men experienced a decrease to 4.0% (@Joseph2024). Native American men also experienced higher unemployment (10%) than Native American women (7%) in 2022. Industry-specific analyses similarly highlight divergent unemployment trends. The Leisure and Hospitality sector reported the highest unemployment rate at 6.0% in 2024, an increase from 5.5% in 2023. Similarly, Wholesale and Retail Trade experienced elevated unemployment, reaching 4.7% in October 2024, up from 4.0% in 2023. Conversely, Financial Activities maintained a significantly lower unemployment rate of 1.9% (@Oberlo2024). \n",
        "\n",
        "Research from the U.S. Bureau of Labor Statistics consistently shows longer unemployment spells in sectors such as Manufacturing and Construction, while industries demanding specialized skills like Education and Health Services exhibit shorter durations. Study by @YiLiChienandPaulMorris reveals negative correlation between the unemployment rate and duration. Such variations in both the rate and duration of unemployment underscore complex interactions among race, gender, age, and industry.\n",
        "\n",
        "@TOIEducation2025 published that the labor market for recent college graduates has \"deteriorated noticeably\" in the first quarter of 2025. The unemployment rate for this cohort (ages 22-27) ranged from 5.5% to 7.1%, exceeding the overall national average of 4.1-4.2%, with Anthropology (9.4%), Physics (7.8%), and Computer Engineering (7.5%) showing among the highest rates. \n",
        "\n",
        "![Unemployment Rate of Recent College Graduates](images/unemployment_rate_recent_graduate.png){#fig-graduates}\n",
        "\n",
        "Although the Federal Open Market Committee (FOMC) reported a low overall unemployment rate for June 2025, recent data clearly indicate a noticeable uptick in the unemployment rate for the 22-27 age group since March, reaching 2021 levels and particularly affecting recent college graduates (@fig-graduates). "
      ],
      "id": "589c3c67"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "3d2ab575",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data pre-processing - part1: Merge several unemployment statistics excel files downlaoded from BLS webiste\n",
        "import pandas as pd\n",
        "import os\n",
        "#os.getcwd()\n",
        "\n",
        "def create_df_race(folder_path, demographic_type, id_vars, var_name, value_name):\n",
        "    merged_df = pd.DataFrame()\n",
        "    file_name = [f.removesuffix('.xlsx') for f in os.listdir(os.path.join(\"../data\", folder_path)) if f.endswith('.xlsx')]\n",
        "    for f in file_name:\n",
        "        file_path = os.path.join(\"../data\", folder_path, f + \".xlsx\")    \n",
        "        df = pd.read_excel(file_path)\n",
        "        rows = df[df.iloc[:,0]=='Year'].index[0]+2-1\n",
        "        df = pd.read_excel(file_path, skiprows=rows)\n",
        "        df_long = df.melt(id_vars=id_vars, var_name=var_name, value_name=value_name)\n",
        "        df_long[demographic_type] = f\n",
        "        merged_df = pd.concat([merged_df, df_long], ignore_index=True)\n",
        "    return merged_df\n",
        "\n",
        "folder_path_list = [\"unemployment_rate_by_race\",\n",
        "             \"unemployment_rate_by_sex\",\n",
        "             \"unemployment_rate_by_industry\",\n",
        "             \"unemployment_rate_by_age\",\n",
        "            \"unemployment_rate_by_education_attainment\"]\n",
        "\n",
        "demographic_type_list = ['Race',\n",
        "                    'Sex',\n",
        "                    'Industry',\n",
        "                    'Age',\n",
        "                    'Education_attainment']\n",
        "\n",
        "d_vars=\"Year\"\n",
        "var_name=\"Month\"\n",
        "value_name=\"Unemployment_rate\"\n",
        "\n",
        "df_dic = {}\n",
        "for i in range(0, len(folder_path_list)):\n",
        "    folder_path = folder_path_list[i]\n",
        "    demographic_type=demographic_type_list[i]\n",
        "    merged_df = create_df_race(folder_path, demographic_type, \"Year\", \"Month\", \"Unemployment_rate\")\n",
        "    df_dic[demographic_type] = merged_df\n",
        "\n",
        "#list(df_dic.values())[0]"
      ],
      "id": "f611376c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data pre-processing - part2: Load and process monthly unemployment overall file\n",
        "df_overall = pd.read_excel(\"../data/unemployment_rate_monthly_data.xlsx\", skiprows=11)\n",
        "df_overall_long = df_overall.melt(id_vars=\"Year\", var_name=\"Month\", value_name=\"Unemployment_rate\")"
      ],
      "id": "d12b9112",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tbl-col": true,
        "tbl-center": true
      },
      "source": [
        "#| label: tbl-survey-data\n",
        "#| tbl-cap: BLS June 2025 Labor Force Survey Data\n",
        "\n",
        "# Data pre-processing - part3: Load and process Jun 2025 BLS labor survey data\n",
        "# process the survey data\n",
        "import numpy as np\n",
        "df_survey_jun = pd.read_csv(\"../data/survey_data/jun_2025.csv\")\n",
        "df_survey_jun.columns= [\"sex\",\"education_attainment\",\"race\",\"age\",\"employment_status\",\n",
        "                        \"unmployment_duration\",\"industry\",\"occupation\",\"industry_detailed\",\n",
        "                        \"occupation_detailed\",'geo_code']\n",
        "## create mapping tables to convert the demographic codes to the descriptions\n",
        "sex_mapping = {\n",
        "        1: \"male\",\n",
        "        2: \"female\"\n",
        "}\n",
        "\n",
        "education_attainment_codes = list(np.arange(31,47))\n",
        "education_attainment_values = [\n",
        "        'less_than_high_school',\n",
        "\t\t'less_than_high_school',\n",
        "\t\t'less_than_high_school',\n",
        "        'less_than_high_school',\n",
        "'less_than_high_school',\n",
        "'less_than_high_school',\n",
        "'less_than_high_school',\n",
        "'less_than_high_school',\n",
        "'high_school',\n",
        "'some_college_or_associate_degree',\n",
        "'some_college_or_associate_degree',\n",
        "'some_college_or_associate_degree',\n",
        "'bachelors_degree',\n",
        "'masters_degree',\n",
        "'professional_degree',\n",
        "'doctoral_degree'\n",
        "    ]    \n",
        "education_attainment_mapping=dict(zip(education_attainment_codes,education_attainment_values))\n",
        "\n",
        "race_codes = list(np.arange(1,27))\n",
        "race_values = [\n",
        "        \"white\",\n",
        "        \"black\",\n",
        "        \"other\",\n",
        "        \"asian\"\n",
        "    ] + [\"other\"] * 22\n",
        "race_mapping= dict(zip(race_codes, race_values))\n",
        "\n",
        "\n",
        "employment_status_codes =[\n",
        "        1,2,3,4,5,6,7\n",
        "    ]\n",
        "employment_status_names = [\n",
        "        \"employed\",\n",
        "        \"employed\",\n",
        "        \"unemployed\",\n",
        "        \"unemployed\",\n",
        "        \"not in labor force\",\n",
        "        \"not in labor force\",\n",
        "        \"not in labor force\"\n",
        "    ]\n",
        "employment_status_mapping = dict(zip(employment_status_codes,employment_status_names))\n",
        "\n",
        "industry_codes = list(np.arange(1,15))\n",
        "industry_names = [\n",
        "    \"Agriculture, forestry, fishing, and hunting\",\n",
        "    \"Mining\",\n",
        "    \"Construction\",\n",
        "    \"Manufacturing\",\n",
        "    \"Wholesale and retail trade\",\n",
        "    \"Transportation and utilities\",\n",
        "    \"Information\",\n",
        "    \"Financial activities\",\n",
        "    \"Professional and business services\",\n",
        "    \"Educational and health services\",\n",
        "    \"Leisure and hospitality\",\n",
        "    \"Other services\",\n",
        "    \"Public administration\",\n",
        "    \"Armed Forces\"\n",
        "    ]\n",
        "industry_mapping = dict(zip(industry_codes, industry_names))\n",
        "\n",
        "## Create new columns with decoded names\n",
        "df_survey_jun['sex_name'] = df_survey_jun['sex'].map(sex_mapping)\n",
        "df_survey_jun['race_name'] = df_survey_jun['race'].map(race_mapping)\n",
        "df_survey_jun['education_attainment_name'] = df_survey_jun['education_attainment'].map(education_attainment_mapping)\n",
        "df_survey_jun['employment_status_name'] = df_survey_jun['employment_status'].map(employment_status_mapping)\n",
        "df_survey_jun['industry_name'] = df_survey_jun['industry'].map(industry_mapping)\n",
        "\n",
        "## Filter out industry_name na rows\n",
        "df_survey_jun = df_survey_jun[~df_survey_jun['industry_name'].isna()]\n",
        "\n",
        "## Add columns \"is_black\" and \"unemployment_status\" for the binary model\n",
        "df_survey_jun['is_black_african'] = (df_survey_jun['race_name']=='black').astype(int)\n",
        "\n",
        "## Add column is_asian for the binary model\n",
        "df_survey_jun['is_asian'] = (df_survey_jun['race_name']=='asian').astype(int)\n",
        "\n",
        "## Add column is_asian for the binary model\n",
        "df_survey_jun['is_white'] = (df_survey_jun['race_name']=='white').astype(int)\n",
        "\n",
        "## Add column employment_status for the binary model\n",
        "df_survey_jun['unemployment_status'] = (df_survey_jun['employment_status_name']=='unemployed').astype(int)\n",
        "\n",
        "## Display the table\n",
        "display(df_survey_jun.loc[:,[col for col in df_survey_jun.columns if 'name' in col or col == 'is_black_african'  or col == 'is_white'  or col == 'is_asian']].head(10).style.hide(axis='index'))"
      ],
      "id": "tbl-survey-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data from the U.S. Bureau of Labor Statistics (BLS) June 2025 labor force survey provide individual-level employment status and corresponding demographic information. For the purpose of this study, a subset of these relevant columns is utilized (@tbl-survey-data). \n",
        "\n",
        "\n",
        "## EDA\n",
        "### Unemployment Rates of Differenet Demographics"
      ],
      "id": "80c99203"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot the distributions of unemployment stats of different demographic categories \n",
        "\n",
        "## 1. Plot the umemployment rate distributions by gender, age, industry, education_unattainment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_hist(df_plot, demographic_type):\n",
        "    unique_categories = df_plot[demographic_type].unique()\n",
        "    num_unique_categories = len(unique_categories)\n",
        "    ncol = 3\n",
        "    nrow = np.int64(np.ceil(num_unique_categories/ncol))\n",
        "    fig, axes = plt.subplots(ncols=ncol, nrows=nrow, sharex=True, sharey=True, figsize = (16,nrow*5))\n",
        "    axes = axes.flatten()\n",
        "    min_rate = df_plot['Unemployment_rate'].min()\n",
        "    max_rate = df_plot['Unemployment_rate'].max()\n",
        "    num_bins = 20 \n",
        "    bins = np.linspace(min_rate, max_rate, num_bins + 1)\n",
        "    for i, category in enumerate(unique_categories):\n",
        "        ax = axes[i]\n",
        "        vals = df_plot[df_plot[demographic_type]==category]['Unemployment_rate']\n",
        "        ax.hist(vals, bins=bins, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        ax.axvline(np.mean(vals), color = 'black', linestyle = \"--\")\n",
        "        ax.set_title(category, fontsize=12)\n",
        "        ax.set_xlabel('Unemployment Rate', fontsize=10)\n",
        "        ax.set_ylabel('Count', fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(f'Unemployment Rate Distribution by {demographic_type}', y=1.02, fontsize=18) \n",
        "    plt.show()\n",
        "\n",
        "# Show the graphs except for the last one in order to add the ariticle label to the last grapph\n",
        "for i in range(0, len(df_dic.keys())-1):\n",
        "    df_plot = list(df_dic.values())[i]\n",
        "    demographic_type = list(df_dic.keys())[i]\n",
        "    print(f\"Unemployment Rate Distribution Histograms By {demographic_type}\")\n",
        "    plot_hist(df_plot, demographic_type)\n"
      ],
      "id": "4f89ea33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-histogram-unemployment-rate-demographics\n",
        "#| fig-cap: Unemployment Rate Distributions By Demographics (2015-2025 statistics)\n",
        "#| fig-alt: Histogram plots of the unemployment rate distributins by Age, Sex, Race, Industry and Education Attainment using 2015-2025 BLS data\n",
        "\n",
        "## 2. Plot the overall umemployment rate \n",
        "## Display this graph separately from the preious chuck in order to add the aritcle label\n",
        "df_plot = list(df_dic.values())[len(df_dic.keys())-1]\n",
        "demographic_type = list(df_dic.keys())[len(df_dic.keys())-1]\n",
        "print(f\"Unemployment Rate Distribution Histograms By {demographic_type}\")\n",
        "plot_hist(df_plot, demographic_type)"
      ],
      "id": "fig-histogram-unemployment-rate-demographics",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BLS data from 2015–2025 indicate that the Black or African American population experienced the highest average unemployment rate (7.5%), primarily within the 5–10% range. Gender differences are minimal, with both averaging around 5%, though rates are slightly higher for men. Among industries, Leisure and Hospitality recorded the highest unemployment (10%) with a long-tail distribution, followed by Agriculture (5–11%) and moderate variability. Construction and Mining/Oil & Gas exhibit similar but marginally lower patterns. The 22–24 age group stands out with significantly elevated unemployment—averaging 7% and predominantly above 5%—while other age groups display lower and more uniform rates. Financial Activities show the lowest and most stable unemployment, consistently under 5%. Individuals without a high school diploma face high and variable unemployment, averaging 7% with a long-tail skew. These patterns suggest that young adults (22–24), Black or African Americans without college degrees, and those employed in Leisure, Construction, or Mining sectors are disproportionately affected by higher unemployment. (@fig-histogram-unemployment-rate-demographics)."
      ],
      "id": "e49685e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-histogram-unemployment-rate\n",
        "#| fig-cap: Overall Population Unemployment Rate Distributions (2015-2025 statistics)\n",
        "#| fig-alt: Histogram plot of the overall population unemployment rate distributins using 2015-2025 BLS data\n",
        "min_rate = df_overall_long['Unemployment_rate'].min()\n",
        "max_rate = df_overall_long['Unemployment_rate'].max()\n",
        "num_bins = 20\n",
        "bins = np.linspace(min_rate, max_rate, num_bins)\n",
        "fig, ax = plt.subplots(figsize = (8, 7))\n",
        "ax.hist(df_overall_long['Unemployment_rate'], bins=bins, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax.axvline(np.mean(df_overall_long['Unemployment_rate']), color=\"black\", linestyle=\"--\")\n",
        "ax.set_xlabel(\"Unemployment Rate\", fontsize=10)\n",
        "ax.set_ylabel(\"Count\", fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Population Unemployment Rate\", y =1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "id": "fig-histogram-unemployment-rate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to BLS data from 2015–2025, the overall population unemployment rate averaged slightly above 4%, with the majority of observations concentrated between 2% and 5% and exhibiting relatively low variability (@fig-histogram-unemployment-rate).\n",
        "\n",
        "### Unemployment Rates of Differenet Industries\n",
        "(To be added)\n",
        "\n",
        "## PGM\n",
        "We posit that unemployment vulnerability is driven by structural inequalities within the labor market, particularly those rooted in demographic and industrial dimensions. Demographic disparities are represented by variables such as race, age, and educational attainment and industry; sex is excluded from the analysis due to prior findings indicating minimal impact on unemployment rates. Establishing a baseline unemployment level is a necessary step before assessing the marginal effects of these demographic and industrial factors.\n",
        "\n",
        "### Baseline unemployment rate distribution \n",
        "Figure 3 illustrates that the population unemployment rate is right-skewed, suggesting that the Log-Normal distribution is an appropriate model. We are going to estimate the parameters of a Log-Normal distribution from the population distribution data using MLE. ($\\sigma$, $\\text{loc}$, and $\\text{scale}$)."
      ],
      "id": "6cfb12db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-histogram-lognorm\n",
        "#| fig-cap: Unmployment Rate Histogram vs. Fitted Log-Norm PDF\n",
        "#| fig-alt: Plot the histogram of unemployment rate data and overlay the Probability Density Function (PDF) of the fitted log-norm distribution.\n",
        "\n",
        "# Fit log-norm distribution using population unemployment rate data\n",
        "from scipy.stats import lognorm, kstest, skew \n",
        "\n",
        "## Get the unemployment_rate data that is not NA, convert to array\n",
        "data_to_fit = df_overall_long[~np.isnan(np.array(df_overall_long['Unemployment_rate']))]['Unemployment_rate']\n",
        "\n",
        "sigma_fit, loc_fit, scale_fit = lognorm.fit(data_to_fit) # Fit log-normal distribution\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(f\"\\nFitted Log-Norm Distribution Parameters:\")\n",
        "print(f\"  Shape parameter 'alpha'): {sigma_fit:.2f}\")\n",
        "print(f\"  Location parameter (loc): {loc_fit:.2f}\")\n",
        "print(f\"  Scale parameter (scale): {scale_fit:.2f}\")\n",
        "\n",
        "# Visualize the fit\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 9))\n",
        "## Histogram of the unemployment data\n",
        "ax.hist(data_to_fit, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Data Histogram')\n",
        "## Fitted log-norm pdf\n",
        "xmin, xmax = ax.get_xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = lognorm.pdf(x, sigma_fit, loc=loc_fit, scale=scale_fit)\n",
        "ax.plot(x, p, 'darkred', lw=2, label='Fitted Log-Normal PDF')\n",
        "ax.set_xlabel('Unemployment Rate', fontsize=10)\n",
        "ax.set_ylabel('Density', fontsize=10)\n",
        "ax.legend()\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Data Histogram vs. Fitted Log-Normal Distribution PDF\", y=1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "id": "fig-histogram-lognorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By overlaying the smooth PDF curve on top of original data's histogram, we can visualize that the Log-Normal distribution matches the distribution of the actual data. The peak of the PDF align with the peak of the histogram. The spread of the PDF roughly match the spread of the data, including the tail (@fig-histogram-lognorm).\n",
        "Now we need to use Kolmogorov-Smirnov Test to test Goodness-of-fit with the original data and estimated parameters, then examine the p value. "
      ],
      "id": "14416ee7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# KS goodness of fit test\n",
        "d_statistic, p_value = kstest(data_to_fit, lambda x: lognorm.cdf(x, sigma_fit, loc=loc_fit, scale=scale_fit)) \n",
        "print(f\"\\nKolmogorov-Smirnov Test Results:\")\n",
        "print(f\"  D-statistic: {d_statistic:.4f}\")\n",
        "print(f\"  P-value: {p_value:.4f}\")"
      ],
      "id": "b1ebfb5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With $p$-value < 0.05, we can't reject the hypothesis that the distribution does not come from the Log-Normal distribution, suggesting Log-Normal is not a good fit for the data. Next, explore other right-skewed distributions - Gamma distribution or the Weibull distribution."
      ],
      "id": "e20e23a1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-histogram-gamma\n",
        "#| fig-cap: Unmployment Rate Histogram vs. Fitted Gamma PDF\n",
        "#| fig-alt: Plot the histogram of unemployment rate data and overlay the Probability Density Function (PDF) of the fitted Gamma distribution.\n",
        "\n",
        "# Fit gamma distribution using MLE\n",
        "from scipy.stats import gamma, skew, kstest\n",
        "alpha_fit, loc_fit, scale_fit = gamma.fit(data_to_fit) # fit gamma distribution\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(f\"\\nFitted Gamma Distribution Parameters:\")\n",
        "print(f\"  Shape parameter 'alpha': {alpha_fit:.2f}\")\n",
        "print(f\"  Location parameter 'loc': {loc_fit:.2f}\")\n",
        "print(f\"  Scale parameter 'scale'): {scale_fit:.2f}\")\n",
        "\n",
        "# Visualize the fit\n",
        "fig, ax = plt.subplots(1, 1, figsize = (10, 8))\n",
        "## Histogram of the unemployment data\n",
        "ax.hist(data_to_fit, bins = 20, density=True, color='skyblue', alpha= 0.7, edgecolor='black', label = 'Data Histogram')\n",
        "xmin, xmax = ax.get_xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "## Plot fitted gamma pdf\n",
        "p = gamma.pdf(x, alpha_fit, loc=loc_fit, scale=scale_fit)\n",
        "ax.plot(x, p, 'darkred', lw=2, label='Fitted Gamma PDF')\n",
        "ax.set_xlabel('Unemployment Rate', fontsize=10)\n",
        "ax.set_ylabel('Density', fontsize=10)\n",
        "ax.legend()\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Data Histogram vs. Fitted Gamma Distribution PDF\", y=1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "id": "fig-histogram-gamma",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although visually the Gamma distribution matches the shape and spread of the actual data. (@fig-histogram-gamma), we need to\n",
        "use KS Test to test Goodness-of-fit by examining the p value. "
      ],
      "id": "17a585df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit the gamma \n",
        "d_statistic, p_value = kstest(data_to_fit, lambda x: gamma.cdf(x, alpha_fit, loc=loc_fit, scale=scale_fit))\n",
        "print(f\"\\nKolmogorov-Smirnov Test Results:\")\n",
        "print(f\"  D-statistic: {d_statistic:.4f}\")\n",
        "print(f\"  P-value: {p_value:.4f}\")"
      ],
      "id": "479347f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, with $p$-value < 0.05, we can not confidently say that the data comes from the Gamma distribution. Next, explore Weibull distribution."
      ],
      "id": "004f0dd3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-histogram-weibull\n",
        "#| fig-cap: Unmployment Rate Histogram vs. Fitted Weibull PDF\n",
        "#| fig-alt: Plot the histogram of unemployment rate data and overlay the Probability Density Function (PDF) of the fitted Weibull distribution.\n",
        "\n",
        "# Fit Weibull distribution using MLE\n",
        "from scipy.stats import weibull_min, skew, kstest\n",
        "from scipy.special import gamma as gamma_func # For Weibull mean calculation\n",
        "c_fit, loc_fit, scale_fit = weibull_min.fit(data_to_fit) # fit weibull distribution\n",
        "\n",
        "# Print the estimated parameters\n",
        "# print(f\"\\nFitted Weibull Distribution Parameters:\")\n",
        "# print(f\"  Shape parameter 'c' (k): {c_fit:.4f}\")\n",
        "# print(f\"  Location parameter (loc): {loc_fit:.4f}\")\n",
        "# print(f\"  Scale parameter (scale, lambda): {scale_fit:.4f}\")\n",
        "\n",
        "# Visualize the fit\n",
        "fig, ax = plt.subplots(1, 1, figsize = (10, 8))\n",
        "## Histogram of the unemployment data\n",
        "ax.hist(data_to_fit, bins = 20, density=True, color='skyblue', alpha= 0.7, edgecolor='black', label = 'Data Histogram')\n",
        "xmin, xmax = ax.get_xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "## Plot fitted gamma pdf\n",
        "p = weibull_min.pdf(x, c_fit, loc=loc_fit, scale=scale_fit)\n",
        "ax.plot(x, p, 'darkred', lw=2, label='Fitted Weibull PDF')\n",
        "ax.set_xlabel('Unemployment Rate', fontsize=10)\n",
        "ax.set_ylabel('Density', fontsize=10)\n",
        "ax.legend()\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Data Histogram vs. Fitted Weibull Distribution PDF\", y=1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "id": "fig-histogram-weibull",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit the Weibull\n",
        "d_statistic, p_value = kstest(data_to_fit, lambda x: weibull_min.cdf(x, c_fit, loc=loc_fit, scale=scale_fit))\n",
        "# Calculate inferred mean\n",
        "fitted_mean = loc_fit + scale_fit * gamma_func(1 + 1/c_fit)\n",
        "# print(f\"\\nKolmogorov-Smirnov Test Results:\")\n",
        "# print(f\"  D-statistic: {d_statistic:.4f}\")\n",
        "# print(f\"  P-value: {p_value:.4f}\")"
      ],
      "id": "93a12e2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tbl-col": true,
        "tbl-center": true
      },
      "source": [
        "#| label: tbl-weibull-params\n",
        "#| tbl-cap: Weibull Distribution and Fitness Statistics\n",
        "\n",
        "# Print out the Weibull stats\n",
        "weibull_stats = {\n",
        "  \"Parameters\": [\n",
        "    \"Shape (c)\",\n",
        "    \"Location (loc)\" ,\n",
        "    \"Scale\",\n",
        "    \"D_statistics\",\n",
        "    \"P-value\",\n",
        "    \"Fitted Mean\"\n",
        "  ],\n",
        "  \"Values\": [\n",
        "     round(c_fit, 4),\n",
        "     round(loc_fit, 4),\n",
        "     round(scale_fit, 4),\n",
        "     round(d_statistic, 4),\n",
        "     round(p_value, 4),\n",
        "     round(fitted_mean, 2)\n",
        "  ]\n",
        "}\n",
        "weibull_stats_table = pd.DataFrame(weibull_stats)\n",
        "display(weibull_stats_table.style.hide(axis=\"index\"))"
      ],
      "id": "tbl-weibull-params",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overlayed smooth PDF curve on top of original data's histogram @fig-histogram-weibull suggests that the Weibull distribution matches the distribution of the actual data. The results of the Weibull distribution, summarized in Table @tbl-weibull-params, including the shape, location, and scale parameters, along with the D-statistic, P-value, and fitted mean also proves Weibull distribution is a good fit, supported by a KS test p-value of 0.1173 (greater than 0.05). The estimated parameters (c=0.7093, loc=3.2000, scale=0.9204) align well with the spread of the data. Shape (c<1): Confirms the strong right-skewness of the data. Location (loc=3.2000): Indicates the distribution starts around 3.20, matching data's lower bound. Inferred Mean: The calculated mean of approximately 4.35 from these parameters is close but slightly higher than the data's actual mean of around 4, showing a good capture of central tendency.\n",
        "\n",
        "### Define the prior means for overall population\n",
        "```python\n",
        "### population unemployment mean probability from the fitted Weibull distribution\n",
        "weibull_fitted_mean_prob = 0.0435\n",
        "# Convert the fitted mean probability to its log-odds equivalent in order to model binary outcome with logistic regression\n",
        "population_mean_log_odds = np.log(weibull_fitted_mean_prob / (1 - weibull_fitted_mean_prob))\n",
        "```"
      ],
      "id": "7935cf44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### population unemployment mean probability from the fitted Weibull distribution\n",
        "weibull_fitted_mean_prob = 0.0435\n",
        "# Convert the fitted mean probability to its log-odds equivalent in order to model binary outcome with logistic regression\n",
        "population_mean_log_odds = np.log(weibull_fitted_mean_prob / (1 - weibull_fitted_mean_prob))"
      ],
      "id": "b6517acd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the prior means by demographic types\n",
        "```python\n",
        "# Function to find the means of different demographics\n",
        "def mean_prob_demographic(df_name, demographic_type, demographic_description):\n",
        "    demographic_mean_prob = df_dic[df_name].loc[df_dic[df_name][demographic_type]==demographic_description]['Unemployment_rate'].mean()/100\n",
        "    demographic_mean_log_odds = np.log(demographic_mean_prob / (1 - demographic_mean_prob))\n",
        "    # beta_effect is the difference between the demographic group mean log-odds and the population mean log-odds\n",
        "    beta_effect = demographic_mean_log_odds - population_mean_log_odds\n",
        "    return beta_effect\n",
        "\n",
        "# Create a grid of demographic information to return the means\n",
        "demographic_grid = pd.DataFrame({\n",
        "    \"df_name\":[\n",
        "        'Race',\n",
        "        'Race',\n",
        "        'Race'\n",
        "    ],\n",
        "    \"demographic_type\":[\n",
        "        \"Race\", \n",
        "        \"Race\",\n",
        "        \"Race\"\n",
        "    ],\n",
        "    \"demographic_description\":[\n",
        "        'black_and_african',\n",
        "        'white',\n",
        "        'asian'\n",
        "    ]\n",
        "})\n",
        "# Return the means\n",
        "demographic_grid['beta_effect']= np.float64(0)\n",
        "for row in range(0,len(demographic_grid)):\n",
        "    # Mean of demographic groups\n",
        "    beta_effect = mean_prob_demographic(demographic_grid['df_name'][row], demographic_grid['demographic_type'][row], demographic_grid['demographic_description'][row])\n",
        "    demographic_grid['beta_effect'][row] = beta_effect\n",
        "\n",
        "```"
      ],
      "id": "228df526"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to find the means of different demographics\n",
        "def mean_prob_demographic(df_name, demographic_type, demographic_description):\n",
        "    demographic_mean_prob = df_dic[df_name].loc[df_dic[df_name][demographic_type]==demographic_description]['Unemployment_rate'].mean()/100\n",
        "    demographic_mean_log_odds = np.log(demographic_mean_prob / (1 - demographic_mean_prob))\n",
        "    # beta_effect is the difference between the demographic group mean log-odds and the population mean log-odds\n",
        "    beta_effect = demographic_mean_log_odds - population_mean_log_odds\n",
        "    return beta_effect\n",
        "\n",
        "# Create a grid of demographic information to return the means\n",
        "demographic_grid = pd.DataFrame({\n",
        "    \"df_name\":[\n",
        "        'Race',\n",
        "        'Race',\n",
        "        'Race'\n",
        "    ],\n",
        "    \"demographic_type\":[\n",
        "        \"Race\", \n",
        "        \"Race\",\n",
        "        \"Race\"\n",
        "    ],\n",
        "    \"demographic_description\":[\n",
        "        'black_and_african',\n",
        "        'white',\n",
        "        'asian'\n",
        "    ]\n",
        "})\n",
        "# Return the beta_effect of different demographics\n",
        "demographic_grid['beta_effect']= np.float64(0)\n",
        "for row in range(0,len(demographic_grid)):\n",
        "    # Mean of demographic groups\n",
        "    beta_effect = mean_prob_demographic(demographic_grid['df_name'][row], demographic_grid['demographic_type'][row], demographic_grid['demographic_description'][row])\n",
        "    demographic_grid['beta_effect'][row] = beta_effect"
      ],
      "id": "5c5ab532",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the unemployment-race PyMC\n",
        "This section sets up the Bayesian model to estimate the additive race effect relative to the fixed baseline.\n",
        "```python\n",
        "\n",
        "# Create the pymc model\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "with pm.Model() as unemployment_race_model:\n",
        "    # Prior of population mean log odds\n",
        "    mu_population_log_odds = pm.Normal('mu_population_log_odds', mu=population_mean_log_odds, sigma=0.5)\n",
        "    \n",
        "    # Additive race effect parameter on population mean\n",
        "    beta_black = pm.Normal('beta_black', mu=demographic_grid[demographic_grid['demographic_description']=='black_and_african']['beta_effect'], sigma=0.3) # Can be positive or negative\n",
        "\n",
        "    beta_asian = pm.Normal('beta_asian', mu=demographic_grid[demographic_grid['demographic_description']=='asian']['beta_effect'], sigma=0.3) \n",
        "\n",
        "    beta_white = pm.Normal('beta_white', mu=demographic_grid[demographic_grid['demographic_description']=='white']['beta_effect'], sigma=0.3) \n",
        "    \n",
        "    # noise\n",
        "    sigma = pm.HalfNormal('sigma', sigma=0.2)\n",
        "\n",
        "    # log-odds and probabilities for each racial group\n",
        "    mu_white_log_odds = pm.Deterministic('mu_white_log_odds', mu_population_log_odds + beta_white)\n",
        "    mu_black_log_odds = pm.Deterministic('mu_black_log_odds', mu_population_log_odds + beta_black)\n",
        "    mu_asian_log_odds = pm.Deterministic('mu_asian_log_odds', mu_population_log_odds + beta_asian)\n",
        "\n",
        "    p_population = pm.Deterministic('p_population', pm.math.invlogit(mu_population_log_odds))\n",
        "    p_white = pm.Deterministic('p_white', pm.math.invlogit(mu_white_log_odds))\n",
        "    p_black = pm.Deterministic('p_black', pm.math.invlogit(mu_black_log_odds))\n",
        "    p_asian = pm.Deterministic('p_asian', pm.math.invlogit(mu_asian_log_odds))\n",
        "\n",
        "    # Likelihoods for observed data: use parameters like derived above to make predictions about the \"true\" probabilities of unemployment.\n",
        "\n",
        "    # predict population mean\n",
        "    population_rates_df = df_overall_long[~np.isnan(df_overall_long['Unemployment_rate'])]\n",
        "    population_rates_df['rate_logit'] = np.log(population_rates_df['Unemployment_rate']*0.01/(1-population_rates_df['Unemployment_rate']*0.01))\n",
        "    population_rates_obs = pm.Normal(\n",
        "        'population_rates_obs',\n",
        "        mu=mu_population_log_odds, \n",
        "        sigma=sigma,\n",
        "        observed=population_rates_df['rate_logit'].values\n",
        "    )\n",
        "\n",
        "    # predict black mean\n",
        "    black_rates_df = df_dic['Race'][df_dic['Race']['Race']=='black_and_african']\n",
        "    black_rates_df = black_rates_df[~np.isnan(black_rates_df['Unemployment_rate'])] \n",
        "    black_rates_df['rate_logit'] = np.log(black_rates_df['Unemployment_rate']*0.01/(1-black_rates_df['Unemployment_rate']*0.01))\n",
        "    black_rates_obs = pm.Normal(\n",
        "        'black_rates_obs',\n",
        "        mu=mu_black_log_odds, \n",
        "        sigma=sigma,\n",
        "        observed=black_rates_df['rate_logit'].values\n",
        "    )\n",
        "\n",
        "    # predict asian mean\n",
        "    asian_rates_df = df_dic['Race'][df_dic['Race']['Race']=='asian']\n",
        "    asian_rates_df = asian_rates_df[~np.isnan(asian_rates_df['Unemployment_rate'])] \n",
        "    asian_rates_df['rate_logit'] = np.log(asian_rates_df['Unemployment_rate']*0.01/(1-asian_rates_df['Unemployment_rate']*0.01))\n",
        "    asian_rates_obs = pm.Normal(\n",
        "        'asian_rates_obs',\n",
        "        mu=mu_asian_log_odds,\n",
        "        sigma=sigma,\n",
        "        observed=asian_rates_df['rate_logit'].values\n",
        "    )\n",
        "\n",
        "    # predict white mean\n",
        "    white_rates_df = df_dic['Race'][df_dic['Race']['Race']=='white']\n",
        "    white_rates_df = white_rates_df[~np.isnan(white_rates_df['Unemployment_rate'])] \n",
        "    white_rates_df['rate_logit'] = np.log(white_rates_df['Unemployment_rate']*0.01/(1-white_rates_df['Unemployment_rate']*0.01))\n",
        "    white_rates_obs = pm.Normal(\n",
        "        'white_rates_obs',\n",
        "        mu=mu_white_log_odds,\n",
        "        sigma=sigma,\n",
        "        observed=white_rates_df['rate_logit'].values\n",
        "    )\n",
        "    \n",
        "    # Assign the correct probability based on race\n",
        "    p_individual_for_obs = pm.math.switch(\n",
        "        df_survey_jun['is_black_african'].values,\n",
        "        p_black, # if is_black, use black prob\n",
        "        pm.math.switch(\n",
        "            df_survey_jun['is_asian'].values, \n",
        "            p_asian, # if is_asian, use asian prob\n",
        "            p_white # else, use white prob\n",
        "        )\n",
        "    )\n",
        "    individual_status_obs = pm.Bernoulli(\n",
        "        'individual_status_obs',\n",
        "        p=p_individual_for_obs,\n",
        "        observed=df_survey_jun['unemployment_status'].values\n",
        "    )\n",
        "```"
      ],
      "id": "4bca0fa6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "with pm.Model() as unemployment_race_model:\n",
        "    # Prior of population mean log odds\n",
        "    mu_population_log_odds = pm.Normal('mu_population_log_odds', mu=population_mean_log_odds, sigma=0.5)\n",
        "    \n",
        "    # Additive race effect parameter on population mean\n",
        "    beta_black = pm.Normal('beta_black', mu=demographic_grid[demographic_grid['demographic_description']=='black_and_african']['beta_effect'], sigma=0.3) # Can be positive or negative\n",
        "\n",
        "    beta_asian = pm.Normal('beta_asian', mu=demographic_grid[demographic_grid['demographic_description']=='asian']['beta_effect'], sigma=0.3) \n",
        "\n",
        "    beta_white = pm.Normal('beta_white', mu=demographic_grid[demographic_grid['demographic_description']=='white']['beta_effect'], sigma=0.3) \n",
        "    \n",
        "    # noise\n",
        "    sigma = pm.HalfNormal('sigma', sigma=0.2)\n",
        "\n",
        "    # log-odds and probabilities for each racial group\n",
        "    mu_white_log_odds = pm.Deterministic('mu_white_log_odds', mu_population_log_odds + beta_white)\n",
        "    mu_black_log_odds = pm.Deterministic('mu_black_log_odds', mu_population_log_odds + beta_black)\n",
        "    mu_asian_log_odds = pm.Deterministic('mu_asian_log_odds', mu_population_log_odds + beta_asian)\n",
        "\n",
        "    p_population = pm.Deterministic('p_population', pm.math.invlogit(mu_population_log_odds))\n",
        "    p_white = pm.Deterministic('p_white', pm.math.invlogit(mu_white_log_odds))\n",
        "    p_black = pm.Deterministic('p_black', pm.math.invlogit(mu_black_log_odds))\n",
        "    p_asian = pm.Deterministic('p_asian', pm.math.invlogit(mu_asian_log_odds))\n",
        "\n",
        "    # Likelihoods for observed data: use parameters like derived above to make predictions about the \"true\" probabilities of unemployment.\n",
        "\n",
        "    # predict population mean\n",
        "    population_rates_df = df_overall_long[~np.isnan(df_overall_long['Unemployment_rate'])]\n",
        "    population_rates_df['rate_logit'] = np.log(population_rates_df['Unemployment_rate']*0.01/(1-population_rates_df['Unemployment_rate']*0.01))\n",
        "    population_rates_obs = pm.Normal(\n",
        "        'population_rates_obs',\n",
        "        mu=mu_population_log_odds, \n",
        "        sigma=sigma,\n",
        "        observed=population_rates_df['rate_logit'].values\n",
        "    )\n",
        "\n",
        "    # predict black mean\n",
        "    black_rates_df = df_dic['Race'][df_dic['Race']['Race']=='black_and_african']\n",
        "    black_rates_df = black_rates_df[~np.isnan(black_rates_df['Unemployment_rate'])] \n",
        "    black_rates_df['rate_logit'] = np.log(black_rates_df['Unemployment_rate']*0.01/(1-black_rates_df['Unemployment_rate']*0.01))\n",
        "    black_rates_obs = pm.Normal(\n",
        "        'black_rates_obs',\n",
        "        mu=mu_black_log_odds, \n",
        "        sigma=sigma,\n",
        "        observed=black_rates_df['rate_logit'].values\n",
        "    )\n",
        "\n",
        "    # predict asian mean\n",
        "    asian_rates_df = df_dic['Race'][df_dic['Race']['Race']=='asian']\n",
        "    asian_rates_df = asian_rates_df[~np.isnan(asian_rates_df['Unemployment_rate'])] \n",
        "    asian_rates_df['rate_logit'] = np.log(asian_rates_df['Unemployment_rate']*0.01/(1-asian_rates_df['Unemployment_rate']*0.01))\n",
        "    asian_rates_obs = pm.Normal(\n",
        "        'asian_rates_obs',\n",
        "        mu=mu_asian_log_odds,\n",
        "        sigma=sigma,\n",
        "        observed=asian_rates_df['rate_logit'].values\n",
        "    )\n",
        "\n",
        "    # predict white mean\n",
        "    white_rates_df = df_dic['Race'][df_dic['Race']['Race']=='white']\n",
        "    white_rates_df = white_rates_df[~np.isnan(white_rates_df['Unemployment_rate'])] \n",
        "    white_rates_df['rate_logit'] = np.log(white_rates_df['Unemployment_rate']*0.01/(1-white_rates_df['Unemployment_rate']*0.01))\n",
        "    white_rates_obs = pm.Normal(\n",
        "        'white_rates_obs',\n",
        "        mu=mu_white_log_odds,\n",
        "        sigma=sigma,\n",
        "        observed=white_rates_df['rate_logit'].values\n",
        "    )\n",
        "    \n",
        "    # Assign the correct probability based on race\n",
        "    p_individual_for_obs = pm.math.switch(\n",
        "        df_survey_jun['is_black_african'].values,\n",
        "        p_black, # if is_black, use black prob\n",
        "        pm.math.switch(\n",
        "            df_survey_jun['is_asian'].values, \n",
        "            p_asian, # if is_asian, use asian prob\n",
        "            p_white # else, use white prob\n",
        "        )\n",
        "    )\n",
        "    individual_status_obs = pm.Bernoulli(\n",
        "        'individual_status_obs',\n",
        "        p=p_individual_for_obs,\n",
        "        observed=df_survey_jun['unemployment_status'].values\n",
        "    )"
      ],
      "id": "3fde01f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph the unemployment-race PGM\n",
        "```python\n",
        "pm.model_to_graphviz(unemployment_race_model)\n",
        "```"
      ],
      "id": "72769640"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pm.model_to_graphviz(unemployment_race_model)"
      ],
      "id": "bf971a2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit the unemployment-race Model - Perform MCMC Sampling\n",
        "```python\n",
        "print(\"Starting MCMC sampling...\")\n",
        "with unemployment_race_model:\n",
        "    indiv_trace = pm.sample(random_seed=5650)\n",
        "```"
      ],
      "id": "b271c8e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Starting MCMC sampling...\")\n",
        "with unemployment_race_model:\n",
        "    indiv_trace = pm.sample(random_seed=5650)"
      ],
      "id": "1c0b8ec3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyze unemployment-race Results and Visualize\n",
        "```python\n",
        "# Analyze Results and Visualize\n",
        "print(\"\\n--- Model Summary (Simplified Model - Multiple Races) ---\")\n",
        "az.summary(indiv_trace, var_names=['mu_population_log_odds', 'beta_black', 'beta_asian', 'beta_white', 'sigma'])\n",
        "\n",
        "# Trace plot\n",
        "fig_trace = az.plot_trace(indiv_trace)\n",
        "plt.suptitle('Trace plot', fontsize=16)\n",
        "plt.subplots_adjust(hspace=0.5) \n",
        "\n",
        "# Convert to DataFrame\n",
        "indiv_post_df = indiv_trace.posterior.to_dataframe().reset_index()\n",
        "# Extract only the first chain\n",
        "indiv_post_df = indiv_post_df[indiv_post_df['chain'] == 0]\n",
        "# Melt\n",
        "indiv_post_df = indiv_post_df[['draw','beta_black', 'beta_asian', 'beta_white']].melt(id_vars=['draw'])\n",
        "\n",
        "# Density Plot\n",
        "import seaborn as sns\n",
        "import patchworklib as pw\n",
        "ax = pw.Brick(figsize=(4, 2.5));\n",
        "sns.kdeplot(\n",
        "    x=\"value\", hue=\"variable\", data=indiv_post_df, ax=ax,\n",
        "    fill=True, bw_adjust=2,\n",
        ");\n",
        "ax.set_xlabel(\"Log-Odds Deviation from Overall Mean\")\n",
        "ax.set_ylabel(\"Density\")\n",
        "ax.set_title(\"Posterior Distribution of Race Effect Deviations\")\n",
        "ax.savefig()\n",
        "\n",
        "```"
      ],
      "id": "dd4d07b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze Results and Visualize\n",
        "print(\"\\n--- Model Summary (Simplified Model - Multiple Races) ---\")\n",
        "az.summary(indiv_trace, var_names=['mu_population_log_odds', 'beta_black', 'beta_asian', 'beta_white', 'sigma'])\n",
        "\n",
        "# Trace plot\n",
        "fig_trace = az.plot_trace(indiv_trace)\n",
        "plt.suptitle('Trace plot', fontsize=16)\n",
        "plt.subplots_adjust(hspace=0.5) \n",
        "\n",
        "# Convert to DataFrame\n",
        "indiv_post_df = indiv_trace.posterior.to_dataframe().reset_index()\n",
        "# Extract only the first chain\n",
        "indiv_post_df = indiv_post_df[indiv_post_df['chain'] == 0]\n",
        "# Melt\n",
        "indiv_post_df = indiv_post_df[['draw','beta_black', 'beta_asian', 'beta_white']].melt(id_vars=['draw'])\n",
        "\n",
        "# Density plot\n",
        "import seaborn as sns\n",
        "import patchworklib as pw\n",
        "ax = pw.Brick(figsize=(4, 2.5));\n",
        "sns.kdeplot(\n",
        "    x=\"value\", hue=\"variable\", data=indiv_post_df, ax=ax,\n",
        "    fill=True, bw_adjust=2,\n",
        ");\n",
        "ax.set_xlabel(\"Log-Odds Deviation from Overall Mean\")\n",
        "ax.set_ylabel(\"Density\")\n",
        "ax.set_title(\"Posterior Distribution of Race Effect Deviations\")\n",
        "ax.savefig()"
      ],
      "id": "65504b08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior distributions of racial group mean log-odds for unemployment reveal clear deviations, with the Black population exhibiting a higher rate compared to both the White and Asian populations.\n",
        "\n",
        "### PGM for unemployment-industry\n",
        "(To be added)\n",
        "\n",
        "### PGM for \n",
        "\n",
        "\n",
        "## References {.unnumbered}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "d836cea6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/kirawei/.pyenv/versions/3.11.5/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}