% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{agujournal2019}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{url} %this package should fix any errors with URLs in refs.
\usepackage{lineno}
\usepackage[inline]{trackchanges} %for better track changes. finalnew option will compile document with changes incorporated.
\usepackage{soul}
\linenumbers
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Causal Inference of Labor Market Inequality Using PGM: A multidimensional analysis of unemployment rate and durations},
  pdfauthor={Mengjia Wei},
  pdfkeywords={PGM, Unemployment Rate, Unemployment Durations, Causal
Inference},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\journalname{Georgetown Univeristy DSAN 5650 Journal}

\draftfalse

\begin{document}
\title{Causal Inference of Labor Market Inequality Using PGM: A
multidimensional analysis of unemployment rate and durations}

\authors{Mengjia Wei\affil{1}}
\affiliation{1}{Georgetown University, }



\begin{abstract}
This study investigates the causal relationships between age,
occupation, race, and unemployment rates in the United States,
applying~probabilistic graphical modeling (PGM)~to uncover latent
dependency structures across demographic and industry variables. Using a
PGM framework, we extend this approach to labor market data by
constructing conditional dependence networks across two key dimensions:
group attributes (age, race, and industry) and time (2015 - 2024 and
2025). Specifically, the study examines recent college graduates (ages
22--24) relative to older individuals (25+), comparing their
unemployment rates by major across 2024 and 2025. A second dimension of
analysis focuses on industry-specific unemployment rate dynamics from
2015 to 2025, particularly in {[}retail{]}, {[}arts{]}, and
{[}technology{]} sectors. In addition to rate-based measures, the study
explores how~unemployment duration~has evolved between 2015 and 2025.
This analysis seeks to identify whether certain groups---such as Black
labor force and {[}Retail Industry{]}---face higher or lower
unemployment, providing a more comprehensive view of labor market
hardship. The model estimates the strength and direction of
probabilistic dependencies using Bayesian structure learning algorithms,
based on labor force aggregated data from BLS CPS datasets. The results
indicate that {[}conclusion1{]}. Additionally, the {[}retail{]},
{[}arts{]}, and {[}technology{]} industries experienced increased
unemployment rates between 2015 and 2025, with respective changes of~{[}
{]},~{[} {]}, and~{[} {]}~percentage points. The findings also suggest
that, consistent with earlier research, unemployment duration is
negatively correlated with the unemployment rate by occupation, with
industries exhibiting higher unemployment often associated with shorter
average durations (Chien, Y., \& Morris, P., 2016). The PGM framework
reveals significant interactive effects between race and industry on
unemployment, particularly among~{[}e.g., Black or Hispanic
workers{]}~in the~{[}e.g., retail or hospitality{]}~sector. These
findings contribute to the growing literature that leverages PGMs for
social inference (e.g., Li et al., 2022), highlighting the model's
potential for uncovering structural labor inequalities over time and
across population subgroups.
\end{abstract}

\section*{Plain Language Summary}
TBD




\section{Introduction}\label{introduction}

The interplay of demographic characteristics and labor market dynamics
consistently reveals significant disparities in unemployment rates.
Decades of research reveal a persistent relationship between race,
gender, and unemployment, evident across diverse economic cycles. Though
the Black unemployment rate fell to a historic low of 6.1\% in 2019, it
was still twice as high as the White unemployment rate of 3.0\%, as
Wilson \& Darity-Jr. (2022) observed. These disparities are further
magnified at the intersection of race and gender. For instance, Black
men faced a 6.1\% unemployment rate in February 2024, notably higher
than Black women at 4.4\%. Similarly, Hispanic women's unemployment rate
increased to 5.0\% in February 2024, while Hispanic men experienced a
decrease to 4.0\% (Joseph Dean (2024)). Native American men also
experienced higher unemployment (10\%) than Native American women (7\%)
in 2022. Industry-specific analyses similarly highlight divergent
unemployment trends. The Leisure and Hospitality sector reported the
highest unemployment rate at 6.0\% in 2024, an increase from 5.5\% in
2023. Similarly, Wholesale and Retail Trade experienced elevated
unemployment, reaching 4.7\% in October 2024, up from 4.0\% in 2023.
Conversely, Financial Activities maintained a significantly lower
unemployment rate of 1.9\% ({``US UNEMPLOYMENT RATE BY INDUSTRY
(2024)''} (2024)).

Research from the U.S. Bureau of Labor Statistics consistently shows
longer unemployment spells in sectors such as Manufacturing and
Construction, while industries demanding specialized skills like
Education and Health Services exhibit shorter durations. Study by YiLi
Chien (2016) reveals negative correlation between the unemployment rate
and duration. Such variations in both the rate and duration of
unemployment underscore complex interactions among race, gender, age,
and industry.

TOIEducation (2025) published that the labor market for recent college
graduates has ``deteriorated noticeably'' in the first quarter of 2025.
The unemployment rate for this cohort (ages 22-27) ranged from 5.5\% to
7.1\%, exceeding the overall national average of 4.1-4.2\%, with
Anthropology (9.4\%), Physics (7.8\%), and Computer Engineering (7.5\%)
showing among the highest rates.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/unemployment_rate_recent_graduate.png}}

}

\caption{\label{fig-graduates}Unemployment Rate of Recent College
Graduates}

\end{figure}%

Although the Federal Open Market Committee (FOMC) reported a low overall
unemployment rate for June 2025, recent data clearly indicate a
noticeable uptick in the unemployment rate for the 22-27 age group since
March, reaching 2021 levels and particularly affecting recent college
graduates (Figure~\ref{fig-graduates}).

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}llllllll@{}}

\caption{\label{tbl-survey-data}BLS June 2025 Labor Force Survey Data}

\tabularnewline

\caption{}\label{T_eff7a}\tabularnewline
\toprule\noalign{}
sex\_name & race\_name & education\_attainment\_name &
employment\_status\_name & industry\_name & is\_black\_african &
is\_asian & is\_white \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
sex\_name & race\_name & education\_attainment\_name &
employment\_status\_name & industry\_name & is\_black\_african &
is\_asian & is\_white \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
male & white & bachelors\_degree & employed & Construction & 0 & 0 &
1 \\
male & white & high\_school & employed & Construction & 0 & 0 & 1 \\
female & white & bachelors\_degree & employed & Manufacturing & 0 & 0 &
1 \\
male & white & bachelors\_degree & employed & Manufacturing & 0 & 0 &
1 \\
female & white & masters\_degree & employed & Transportation and
utilities & 0 & 0 & 1 \\
female & white & bachelors\_degree & employed & Construction & 0 & 0 &
1 \\
male & white & high\_school & employed & Wholesale and retail trade & 0
& 0 & 1 \\
female & white & bachelors\_degree & employed & Professional and
business services & 0 & 0 & 1 \\
male & white & less\_than\_high\_school & employed & Professional and
business services & 0 & 0 & 1 \\
female & white & high\_school & employed & Educational and health
services & 0 & 0 & 1 \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Data from the U.S. Bureau of Labor Statistics (BLS) June 2025 labor
force survey provide individual-level employment status and
corresponding demographic information. For the purpose of this study, a
subset of these relevant columns is utilized
(Table~\ref{tbl-survey-data}).

\section{EDA}\label{eda}

\subsection{Unemployment Rates of Differenet
Demographics}\label{unemployment-rates-of-differenet-demographics}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Race
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-6-output-2.png}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Sex
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-6-output-4.png}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Industry
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-6-output-6.png}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Age
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-6-output-8.png}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Education_attainment
\end{verbatim}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-unemployment-rate-demographics-output-2.png}}

}

\caption{\label{fig-histogram-unemployment-rate-demographics}Unemployment
Rate Distributions By Demographics (2015-2025 statistics)}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

BLS data from 2015--2025 indicate that the Black or African American
population experienced the highest average unemployment rate (7.5\%),
primarily within the 5--10\% range. Gender differences are minimal, with
both averaging around 5\%, though rates are slightly higher for men.
Among industries, Leisure and Hospitality recorded the highest
unemployment (10\%) with a long-tail distribution, followed by
Agriculture (5--11\%) and moderate variability. Construction and
Mining/Oil \& Gas exhibit similar but marginally lower patterns. The
22--24 age group stands out with significantly elevated
unemployment---averaging 7\% and predominantly above 5\%---while other
age groups display lower and more uniform rates. Financial Activities
show the lowest and most stable unemployment, consistently under 5\%.
Individuals without a high school diploma face high and variable
unemployment, averaging 7\% with a long-tail skew. These patterns
suggest that young adults (22--24), Black or African Americans without
college degrees, and those employed in Leisure, Construction, or Mining
sectors are disproportionately affected by higher unemployment.
(Figure~\ref{fig-histogram-unemployment-rate-demographics}).

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-unemployment-rate-output-1.png}}

}

\caption{\label{fig-histogram-unemployment-rate}Overall Population
Unemployment Rate Distributions (2015-2025 statistics)}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

According to BLS data from 2015--2025, the overall population
unemployment rate averaged slightly above 4\%, with the majority of
observations concentrated between 2\% and 5\% and exhibiting relatively
low variability (Figure~\ref{fig-histogram-unemployment-rate}).

\section{PGM}\label{pgm}

We posit that unemployment vulnerability is driven by structural
inequalities within the labor market, particularly those rooted in
demographic and industrial dimensions. Demographic disparities are
represented by variables such as race, age, and educational attainment
and industry; sex is excluded from the analysis due to prior findings
indicating minimal impact on unemployment rates. Establishing a baseline
unemployment level is a necessary step before assessing the marginal
effects of these demographic and industrial factors.

\subsection{Baseline unemployment rate
distribution}\label{baseline-unemployment-rate-distribution}

Figure 3 illustrates that the population unemployment rate is
right-skewed, suggesting that the Log-Normal distribution is an
appropriate model. We are going to estimate the parameters of a
Log-Normal distribution from the population distribution data using MLE.
(\(\sigma\), \(\text{loc}\), and \(\text{scale}\)).

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Fitted Log-Norm Distribution Parameters:
  Shape parameter 'alpha'): 9.92
  Location parameter (loc): 3.20
  Scale parameter (scale): 0.03
\end{verbatim}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-lognorm-output-2.png}}

}

\caption{\label{fig-histogram-lognorm}Unmployment Rate Histogram
vs.~Fitted Log-Norm PDF}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

By overlaying the smooth PDF curve on top of original data's histogram,
we can visualize that the Log-Normal distribution matches the
distribution of the actual data. The peak of the PDF align with the peak
of the histogram. The spread of the PDF roughly match the spread of the
data, including the tail (Figure~\ref{fig-histogram-lognorm}). Now we
need to use Kolmogorov-Smirnov Test to test Goodness-of-fit with the
original data and estimated parameters, then examine the p value.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Kolmogorov-Smirnov Test Results:
  D-statistic: 0.4592
  P-value: 0.0000
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

With \(p\)-value \textless{} 0.05, we can't reject the hypothesis that
the distribution does not come from the Log-Normal distribution,
suggesting Log-Normal is not a good fit for the data. Next, explore
other right-skewed distributions - Gamma distribution or the Weibull
distribution.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Fitted Gamma Distribution Parameters:
  Shape parameter 'alpha': 0.45
  Location parameter 'loc': 3.20
  Scale parameter 'scale'): 1.36
\end{verbatim}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-gamma-output-2.png}}

}

\caption{\label{fig-histogram-gamma}Unmployment Rate Histogram
vs.~Fitted Gamma PDF}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Although visually the Gamma distribution matches the shape and spread of
the actual data. (Figure~\ref{fig-histogram-gamma}), we need to use KS
Test to test Goodness-of-fit by examining the p value.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Kolmogorov-Smirnov Test Results:
  D-statistic: 0.2699
  P-value: 0.0000
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Again, with \(p\)-value \textless{} 0.05, we can not confidently say
that the data comes from the Gamma distribution. Next, explore Weibull
distribution.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-weibull-output-1.png}}

}

\caption{\label{fig-histogram-weibull}Unmployment Rate Histogram
vs.~Fitted Weibull PDF}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}ll@{}}

\caption{\label{tbl-weibull-params}Weibull Distribution and Fitness
Statistics}

\tabularnewline

\caption{}\label{T_b7626}\tabularnewline
\toprule\noalign{}
Parameters & Values \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Parameters & Values \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Shape (c) & 0.709300 \\
Location (loc) & 3.200000 \\
Scale & 0.920400 \\
D\_statistics & 0.104700 \\
P-value & 0.117300 \\
Fitted Mean & 4.350000 \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

The overlayed smooth PDF curve on top of original data's histogram
Figure~\ref{fig-histogram-weibull} suggests that the Weibull
distribution matches the distribution of the actual data. The results of
the Weibull distribution, summarized in Table
Table~\ref{tbl-weibull-params}, including the shape, location, and scale
parameters, along with the D-statistic, P-value, and fitted mean also
proves Weibull distribution is a good fit, supported by a KS test
p-value of 0.1173 (greater than 0.05). The estimated parameters
(c=0.7093, loc=3.2000, scale=0.9204) align well with the spread of the
data. Shape (c\textless1): Confirms the strong right-skewness of the
data. Location (loc=3.2000): Indicates the distribution starts around
3.20, matching data's lower bound. Inferred Mean: The calculated mean of
approximately 4.35 from these parameters is close but slightly higher
than the data's actual mean of around 4, showing a good capture of
central tendency.

\subsection{Define the prior means for overall
population}\label{define-the-prior-means-for-overall-population}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#\# population unemployment mean probability from the fitted Weibull distribution}
\NormalTok{weibull\_fitted\_mean\_prob }\OperatorTok{=} \FloatTok{0.0435}
\CommentTok{\# Convert the fitted mean probability to its log{-}odds equivalent in order to model binary outcome with logistic regression}
\NormalTok{population\_mean\_log\_odds }\OperatorTok{=}\NormalTok{ np.log(weibull\_fitted\_mean\_prob }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ weibull\_fitted\_mean\_prob))}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Define the prior means by demographic
types}\label{define-the-prior-means-by-demographic-types}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Function to find the means of different demographics}
\KeywordTok{def}\NormalTok{ mean\_prob\_demographic(df\_name, demographic\_type, demographic\_description):}
\NormalTok{    demographic\_mean\_prob }\OperatorTok{=}\NormalTok{ df\_dic[df\_name].loc[df\_dic[df\_name][demographic\_type]}\OperatorTok{==}\NormalTok{demographic\_description][}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{].mean()}\OperatorTok{/}\DecValTok{100}
\NormalTok{    demographic\_mean\_log\_odds }\OperatorTok{=}\NormalTok{ np.log(demographic\_mean\_prob }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ demographic\_mean\_prob))}
    \CommentTok{\# beta\_effect is the difference between the demographic group mean log{-}odds and the population mean log{-}odds}
\NormalTok{    beta\_effect }\OperatorTok{=}\NormalTok{ demographic\_mean\_log\_odds }\OperatorTok{{-}}\NormalTok{ population\_mean\_log\_odds}
    \ControlFlowTok{return}\NormalTok{ beta\_effect}

\CommentTok{\# Create a grid of demographic information to return the means}
\NormalTok{demographic\_grid }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{"df\_name"}\NormalTok{:[}
        \StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}Race\textquotesingle{}}
\NormalTok{    ],}
    \StringTok{"demographic\_type"}\NormalTok{:[}
        \StringTok{"Race"}\NormalTok{, }
        \StringTok{"Race"}\NormalTok{,}
        \StringTok{"Race"}
\NormalTok{    ],}
    \StringTok{"demographic\_description"}\NormalTok{:[}
        \StringTok{\textquotesingle{}black\_and\_african\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}asian\textquotesingle{}}
\NormalTok{    ]}
\NormalTok{\})}
\CommentTok{\# Return the means}
\NormalTok{demographic\_grid[}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{]}\OperatorTok{=}\NormalTok{ np.float64(}\DecValTok{0}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ row }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{,}\BuiltInTok{len}\NormalTok{(demographic\_grid)):}
    \CommentTok{\# Mean of demographic groups}
\NormalTok{    beta\_effect }\OperatorTok{=}\NormalTok{ mean\_prob\_demographic(demographic\_grid[}\StringTok{\textquotesingle{}df\_name\textquotesingle{}}\NormalTok{][row], demographic\_grid[}\StringTok{\textquotesingle{}demographic\_type\textquotesingle{}}\NormalTok{][row], demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{][row])}
\NormalTok{    demographic\_grid[}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{][row] }\OperatorTok{=}\NormalTok{ beta\_effect}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Define the PyMC}\label{define-the-pymc}

This section sets up the Bayesian model to estimate the additive race
effect relative to the fixed baseline.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# Create the pymc model}
\ImportTok{import}\NormalTok{ pymc }\ImportTok{as}\NormalTok{ pm}
\ImportTok{import}\NormalTok{ arviz }\ImportTok{as}\NormalTok{ az}

\ControlFlowTok{with}\NormalTok{ pm.Model() }\ImportTok{as}\NormalTok{ unemployment\_race\_model:}
    \CommentTok{\# Prior of population mean log odds}
\NormalTok{    mu\_population\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}mu\_population\_log\_odds\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{population\_mean\_log\_odds, sigma}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
    
    \CommentTok{\# Additive race effect parameter on population mean}
\NormalTok{    beta\_black }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}beta\_black\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{demographic\_grid[demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}black\_and\_african\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{], sigma}\OperatorTok{=}\FloatTok{0.3}\NormalTok{) }\CommentTok{\# Can be positive or negative}

\NormalTok{    beta\_asian }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}beta\_asian\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{demographic\_grid[demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}asian\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{], sigma}\OperatorTok{=}\FloatTok{0.3}\NormalTok{) }

\NormalTok{    beta\_white }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}beta\_white\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{demographic\_grid[demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{], sigma}\OperatorTok{=}\FloatTok{0.3}\NormalTok{) }
    
    \CommentTok{\# noise}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ pm.HalfNormal(}\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{, sigma}\OperatorTok{=}\FloatTok{0.2}\NormalTok{)}

    \CommentTok{\# log{-}odds and probabilities for each racial group}
\NormalTok{    mu\_white\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}mu\_white\_log\_odds\textquotesingle{}}\NormalTok{, mu\_population\_log\_odds }\OperatorTok{+}\NormalTok{ beta\_white)}
\NormalTok{    mu\_black\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}mu\_black\_log\_odds\textquotesingle{}}\NormalTok{, mu\_population\_log\_odds }\OperatorTok{+}\NormalTok{ beta\_black)}
\NormalTok{    mu\_asian\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}mu\_asian\_log\_odds\textquotesingle{}}\NormalTok{, mu\_population\_log\_odds }\OperatorTok{+}\NormalTok{ beta\_asian)}

\NormalTok{    p\_population }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_population\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_population\_log\_odds))}
\NormalTok{    p\_white }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_white\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_white\_log\_odds))}
\NormalTok{    p\_black }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_black\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_black\_log\_odds))}
\NormalTok{    p\_asian }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_asian\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_asian\_log\_odds))}

    \CommentTok{\# Likelihoods for observed data: use parameters like derived above to make predictions about the "true" probabilities of unemployment.}

    \CommentTok{\# predict population mean}
\NormalTok{    population\_rates\_df }\OperatorTok{=}\NormalTok{ df\_overall\_long[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(df\_overall\_long[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])]}
\NormalTok{    population\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(population\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{population\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    population\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}population\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_population\_log\_odds, }
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{population\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}

    \CommentTok{\# predict black mean}
\NormalTok{    black\_rates\_df }\OperatorTok{=}\NormalTok{ df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}black\_and\_african\textquotesingle{}}\NormalTok{]}
\NormalTok{    black\_rates\_df }\OperatorTok{=}\NormalTok{ black\_rates\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(black\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])] }
\NormalTok{    black\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(black\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{black\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    black\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}black\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_black\_log\_odds, }
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{black\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}

    \CommentTok{\# predict asian mean}
\NormalTok{    asian\_rates\_df }\OperatorTok{=}\NormalTok{ df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}asian\textquotesingle{}}\NormalTok{]}
\NormalTok{    asian\_rates\_df }\OperatorTok{=}\NormalTok{ asian\_rates\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(asian\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])] }
\NormalTok{    asian\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(asian\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{asian\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    asian\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}asian\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_asian\_log\_odds,}
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{asian\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}

    \CommentTok{\# predict white mean}
\NormalTok{    white\_rates\_df }\OperatorTok{=}\NormalTok{ df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{]}
\NormalTok{    white\_rates\_df }\OperatorTok{=}\NormalTok{ white\_rates\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(white\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])] }
\NormalTok{    white\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(white\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{white\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    white\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}white\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_white\_log\_odds,}
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{white\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}
    
    \CommentTok{\# Assign the correct probability based on race}
\NormalTok{    p\_individual\_for\_obs }\OperatorTok{=}\NormalTok{ pm.math.switch(}
\NormalTok{        df\_survey\_jun[}\StringTok{\textquotesingle{}is\_black\_african\textquotesingle{}}\NormalTok{].values,}
\NormalTok{        p\_black, }\CommentTok{\# if is\_black, use black prob}
\NormalTok{        pm.math.switch(}
\NormalTok{            df\_survey\_jun[}\StringTok{\textquotesingle{}is\_asian\textquotesingle{}}\NormalTok{].values, }
\NormalTok{            p\_asian, }\CommentTok{\# if is\_asian, use asian prob}
\NormalTok{            p\_white }\CommentTok{\# else, use white prob}
\NormalTok{        )}
\NormalTok{    )}
\NormalTok{    individual\_status\_obs }\OperatorTok{=}\NormalTok{ pm.Bernoulli(}
        \StringTok{\textquotesingle{}individual\_status\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        p}\OperatorTok{=}\NormalTok{p\_individual\_for\_obs,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{df\_survey\_jun[}\StringTok{\textquotesingle{}unemployment\_status\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Graph the PGM}\label{graph-the-pgm}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pm.model\_to\_graphviz(unemployment\_race\_model)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/index_files/figure-pdf/cell-19-output-1.pdf}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Fit the Model - Perform MCMC
Sampling}\label{fit-the-model---perform-mcmc-sampling}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"Starting MCMC sampling..."}\NormalTok{)}
\ControlFlowTok{with}\NormalTok{ unemployment\_race\_model:}
\NormalTok{    indiv\_trace }\OperatorTok{=}\NormalTok{ pm.sample(random\_seed}\OperatorTok{=}\DecValTok{5650}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Starting MCMC sampling...
\end{verbatim}

\begin{verbatim}
Output()
\end{verbatim}

\begin{verbatim}
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Analyze Results and
Visualize}\label{analyze-results-and-visualize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Analyze Results and Visualize}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{{-}{-}{-} Model Summary (Simplified Model {-} Multiple Races) {-}{-}{-}"}\NormalTok{)}
\NormalTok{az.summary(indiv\_trace, var\_names}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}mu\_population\_log\_odds\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_black\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_asian\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_white\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Convert to DataFrame}
\NormalTok{indiv\_post\_df }\OperatorTok{=}\NormalTok{ indiv\_trace.posterior.to\_dataframe().reset\_index()}
\CommentTok{\# Extract only the first chain}
\NormalTok{indiv\_post\_df }\OperatorTok{=}\NormalTok{ indiv\_post\_df[indiv\_post\_df[}\StringTok{\textquotesingle{}chain\textquotesingle{}}\NormalTok{] }\OperatorTok{==} \DecValTok{0}\NormalTok{]}
\CommentTok{\# Melt as before}
\NormalTok{indiv\_post\_df }\OperatorTok{=}\NormalTok{ indiv\_post\_df[[}\StringTok{\textquotesingle{}draw\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}beta\_black\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_asian\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_white\textquotesingle{}}\NormalTok{]].melt(id\_vars}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}draw\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Plot}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\ImportTok{import}\NormalTok{ patchworklib }\ImportTok{as}\NormalTok{ pw}
\NormalTok{ax }\OperatorTok{=}\NormalTok{ pw.Brick(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{4}\NormalTok{, }\FloatTok{2.5}\NormalTok{))}\OperatorTok{;}
\NormalTok{sns.kdeplot(}
\NormalTok{    x}\OperatorTok{=}\StringTok{"value"}\NormalTok{, hue}\OperatorTok{=}\StringTok{"variable"}\NormalTok{, data}\OperatorTok{=}\NormalTok{indiv\_post\_df, ax}\OperatorTok{=}\NormalTok{ax,}
\NormalTok{    fill}\OperatorTok{=}\VariableTok{True}\NormalTok{, bw\_adjust}\OperatorTok{=}\DecValTok{2}\NormalTok{,}
\NormalTok{)}\OperatorTok{;}
\NormalTok{ax.set\_xlabel(}\StringTok{"Log{-}Odds Deviation from Overall Mean"}\NormalTok{)}
\NormalTok{ax.set\_ylabel(}\StringTok{"Density"}\NormalTok{)}
\NormalTok{ax.set\_title(}\StringTok{"Posterior Distribution of Race Effect Deviations"}\NormalTok{)}
\NormalTok{ax.savefig()}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

--- Model Summary (Simplified Model - Multiple Races) ---
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-21-output-2.png}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\vspace{1em}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-Joseph2024}
Joseph Dean, E. S. (2024). \href{}{Gender differences in unemployment
trends: Race, jobs and the economy update for february 2024}.
\emph{NCRC}.

\bibitem[\citeproctext]{ref-TOIEducation2025}
TOIEducation. (2025). \href{}{Degrees at risk: 10 US college majors with
the highest unemployment rate in 2025}. \emph{The Times Of India}.

\bibitem[\citeproctext]{ref-Oberlo2024}
\href{}{US UNEMPLOYMENT RATE BY INDUSTRY (2024)}. (2024). \emph{Oberlo}.

\bibitem[\citeproctext]{ref-ValerieWilson2022}
Wilson, V., \& Darity-Jr., W. (2022). \href{}{Understanding black-white
disparities in labor market outcomes requires models that account for
persistent discrimination and unequal bargaining power}. \emph{Economic
Policy Institute}.

\bibitem[\citeproctext]{ref-YiLiChienandPaulMorris}
YiLi Chien, P. M. (2016). \href{}{Unemployment by industry: Duration
must be considered, too}. \emph{Federal Reserve Bank of St.Lois -
Regional Economist}.

\end{CSLReferences}




\end{document}
