% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{agujournal2019}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{url} %this package should fix any errors with URLs in refs.
\usepackage{lineno}
\usepackage[inline]{trackchanges} %for better track changes. finalnew option will compile document with changes incorporated.
\usepackage{soul}
\linenumbers
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Causal Inference of Labor Market Inequality Using PGM: A multidimensional analysis of unemployment rate and durations},
  pdfauthor={Mengjia Wei},
  pdfkeywords={PGM, Unemployment Rate, Unemployment Durations, Causal
Inference},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\journalname{Georgetown Univeristy DSAN 5650 Journal}

\draftfalse

\begin{document}
\title{Causal Inference of Labor Market Inequality Using PGM: A
multidimensional analysis of unemployment rate and durations}

\authors{Mengjia Wei\affil{1}}
\affiliation{1}{Georgetown University, }



\begin{abstract}
In its revised report released on July 31, 2025, the U.S. Bureau of
Labor Statistics (BLS) reported a sharp slowdown in job creation
beginning in May, signaling heightened uncertainty and growing concerns
about the overall health of the U.S. labor market. This study
investigates the causal relationships between race, industry and
unemployment rates in the United States, applying~probabilistic
graphical modeling (PGM)~to uncover latent dependency structures across
demographic and industry variables. Using a PGM framework, we extend
this approach to labor market data by constructing conditional
dependence networks across two key dimensions: group attributes (race
and industry) and time (2024 vs.~2025). Specifically, the study examines
recent college graduates (ages 22--24) relative to older individuals
(25+), comparing their unemployment rates across 2024 and 2025. This
study first examined the race effect on the unemployment rate disparitu.
The industry-specific unemployment rate dynamics focuses on {[}retail{]}
{[}{]} and {[}Leisure and hospitality{]} sectors. This analysis seeks to
identify whether certain groups---such as Black labor force and
{[}Retail Industry{]}---face higher or lower unemployment, providing a
more comprehensive view of labor market hardship. The model estimates
the strength and direction of probabilistic dependencies using Bayesian
structure learning algorithms, based on labor force aggregated data from
BLS CPS datasets. The results indicate that {[}conclusion1{]}.
Additionally, the {[}retail{]}, {[}{]}, and {[}technology{]} industries
experienced increased unemployment rates between the year of 2015 and
the year of 2025, with respective changes of~{[} {]},~{[} {]}, and~{[}
{]}~percentage points. The PGM framework reveals significant interactive
effects between race and industry on unemployment, particularly among
Black workers~and the~{[}retail and hospitality{]}~sectors. These
findings contribute to the growing literature that leverages PGMs for
social inference (e.g., Li et al., 2022), highlighting the model's
potential for uncovering structural labor inequalities over time and
across population subgroups.
\end{abstract}

\section*{Plain Language Summary}
TBD




\section{Introduction}\label{introduction}

The interplay of demographic characteristics and labor market dynamics
consistently reveals significant disparities in unemployment rates.
Decades of research reveal a persistent relationship between race,
gender, and unemployment, evident across diverse economic cycles. Though
the Black unemployment rate fell to a historic low of 6.1\% in 2019, it
was still twice as high as the White unemployment rate of 3.0\%, as
Wilson \& Darity-Jr. (2022) observed. These disparities are further
magnified at the intersection of race and gender. For instance, Black
men faced a 6.1\% unemployment rate in February 2024, notably higher
than Black women at 4.4\%. Similarly, Hispanic women's unemployment rate
increased to 5.0\% in February 2024, while Hispanic men experienced a
decrease to 4.0\% (Joseph Dean (2024)). Native American men also
experienced higher unemployment (10\%) than Native American women (7\%)
in 2022. Industry-specific analyses similarly highlight divergent
unemployment trends. The Leisure and Hospitality sector reported the
highest unemployment rate at 6.0\% in 2024, an increase from 5.5\% in
2023. Similarly, Wholesale and Retail Trade experienced elevated
unemployment, reaching 4.7\% in October 2024, up from 4.0\% in 2023.
Conversely, Financial Activities maintained a significantly lower
unemployment rate of 1.9\% ({``US UNEMPLOYMENT RATE BY INDUSTRY
(2024)''} (2024)).

Research from the U.S. Bureau of Labor Statistics consistently shows
longer unemployment spells in sectors such as Manufacturing and
Construction, while industries demanding specialized skills like
Education and Health Services exhibit shorter durations. Study by YiLi
Chien (2016) reveals negative correlation between the unemployment rate
and duration. Such variations in both the rate and duration of
unemployment underscore complex interactions among race, gender, age,
and industry.

TOIEducation (2025) published that the labor market for recent college
graduates has ``deteriorated noticeably'' in the first quarter of 2025.
The unemployment rate for this cohort (ages 22-27) ranged from 5.5\% to
7.1\%, exceeding the overall national average of 4.1-4.2\%, with
Anthropology (9.4\%), Physics (7.8\%), and Computer Engineering (7.5\%)
showing among the highest rates.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/unemployment_rate_recent_graduate.png}}

}

\caption{\label{fig-graduates}Unemployment Rate of Recent College
Graduates}

\end{figure}%

Although the Federal Open Market Committee (FOMC) reported a low overall
unemployment rate for June 2025 (Based on the U.S. Bureau of Labor
Statistics (BLS) revised job creation data released on July 31, 2025, a
marked decline in job creation has been observed beginning in May,
raising substantial concerns regarding the stability of the U.S. labor
market.), recent data clearly indicate a noticeable uptick in the
unemployment rate for the 22-27 age group since March, reaching 2021
levels and particularly affecting recent college graduates
(Figure~\ref{fig-graduates}).

\section{Data}\label{data}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}llll@{}}

\caption{\label{tbl-monthly-unemployment-rate-race}BLS 2015-2025 Monthly
Unemployment Rate By Race}

\tabularnewline

\caption{}\label{T_c9f29}\tabularnewline
\toprule\noalign{}
Year & Month & Unemployment\_rate & Race \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Year & Month & Unemployment\_rate & Race \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2015 & Jan & 5.30 & white \\
2016 & Jan & 4.70 & white \\
2017 & Jan & 4.70 & white \\
2018 & Jan & 3.90 & white \\
2019 & Jan & 4.00 & white \\
2020 & Jan & 3.50 & white \\
2021 & Jan & 6.20 & white \\
2022 & Jan & 3.90 & white \\
2023 & Jan & 3.50 & white \\
2024 & Jan & 3.80 & white \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Data from the U.S. Bureau of Labor Statistics (BLS) 2015 to 2025 monthly
aggregated unemployment rate by races. This dataset is used to analyze
the race effect on unemployment along with the monthly unemployment rate
aggregated data by race
(Table~\ref{tbl-monthly-unemployment-rate-race}).

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}llllllll@{}}

\caption{\label{tbl-survey-data-jun2025}BLS June 2025 Labor Force Survey
Data}

\tabularnewline

\caption{}\label{T_34704}\tabularnewline
\toprule\noalign{}
sex\_name & race\_name & education\_attainment\_name &
employment\_status\_name & industry\_name & is\_black\_african &
is\_asian & is\_white \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
sex\_name & race\_name & education\_attainment\_name &
employment\_status\_name & industry\_name & is\_black\_african &
is\_asian & is\_white \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
male & white & bachelors\_degree & employed & Construction & 0 & 0 &
1 \\
male & white & high\_school & employed & Construction & 0 & 0 & 1 \\
female & white & bachelors\_degree & employed & Manufacturing & 0 & 0 &
1 \\
male & white & bachelors\_degree & employed & Manufacturing & 0 & 0 &
1 \\
female & white & masters\_degree & employed & Transportation and
utilities & 0 & 0 & 1 \\
female & white & bachelors\_degree & employed & Construction & 0 & 0 &
1 \\
male & white & high\_school & employed & Wholesale and retail trade & 0
& 0 & 1 \\
female & white & bachelors\_degree & employed & Professional and
business services & 0 & 0 & 1 \\
male & white & less\_than\_high\_school & employed & Professional and
business services & 0 & 0 & 1 \\
female & white & high\_school & employed & Educational and health
services & 0 & 0 & 1 \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Data from the U.S. Bureau of Labor Statistics (BLS) June 2025 labor
force survey provide individual-level employment status and
corresponding demographic information. For the purpose of this study, a
subset of these relevant columns is utilized
(Table~\ref{tbl-survey-data-jun2025}). This dataset is used to sample
and predict employment status using the observations in the survey data.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}lllll@{}}

\caption{\label{tbl-survey-data-2024-2025}BLS 2024 - 2025 Jan - Jul
Labor Force Survey Data}

\tabularnewline

\caption{}\label{T_37ec8}\tabularnewline
\toprule\noalign{}
industry & employment\_status & month\_year & industry\_name &
employment\_status\_description \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
industry & employment\_status & month\_year & industry\_name &
employment\_status\_description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
11 & 1 & jan\_2024 & Leisure and hospitality & employed \\
11 & 1 & jan\_2024 & Leisure and hospitality & employed \\
10 & 1 & jan\_2024 & Educational and health services & employed \\
5 & 1 & jan\_2024 & Wholesale and retail trade & employed \\
4 & 4 & jan\_2024 & Manufacturing & unemployed \\
8 & 1 & jan\_2024 & Financial activities & employed \\
9 & 1 & jan\_2024 & Professional and business services & employed \\
5 & 1 & jan\_2024 & Wholesale and retail trade & employed \\
4 & 1 & jan\_2024 & Manufacturing & employed \\
4 & 1 & jan\_2024 & Manufacturing & employed \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Data from the U.S. Bureau of Labor Statistics (BLS) historical monthly
labor force survey provide individual-level employment status by
industries. For the purpose of this study, we utilized 2024 Jan to Jul
and 2025 Jan to Jun data. (Table~\ref{tbl-survey-data-2024-2025}). This
dataset is used to analyze the industry effect on unemployment rate in
the recent 2 years.

\section{EDA}\label{eda}

\subsection{Unemployment Rates of Differenet
Races}\label{unemployment-rates-of-differenet-races}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Race
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-7-output-2.png}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Sex
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-7-output-4.png}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Industry
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-7-output-6.png}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Age
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-7-output-8.png}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Unemployment Rate Distribution Histograms By Education_attainment
\end{verbatim}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-unemployment-rate-demographics-output-2.png}}

}

\caption{\label{fig-histogram-unemployment-rate-demographics}Unemployment
Rate Distributions By Demographics (2015-2025 statistics)}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

BLS data from 2015--2025 indicate that the Black or African American
population experienced the highest average unemployment rate (7.5\%),
primarily within the 5--10\% range. Gender differences are minimal, with
both averaging around 5\%, though rates are slightly higher for men.
Among industries, Leisure and Hospitality recorded the highest
unemployment (10\%) with a long-tail distribution, followed by
Agriculture (5--11\%) and moderate variability. Construction and
Mining/Oil \& Gas exhibit similar but marginally lower patterns. The
22--24 age group stands out with significantly elevated
unemployment---averaging 7\% and predominantly above 5\%---while other
age groups display lower and more uniform rates. Financial Activities
show the lowest and most stable unemployment, consistently under 5\%.
Individuals without a high school diploma face high and variable
unemployment, averaging 7\% with a long-tail skew. These patterns
suggest that young adults (22--24), Black or African Americans without
college degrees, and those employed in Leisure, Construction, or Mining
sectors are disproportionately affected by higher unemployment.
(Figure~\ref{fig-histogram-unemployment-rate-demographics}).

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-unemployment-rate-output-1.png}}

}

\caption{\label{fig-histogram-unemployment-rate}Overall Population
Unemployment Rate Distributions (2015-2025 statistics)}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

According to BLS data from 2015--2025, the overall population
unemployment rate averaged slightly above 4\%, with the majority of
observations concentrated between 2\% and 5\% and exhibiting relatively
low variability (Figure~\ref{fig-histogram-unemployment-rate}).

\subsection{Unemployment Rates of Differenet
Industries}\label{unemployment-rates-of-differenet-industries}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-boxplot-unemployment-rate-industry-output-1.png}}

}

\caption{\label{fig-boxplot-unemployment-rate-industry}Unemployment Rate
Distributions By Industries (2015-2025 statistics)}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

The boxplot illustrates notable variation in unemployment rates across
industries. ``Agricultural, mining/oil/gas extraction'' and
``Construction'' industries exhibit the highest variation and upper
extremes, indicating greater instability in employment. Due to the
volatility and unpredictivity as a result of seasonlity, these two
categories are going to be excluded from our analysis. In contrast,
``Government'', ``Financial services'', and ``Education/health
services'' show consistently low and stable unemployment rates, with
narrower interquartile ranges and fewer outliers. These patterns suggest
structural differences in labor market vulnerability across sectors.
(Figure~\ref{fig-boxplot-unemployment-rate-industry}).

\section{PGM}\label{pgm}

We posit that unemployment vulnerability is driven by structural
inequalities within the labor market, particularly those rooted in
demographic and industrial dimensions. Demographic disparities are
represented by variables such as race, age, and educational attainment
and industry; sex is excluded from the analysis due to prior findings
indicating minimal impact on unemployment rates. Establishing a baseline
unemployment level is a necessary step before assessing the marginal
effects of these demographic and industrial factors.

\subsection{Baseline unemployment rate
distribution}\label{baseline-unemployment-rate-distribution}

Figure 3 illustrates that the population unemployment rate is
right-skewed, suggesting that the Log-Normal distribution is an
appropriate model. We are going to estimate the parameters of a
Log-Normal distribution from the population distribution data using MLE.
(\(\sigma\), \(\text{loc}\), and \(\text{scale}\)).

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Fitted Log-Norm Distribution Parameters:
  Shape parameter 'alpha'): 9.92
  Location parameter (loc): 3.20
  Scale parameter (scale): 0.03
\end{verbatim}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-lognorm-output-2.png}}

}

\caption{\label{fig-histogram-lognorm}Unmployment Rate Histogram
vs.~Fitted Log-Norm PDF}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

By overlaying the smooth PDF curve on top of original data's histogram,
we can visualize that the Log-Normal distribution matches the
distribution of the actual data. The peak of the PDF align with the peak
of the histogram. The spread of the PDF roughly match the spread of the
data, including the tail (Figure~\ref{fig-histogram-lognorm}). Now we
need to use Kolmogorov-Smirnov Test to test Goodness-of-fit with the
original data and estimated parameters, then examine the p value.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Kolmogorov-Smirnov Test Results:
  D-statistic: 0.4592
  P-value: 0.0000
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

With \(p\)-value \textless{} 0.05, we can't reject the hypothesis that
the distribution does not come from the Log-Normal distribution,
suggesting Log-Normal is not a good fit for the data. Next, explore
other right-skewed distributions - Gamma distribution or the Weibull
distribution.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Fitted Gamma Distribution Parameters:
  Shape parameter 'alpha': 0.45
  Location parameter 'loc': 3.20
  Scale parameter 'scale'): 1.36
\end{verbatim}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-gamma-output-2.png}}

}

\caption{\label{fig-histogram-gamma}Unmployment Rate Histogram
vs.~Fitted Gamma PDF}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Although visually the Gamma distribution matches the shape and spread of
the actual data. (Figure~\ref{fig-histogram-gamma}), we need to use KS
Test to test Goodness-of-fit by examining the p value.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

Kolmogorov-Smirnov Test Results:
  D-statistic: 0.2699
  P-value: 0.0000
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

Again, with \(p\)-value \textless{} 0.05, we can not confidently say
that the data comes from the Gamma distribution. Next, explore Weibull
distribution.

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-histogram-weibull-output-1.png}}

}

\caption{\label{fig-histogram-weibull}Unmployment Rate Histogram
vs.~Fitted Weibull PDF}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}ll@{}}

\caption{\label{tbl-weibull-params}Weibull Distribution and Fitness
Statistics}

\tabularnewline

\caption{}\label{T_65bf9}\tabularnewline
\toprule\noalign{}
Parameters & Values \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Parameters & Values \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Shape (c) & 0.709300 \\
Location (loc) & 3.200000 \\
Scale & 0.920400 \\
D\_statistics & 0.104700 \\
P-value & 0.117300 \\
Fitted Mean & 4.350000 \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

The overlayed smooth PDF curve on top of original data's histogram
Figure~\ref{fig-histogram-weibull} suggests that the Weibull
distribution matches the distribution of the actual data. The results of
the Weibull distribution, summarized in Table
Table~\ref{tbl-weibull-params}, including the shape, location, and scale
parameters, along with the D-statistic, P-value, and fitted mean also
proves Weibull distribution is a good fit, supported by a KS test
p-value of 0.1173 (greater than 0.05). The estimated parameters
(c=0.7093, loc=3.2000, scale=0.9204) align well with the spread of the
data. Shape (c\textless1): Confirms the strong right-skewness of the
data. Location (loc=3.2000): Indicates the distribution starts around
3.20, matching data's lower bound. Inferred Mean: The calculated mean of
approximately 4.35 from these parameters is close but slightly higher
than the data's actual mean of around 4, showing a good capture of
central tendency.

\subsection{Define the prior means for overall
population}\label{define-the-prior-means-for-overall-population}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#\# population unemployment mean probability from the fitted Weibull distribution}
\NormalTok{weibull\_fitted\_mean\_prob }\OperatorTok{=} \FloatTok{0.0435}
\CommentTok{\# Convert the fitted mean probability to its log{-}odds equivalent in order to model binary outcome with logistic regression}
\NormalTok{population\_mean\_log\_odds }\OperatorTok{=}\NormalTok{ np.log(weibull\_fitted\_mean\_prob }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ weibull\_fitted\_mean\_prob))}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Define the prior means by
races}\label{define-the-prior-means-by-races}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Function to find the means of different demographics}
\KeywordTok{def}\NormalTok{ mean\_prob\_demographic(df\_name, demographic\_type, demographic\_description):}
\NormalTok{    demographic\_mean\_prob }\OperatorTok{=}\NormalTok{ df\_dic[df\_name].loc[df\_dic[df\_name][demographic\_type]}\OperatorTok{==}\NormalTok{demographic\_description][}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{].mean()}\OperatorTok{/}\DecValTok{100}
\NormalTok{    demographic\_mean\_log\_odds }\OperatorTok{=}\NormalTok{ np.log(demographic\_mean\_prob }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ demographic\_mean\_prob))}
    \CommentTok{\# beta\_effect is the difference between the demographic group mean log{-}odds and the population mean log{-}odds}
\NormalTok{    beta\_effect }\OperatorTok{=}\NormalTok{ demographic\_mean\_log\_odds }\OperatorTok{{-}}\NormalTok{ population\_mean\_log\_odds}
    \ControlFlowTok{return}\NormalTok{ beta\_effect}

\CommentTok{\# Create a grid of demographic information to return the means}
\NormalTok{demographic\_grid }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{"df\_name"}\NormalTok{:[}
        \StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}Race\textquotesingle{}}
\NormalTok{    ],}
    \StringTok{"demographic\_type"}\NormalTok{:[}
        \StringTok{"Race"}\NormalTok{, }
        \StringTok{"Race"}\NormalTok{,}
        \StringTok{"Race"}
\NormalTok{    ],}
    \StringTok{"demographic\_description"}\NormalTok{:[}
        \StringTok{\textquotesingle{}black\_and\_african\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{,}
        \StringTok{\textquotesingle{}asian\textquotesingle{}}
\NormalTok{    ]}
\NormalTok{\})}
\CommentTok{\# Return the beta\_effect of different demographics}
\NormalTok{demographic\_grid[}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{]}\OperatorTok{=}\NormalTok{ np.float64(}\DecValTok{0}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ row }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{,}\BuiltInTok{len}\NormalTok{(demographic\_grid)):}
    \CommentTok{\# Mean of demographic groups}
\NormalTok{    beta\_effect }\OperatorTok{=}\NormalTok{ mean\_prob\_demographic(demographic\_grid[}\StringTok{\textquotesingle{}df\_name\textquotesingle{}}\NormalTok{][row], demographic\_grid[}\StringTok{\textquotesingle{}demographic\_type\textquotesingle{}}\NormalTok{][row], demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{][row])}
\NormalTok{    demographic\_grid[}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{][row] }\OperatorTok{=}\NormalTok{ beta\_effect}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Define the unemployment-race
PyMC}\label{define-the-unemployment-race-pymc}

This section sets up the Bayesian model to estimate the additive race
effect relative to the fixed baseline.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create the pymc model}
\ImportTok{import}\NormalTok{ pymc }\ImportTok{as}\NormalTok{ pm}
\ImportTok{import}\NormalTok{ arviz }\ImportTok{as}\NormalTok{ az}

\ControlFlowTok{with}\NormalTok{ pm.Model() }\ImportTok{as}\NormalTok{ unemployment\_race\_model:}
    \CommentTok{\# Prior of population mean log odds}
\NormalTok{    mu\_population\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}mu\_population\_log\_odds\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{population\_mean\_log\_odds, sigma}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
    
    \CommentTok{\# Additive race effect parameter on population mean}
\NormalTok{    beta\_black }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}beta\_black\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{demographic\_grid[demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}black\_and\_african\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{], sigma}\OperatorTok{=}\FloatTok{0.3}\NormalTok{) }\CommentTok{\# Can be positive or negative}

\NormalTok{    beta\_asian }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}beta\_asian\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{demographic\_grid[demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}asian\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{], sigma}\OperatorTok{=}\FloatTok{0.3}\NormalTok{) }

\NormalTok{    beta\_white }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{\textquotesingle{}beta\_white\textquotesingle{}}\NormalTok{, mu}\OperatorTok{=}\NormalTok{demographic\_grid[demographic\_grid[}\StringTok{\textquotesingle{}demographic\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}beta\_effect\textquotesingle{}}\NormalTok{], sigma}\OperatorTok{=}\FloatTok{0.3}\NormalTok{) }
    
    \CommentTok{\# noise}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ pm.HalfNormal(}\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{, sigma}\OperatorTok{=}\FloatTok{0.2}\NormalTok{)}

    \CommentTok{\# log{-}odds and probabilities for each racial group}
\NormalTok{    mu\_white\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}mu\_white\_log\_odds\textquotesingle{}}\NormalTok{, mu\_population\_log\_odds }\OperatorTok{+}\NormalTok{ beta\_white)}
\NormalTok{    mu\_black\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}mu\_black\_log\_odds\textquotesingle{}}\NormalTok{, mu\_population\_log\_odds }\OperatorTok{+}\NormalTok{ beta\_black)}
\NormalTok{    mu\_asian\_log\_odds }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}mu\_asian\_log\_odds\textquotesingle{}}\NormalTok{, mu\_population\_log\_odds }\OperatorTok{+}\NormalTok{ beta\_asian)}

\NormalTok{    p\_population }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_population\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_population\_log\_odds))}
\NormalTok{    p\_white }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_white\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_white\_log\_odds))}
\NormalTok{    p\_black }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_black\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_black\_log\_odds))}
\NormalTok{    p\_asian }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{\textquotesingle{}p\_asian\textquotesingle{}}\NormalTok{, pm.math.invlogit(mu\_asian\_log\_odds))}

    \CommentTok{\# Likelihoods for observed data: use parameters like derived above to make predictions about the "true" probabilities of unemployment.}

    \CommentTok{\# predict population mean}
\NormalTok{    population\_rates\_df }\OperatorTok{=}\NormalTok{ df\_overall\_long[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(df\_overall\_long[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])]}
\NormalTok{    population\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(population\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{population\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    population\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}population\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_population\_log\_odds, }
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{population\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}

    \CommentTok{\# predict black mean}
\NormalTok{    black\_rates\_df }\OperatorTok{=}\NormalTok{ df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}black\_and\_african\textquotesingle{}}\NormalTok{]}
\NormalTok{    black\_rates\_df }\OperatorTok{=}\NormalTok{ black\_rates\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(black\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])] }
\NormalTok{    black\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(black\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{black\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    black\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}black\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_black\_log\_odds, }
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{black\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}

    \CommentTok{\# predict asian mean}
\NormalTok{    asian\_rates\_df }\OperatorTok{=}\NormalTok{ df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}asian\textquotesingle{}}\NormalTok{]}
\NormalTok{    asian\_rates\_df }\OperatorTok{=}\NormalTok{ asian\_rates\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(asian\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])] }
\NormalTok{    asian\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(asian\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{asian\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    asian\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}asian\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_asian\_log\_odds,}
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{asian\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}

    \CommentTok{\# predict white mean}
\NormalTok{    white\_rates\_df }\OperatorTok{=}\NormalTok{ df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][df\_dic[}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{]}
\NormalTok{    white\_rates\_df }\OperatorTok{=}\NormalTok{ white\_rates\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{np.isnan(white\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{])] }
\NormalTok{    white\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(white\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{{-}}\NormalTok{white\_rates\_df[}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{]}\OperatorTok{*}\FloatTok{0.01}\NormalTok{))}
\NormalTok{    white\_rates\_obs }\OperatorTok{=}\NormalTok{ pm.Normal(}
        \StringTok{\textquotesingle{}white\_rates\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        mu}\OperatorTok{=}\NormalTok{mu\_white\_log\_odds,}
\NormalTok{        sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{white\_rates\_df[}\StringTok{\textquotesingle{}rate\_logit\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}
    
    \CommentTok{\# Assign the correct probability based on race}
\NormalTok{    p\_individual\_for\_obs }\OperatorTok{=}\NormalTok{ pm.math.switch(}
\NormalTok{        df\_survey\_jun[}\StringTok{\textquotesingle{}is\_black\_african\textquotesingle{}}\NormalTok{].values,}
\NormalTok{        p\_black, }\CommentTok{\# if is\_black, use black prob}
\NormalTok{        pm.math.switch(}
\NormalTok{            df\_survey\_jun[}\StringTok{\textquotesingle{}is\_asian\textquotesingle{}}\NormalTok{].values, }
\NormalTok{            p\_asian, }\CommentTok{\# if is\_asian, use asian prob}
\NormalTok{            p\_white }\CommentTok{\# else, use white prob}
\NormalTok{        )}
\NormalTok{    )}
\NormalTok{    individual\_status\_obs }\OperatorTok{=}\NormalTok{ pm.Bernoulli(}
        \StringTok{\textquotesingle{}individual\_status\_obs\textquotesingle{}}\NormalTok{,}
\NormalTok{        p}\OperatorTok{=}\NormalTok{p\_individual\_for\_obs,}
\NormalTok{        observed}\OperatorTok{=}\NormalTok{df\_survey\_jun[}\StringTok{\textquotesingle{}unemployment\_status\textquotesingle{}}\NormalTok{].values}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Graph the unemployment-race
PGM}\label{graph-the-unemployment-race-pgm}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pm.model\_to\_graphviz(unemployment\_race\_model)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/index_files/figure-pdf/cell-21-output-1.pdf}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Fit the unemployment-race Model - Perform MCMC
Sampling}\label{fit-the-unemployment-race-model---perform-mcmc-sampling}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"Starting MCMC sampling..."}\NormalTok{)}
\ControlFlowTok{with}\NormalTok{ unemployment\_race\_model:}
\NormalTok{    indiv\_trace }\OperatorTok{=}\NormalTok{ pm.sample(random\_seed}\OperatorTok{=}\DecValTok{5650}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Starting MCMC sampling...
\end{verbatim}

\begin{verbatim}
Output()
\end{verbatim}

\begin{verbatim}
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\subsection{Analyze unemployment-race Results and
Visualize}\label{analyze-unemployment-race-results-and-visualize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Analyze Results and Visualize}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{{-}{-}{-} Model Summary (Simplified Model {-} Multiple Races) {-}{-}{-}"}\NormalTok{)}
\NormalTok{display(pd.DataFrame(az.summary(indiv\_trace, var\_names}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}mu\_population\_log\_odds\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_black\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_asian\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_white\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{])))}

\CommentTok{\# Trace plot}
\NormalTok{fig\_trace }\OperatorTok{=}\NormalTok{ az.plot\_trace(indiv\_trace)}
\NormalTok{plt.suptitle(}\StringTok{\textquotesingle{}Trace plot\textquotesingle{}}\NormalTok{, fontsize}\OperatorTok{=}\DecValTok{16}\NormalTok{)}
\NormalTok{plt.subplots\_adjust(hspace}\OperatorTok{=}\FloatTok{0.5}\NormalTok{) }

\CommentTok{\# Convert to DataFrame}
\NormalTok{indiv\_post\_df }\OperatorTok{=}\NormalTok{ indiv\_trace.posterior.to\_dataframe().reset\_index()}
\CommentTok{\# Extract only the first chain}
\NormalTok{indiv\_post\_df }\OperatorTok{=}\NormalTok{ indiv\_post\_df[indiv\_post\_df[}\StringTok{\textquotesingle{}chain\textquotesingle{}}\NormalTok{] }\OperatorTok{==} \DecValTok{0}\NormalTok{]}
\CommentTok{\# Melt}
\NormalTok{indiv\_post\_df }\OperatorTok{=}\NormalTok{ indiv\_post\_df[[}\StringTok{\textquotesingle{}draw\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}beta\_black\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_asian\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\_white\textquotesingle{}}\NormalTok{]].melt(id\_vars}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}draw\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Density plot}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\ImportTok{import}\NormalTok{ patchworklib }\ImportTok{as}\NormalTok{ pw}
\NormalTok{ax }\OperatorTok{=}\NormalTok{ pw.Brick(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{4}\NormalTok{, }\FloatTok{2.5}\NormalTok{))}\OperatorTok{;}
\NormalTok{sns.kdeplot(}
\NormalTok{    x}\OperatorTok{=}\StringTok{"value"}\NormalTok{, hue}\OperatorTok{=}\StringTok{"variable"}\NormalTok{, data}\OperatorTok{=}\NormalTok{indiv\_post\_df, ax}\OperatorTok{=}\NormalTok{ax,}
\NormalTok{    fill}\OperatorTok{=}\VariableTok{True}\NormalTok{, bw\_adjust}\OperatorTok{=}\DecValTok{2}\NormalTok{,}
\NormalTok{)}\OperatorTok{;}
\NormalTok{ax.set\_xlabel(}\StringTok{"Log{-}Odds Deviation from Overall Mean"}\NormalTok{)}
\NormalTok{ax.set\_ylabel(}\StringTok{"Density"}\NormalTok{)}
\NormalTok{ax.set\_title(}\StringTok{"Posterior Distribution of Race Effect Deviations"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}

--- Model Summary (Simplified Model - Multiple Races) ---
\end{verbatim}

\begin{longtable}[]{@{}llllllllll@{}}
\toprule\noalign{}
& mean & sd & hdi\_3\% & hdi\_97\% & mcse\_mean & mcse\_sd & ess\_bulk &
ess\_tail & r\_hat \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
mu\_population\_log\_odds & -3.146 & 0.028 & -3.199 & -3.093 & 0.001 &
0.000 & 1539.0 & 1941.0 & 1.0 \\
beta\_black{[}0{]} & 0.565 & 0.038 & 0.497 & 0.640 & 0.001 & 0.001 &
1845.0 & 2677.0 & 1.0 \\
beta\_asian{[}0{]} & -0.149 & 0.039 & -0.218 & -0.075 & 0.001 & 0.001 &
1859.0 & 2245.0 & 1.0 \\
beta\_white{[}0{]} & -0.128 & 0.034 & -0.191 & -0.065 & 0.001 & 0.000 &
1772.0 & 2332.0 & 1.0 \\
sigma & 0.320 & 0.010 & 0.301 & 0.340 & 0.000 & 0.000 & 3604.0 & 2570.0
& 1.0 \\
\end{longtable}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-23-output-3.png}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-23-output-4.png}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

The posterior distributions of racial group mean log-odds for
unemployment reveal clear deviations, with the Black population
exhibiting a higher rate compared to both the White and Asian
populations.

\subsection{PGM for
unemployment-industry}\label{pgm-for-unemployment-industry}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# 1. Exclude some industries and persons "not in labor force" and industries that don\textquotesingle{}t have historical unemployment stats}
\NormalTok{survey\_df\_industry }\OperatorTok{=}\NormalTok{ survey\_df[}\OperatorTok{\textasciitilde{}}\NormalTok{survey\_df[}\StringTok{\textquotesingle{}industry\_name\textquotesingle{}}\NormalTok{].isin([}\StringTok{\textquotesingle{}Construction\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}Mining\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}Other services\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}Agriculture, forestry, fishing, and hunting\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}Armed Forces\textquotesingle{}}\NormalTok{])]}
\NormalTok{survey\_df\_industry }\OperatorTok{=}\NormalTok{ survey\_df\_industry[survey\_df\_industry[}\StringTok{\textquotesingle{}employment\_status\_description\textquotesingle{}}\NormalTok{]}\OperatorTok{!=}\StringTok{"not in labor force"}\NormalTok{]}
\CommentTok{\#\# Factorize the industry\_name column to get numerical indices and names}
\NormalTok{industry\_idx, industry\_names }\OperatorTok{=}\NormalTok{ survey\_df\_industry[}\StringTok{\textquotesingle{}industry\_name\textquotesingle{}}\NormalTok{].factorize()}
\NormalTok{survey\_df\_industry[}\StringTok{\textquotesingle{}industry\_idx\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ industry\_idx}
\CommentTok{\#\# Map EmploymentStatus to numerical (0 for Employed, 1 for Unemployed)}
\NormalTok{survey\_df\_industry[}\StringTok{\textquotesingle{}unemployment\_status\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ survey\_df\_industry[}\StringTok{\textquotesingle{}employment\_status\_description\textquotesingle{}}\NormalTok{].}\BuiltInTok{map}\NormalTok{(\{}\StringTok{\textquotesingle{}employed\textquotesingle{}}\NormalTok{: }\DecValTok{0}\NormalTok{, }\StringTok{\textquotesingle{}unemployed\textquotesingle{}}\NormalTok{: }\DecValTok{1}\NormalTok{\})}

\CommentTok{\#\# 2. Get the prior means and sds of unemployment rates by industries from the historical monthly statistics (exlcuding 2020{-}2021)}
\NormalTok{df\_industry\_monthly\_ur }\OperatorTok{=}\NormalTok{ df\_industry[}\OperatorTok{\textasciitilde{}}\NormalTok{df\_industry[}\StringTok{\textquotesingle{}Industry\textquotesingle{}}\NormalTok{].isin([}\StringTok{\textquotesingle{}construction\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}mining\_quarrying\_and\_oil\_and\_gas\_ extraction\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}other\_services\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}agricultural\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}self\_employed\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}non\_durable\_goods\textquotesingle{}}\NormalTok{,}
                              \StringTok{\textquotesingle{}durable\_goods\textquotesingle{}}\NormalTok{])]}

\NormalTok{ur\_by\_industry }\OperatorTok{=}\NormalTok{ pd.DataFrame(df\_industry\_monthly\_ur.groupby(}\StringTok{\textquotesingle{}Industry\textquotesingle{}}\NormalTok{, as\_index}\OperatorTok{=}\VariableTok{False}\NormalTok{).agg(}
\NormalTok{    mean\_ur }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{),}
\NormalTok{    sd\_ur }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Unemployment\_rate\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}std\textquotesingle{}}\NormalTok{)}
\NormalTok{))}
 \CommentTok{\# modify the industry name column to align with industry\_names}
\NormalTok{ur\_by\_industry[}\StringTok{\textquotesingle{}Industry\textquotesingle{}}\NormalTok{]}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Educational and health services\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Financial activities\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Public administration\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Information\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Leisure and hospitality\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Manufacturing\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Professional and business services\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Transportation and utilities\textquotesingle{}}\NormalTok{,}
                            \StringTok{\textquotesingle{}Wholesale and retail trade\textquotesingle{}}\NormalTok{]}
\CommentTok{\# Logit transformation function}
\KeywordTok{def}\NormalTok{ logit(p):}
    \ControlFlowTok{return}\NormalTok{ np.log(p }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ p))}
\NormalTok{ur\_by\_industry[}\StringTok{\textquotesingle{}mean\_ur\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ logit(ur\_by\_industry[}\StringTok{\textquotesingle{}mean\_ur\textquotesingle{}}\NormalTok{]}\OperatorTok{/}\DecValTok{100}\NormalTok{)}
\NormalTok{ur\_by\_industry[}\StringTok{\textquotesingle{}sd\_ur\_logit\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ logit(ur\_by\_industry[}\StringTok{\textquotesingle{}sd\_ur\textquotesingle{}}\NormalTok{]}\OperatorTok{/}\DecValTok{100}\NormalTok{)}

\CommentTok{\#\# 3. Define the Adaptive pooling PyMC model}
\CommentTok{\# priors}
\NormalTok{ur\_by\_industry\_copy }\OperatorTok{=}\NormalTok{ ur\_by\_industry.copy()}
\NormalTok{ur\_by\_industry\_copy }\OperatorTok{=}\NormalTok{ ur\_by\_industry\_copy.set\_index(}\StringTok{\textquotesingle{}Industry\textquotesingle{}}\NormalTok{)}
\NormalTok{prior\_mu\_alpha\_vals }\OperatorTok{=}\NormalTok{ np.array([ur\_by\_industry\_copy.loc[ind, }\StringTok{\textquotesingle{}mean\_ur\_logit\textquotesingle{}}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ ind }\KeywordTok{in}\NormalTok{ industry\_names])}
\NormalTok{prior\_sigma\_alpha\_vals }\OperatorTok{=}\NormalTok{ np.array([ur\_by\_industry\_copy.loc[ind, }\StringTok{\textquotesingle{}sd\_ur\_logit\textquotesingle{}}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ ind }\KeywordTok{in}\NormalTok{ industry\_names])}
\CommentTok{\# Define the PGM model}
\NormalTok{coords }\OperatorTok{=}\NormalTok{ \{}\StringTok{"industry"}\NormalTok{: industry\_names\}}
\ControlFlowTok{with}\NormalTok{ pm.Model(coords}\OperatorTok{=}\NormalTok{coords) }\ImportTok{as}\NormalTok{ adaptive\_unemployment\_industry\_model:}
\NormalTok{    industry\_idx\_obs }\OperatorTok{=}\NormalTok{ pm.Data(}\StringTok{"industry\_idx\_obs"}\NormalTok{, survey\_df\_industry[}\StringTok{\textquotesingle{}industry\_idx\textquotesingle{}}\NormalTok{].values, dims}\OperatorTok{=}\StringTok{"obs\_id"}\NormalTok{)}
    \CommentTok{\# Global Priors }
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ pm.Exponential(}\StringTok{"sigma"}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# standard deviation for alpha\_industry}
    \CommentTok{\# Industry{-}Specific Parameters {-} observed industry means}
\NormalTok{    mu\_alpha\_industry }\OperatorTok{=}\NormalTok{ pm.Data(}\StringTok{"mu\_alpha\_industry"}\NormalTok{, prior\_mu\_alpha\_vals, dims}\OperatorTok{=}\StringTok{"industry"}\NormalTok{) }\CommentTok{\# history industry means}
\NormalTok{    alpha\_industry }\OperatorTok{=}\NormalTok{ pm.Normal(}\StringTok{"alpha\_industry"}\NormalTok{, }
\NormalTok{                                mu}\OperatorTok{=}\NormalTok{mu\_alpha\_industry, }\CommentTok{\# historical industry means}
\NormalTok{                                sigma}\OperatorTok{=}\NormalTok{sigma,}
\NormalTok{                                dims}\OperatorTok{=}\StringTok{"industry"}\NormalTok{)}
    \CommentTok{\# Probability of unemployment of each industry determined by alpha\_industry}
\NormalTok{    p\_unemployment }\OperatorTok{=}\NormalTok{ pm.Deterministic(}\StringTok{"p\_unemployment"}\NormalTok{, pm.invlogit(alpha\_industry[industry\_idx\_obs]))}
    \CommentTok{\# Observed data {-} unemployment status}
\NormalTok{    unemployment\_status\_observed }\OperatorTok{=}\NormalTok{ pm.Bernoulli(}\StringTok{"unemployment\_status"}\NormalTok{, }
\NormalTok{                                            p}\OperatorTok{=}\NormalTok{p\_unemployment, }
\NormalTok{                                            observed}\OperatorTok{=}\NormalTok{survey\_df\_industry[}\StringTok{\textquotesingle{}unemployment\_status\textquotesingle{}}\NormalTok{].values,}
\NormalTok{                                            dims}\OperatorTok{=}\StringTok{"obs\_id"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# 4.Visualize the PGM}
\NormalTok{pm.model\_to\_graphviz(adaptive\_unemployment\_industry\_model)  }
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/index_files/figure-pdf/cell-25-output-1.pdf}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# 5.MCMC sampling and prediction}
\ControlFlowTok{with}\NormalTok{ adaptive\_unemployment\_industry\_model:}
\NormalTok{    ur\_industry\_trace }\OperatorTok{=}\NormalTok{ pm.sample(tune }\OperatorTok{=} \DecValTok{500}\NormalTok{, draws}\OperatorTok{=}\DecValTok{500}\NormalTok{, random\_seed}\OperatorTok{=}\DecValTok{5650}\NormalTok{)}
\CommentTok{\# Pring summary of the trace}
\NormalTok{trace\_alpha\_summary }\OperatorTok{=}\NormalTok{ az.summary(}
\NormalTok{    ur\_industry\_trace,}
\NormalTok{    var\_names}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}alpha\_industry\textquotesingle{}}\NormalTok{],}
\NormalTok{    kind}\OperatorTok{=}\StringTok{"stats"}\NormalTok{, }
\NormalTok{    round\_to}\OperatorTok{=}\DecValTok{2}
\NormalTok{)}
\NormalTok{trace\_alpha\_summary[}\StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{trace\_alpha\_summary[}\StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{])) }\CommentTok{\# convert logit to probability}
\NormalTok{trace\_alpha\_summary[}\StringTok{\textquotesingle{}hdi\_3\%\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{trace\_alpha\_summary[}\StringTok{\textquotesingle{}hdi\_3\%\textquotesingle{}}\NormalTok{])) }\CommentTok{\# convert logit to probability}
\NormalTok{trace\_alpha\_summary[}\StringTok{\textquotesingle{}hdi\_97\%\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{trace\_alpha\_summary[}\StringTok{\textquotesingle{}hdi\_97\%\textquotesingle{}}\NormalTok{])) }\CommentTok{\# convert logit to probability}
\NormalTok{display(trace\_alpha\_summary)}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{verbatim}
Output()
\end{verbatim}

\begin{verbatim}
\end{verbatim}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}lllll@{}}

\caption{\label{tbl-industry-trace-summary}Summary of Posterior
Distributions}

\tabularnewline

\toprule\noalign{}
& mean & sd & hdi\_3\% & hdi\_97\% \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
alpha\_industry{[}Leisure and hospitality{]} & 0.056786 & 0.02 &
0.055201 & 0.058967 \\
alpha\_industry{[}Educational and health services{]} & 0.023661 & 0.02 &
0.022977 & 0.024364 \\
alpha\_industry{[}Wholesale and retail trade{]} & 0.042290 & 0.02 &
0.040699 & 0.043522 \\
alpha\_industry{[}Manufacturing{]} & 0.030769 & 0.02 & 0.029598 &
0.032295 \\
alpha\_industry{[}Financial activities{]} & 0.022977 & 0.03 & 0.021881 &
0.024602 \\
alpha\_industry{[}Professional and business services{]} & 0.038791 &
0.02 & 0.037688 & 0.039925 \\
alpha\_industry{[}Public administration{]} & 0.017810 & 0.04 & 0.016464
& 0.019265 \\
alpha\_industry{[}Transportation and utilities{]} & 0.036969 & 0.03 &
0.035230 & 0.038791 \\
alpha\_industry{[}Information{]} & 0.047426 & 0.04 & 0.043522 &
0.051174 \\

\end{longtable}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

The provided trace summary (Table~\ref{tbl-industry-trace-summary})
details the posterior estimates for the alpha\_industry parameters,
which represent the estimated industry-specific parameters for
unemployment probability. For example, `Leisure and hospitality' has a
mean of 0.056, while `Public administration' has a mean of 0.018. The
sd, hdi\_3\% and hdi\_97\% are consistently quite narrow across all
industries, (e.g., `Leisure and hospitality' from 0.055 to 0.059, a
range of 0.004). This indicates a strong concentration of posterior
probability around the mean estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Posterior mean}
\NormalTok{ur\_industry\_post\_mean }\OperatorTok{=}\NormalTok{ ur\_industry\_trace.posterior.mean(dim}\OperatorTok{=}\NormalTok{(}\StringTok{"chain"}\NormalTok{, }\StringTok{"draw"}\NormalTok{))}
\NormalTok{ur\_industry\_post\_mean\_iter }\OperatorTok{=}\NormalTok{ ur\_industry\_post\_mean.sortby(}\StringTok{"alpha\_industry"}\NormalTok{)}
\NormalTok{ur\_industry\_post\_mean\_iter[}\StringTok{\textquotesingle{}alpha\_prob\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{ur\_industry\_post\_mean\_iter[}\StringTok{\textquotesingle{}alpha\_industry\textquotesingle{}}\NormalTok{]))}
\NormalTok{ur\_industry\_post\_mean.to\_dataframe()}
\NormalTok{ur\_industry\_post\_hdi }\OperatorTok{=}\NormalTok{ az.hdi(ur\_industry\_trace)}
\NormalTok{ur\_industry\_post\_hdi\_iter }\OperatorTok{=}\NormalTok{ ur\_industry\_post\_hdi.sortby(ur\_industry\_post\_mean\_iter.alpha\_industry)}
\NormalTok{ur\_industry\_post\_hdi\_iter[}\StringTok{\textquotesingle{}alpha\_prob\textquotesingle{}}\NormalTok{]}\OperatorTok{=}\DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{ur\_industry\_post\_hdi\_iter[}\StringTok{\textquotesingle{}alpha\_industry\textquotesingle{}}\NormalTok{]))}
\NormalTok{ur\_industry\_post\_hdi\_iter.to\_dataframe()}
\CommentTok{\# Plot the posterior alpha\_industry (mean of unemployment)}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{))}
\NormalTok{ur\_industry\_post\_mean\_iter.plot.scatter(x}\OperatorTok{=}\StringTok{\textquotesingle{}industry\textquotesingle{}}\NormalTok{, y}\OperatorTok{=}\StringTok{"alpha\_prob"}\NormalTok{, ax}\OperatorTok{=}\NormalTok{ax, alpha}\OperatorTok{=}\FloatTok{0.8}\NormalTok{, s}\OperatorTok{=}\DecValTok{80}\NormalTok{)}
\NormalTok{ax.vlines(}
\NormalTok{    np.arange(industry\_names.size),}
\NormalTok{    ur\_industry\_post\_hdi\_iter.alpha\_prob.sel(hdi}\OperatorTok{=}\StringTok{"lower"}\NormalTok{),}
\NormalTok{    ur\_industry\_post\_hdi\_iter.alpha\_prob.sel(hdi}\OperatorTok{=}\StringTok{"higher"}\NormalTok{),}
\NormalTok{    color}\OperatorTok{=}\StringTok{"orange"}\NormalTok{,}
\NormalTok{    alpha}\OperatorTok{=}\FloatTok{0.6}\NormalTok{,}
\NormalTok{    linewidth}\OperatorTok{=}\DecValTok{3}
\NormalTok{)}
\NormalTok{ax.grid(}\VariableTok{True}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.6}\NormalTok{, color}\OperatorTok{=}\StringTok{\textquotesingle{}lightgray\textquotesingle{}}\NormalTok{)     }
\NormalTok{ax.tick\_params(axis}\OperatorTok{=}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{, labelsize}\OperatorTok{=}\DecValTok{10}\NormalTok{, rotation}\OperatorTok{=}\DecValTok{90}\NormalTok{)}
\NormalTok{ax.set\_xlabel(}\StringTok{\textquotesingle{}Industry\textquotesingle{}}\NormalTok{, fontsize }\OperatorTok{=} \DecValTok{12}\NormalTok{)}
\NormalTok{ax.set\_ylabel(}\StringTok{\textquotesingle{}Posterior means\textquotesingle{}}\NormalTok{, fontsize }\OperatorTok{=} \DecValTok{12}\NormalTok{)}
\NormalTok{ax.set\_title(}\StringTok{"Estimated Industry{-}Specific Unemployment Rate (Adaptive Pooling)"}\NormalTok{, y}\OperatorTok{=}\FloatTok{1.02}\NormalTok{, fontsize}\OperatorTok{=}\DecValTok{16}\NormalTok{)}
\NormalTok{plt.tight\_layout() }
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-industry-pgm-scatter-output-1.png}}

}

\caption{\label{fig-industry-pgm-scatter}Estimated Industry-Specific
Unemployment Rate (Adaptive Pooliing)}

\end{figure}%

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

The PGM estimated unemployment rates graphed in
Figure~\ref{fig-industry-pgm-scatter} reveals distinct causal influences
of industry type on unemployment probability. The model infers that the
`Leisure and Hospitality' industry has the highest positive causal
effect on unemployment likelihood. Conversely, `Public Administration'
and `Financial Services' show a negative causal influence, resulting in
lower estimated unemployment rates. The `Information' industry, while
having the second-highest mean unemployment, exhibits the widest
credible interval, indicating greater uncertainty in quantifying its
causal impact on employment stability.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot the trace for Information, Leisure \& Hospitality, Government Administration and Financial services}
\NormalTok{trace\_industries}\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Leisure and hospitality\textquotesingle{}}\NormalTok{,}
              \StringTok{\textquotesingle{}Financial activities\textquotesingle{}}\NormalTok{,}
              \StringTok{\textquotesingle{}Public administration\textquotesingle{}}\NormalTok{,}
              \StringTok{\textquotesingle{}Information\textquotesingle{}}\NormalTok{]}
\CommentTok{\#\# create subset of the trace summary with the selected industries alpha transformed to probabilities}
\NormalTok{alpha\_industry\_subset }\OperatorTok{=} \DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{ur\_industry\_trace.posterior[}\StringTok{\textquotesingle{}alpha\_industry\textquotesingle{}}\NormalTok{].sel(industry}\OperatorTok{=}\NormalTok{trace\_industries)))}
\ImportTok{import}\NormalTok{ xarray }\ImportTok{as}\NormalTok{ xr}
\NormalTok{trace\_for\_plot }\OperatorTok{=}\NormalTok{ az.InferenceData(}
\NormalTok{    posterior}\OperatorTok{=}\NormalTok{xr.Dataset(}
\NormalTok{        data\_vars}\OperatorTok{=}\NormalTok{\{}
            \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{: ur\_industry\_trace.posterior[}\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{],}
            \StringTok{\textquotesingle{}alpha\_industry\textquotesingle{}}\NormalTok{: alpha\_industry\_subset}
\NormalTok{        \}}
\NormalTok{    )}
\NormalTok{)}
\NormalTok{az.plot\_trace(trace\_for\_plot)}
\NormalTok{plt.tight\_layout()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/cell-29-output-1.png}}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\vspace{1em}

\textsubscript{Source:
\href{https://mw1296.github.io/dsan5650_social_causal_inference/index.qmd.html}{Article
Notebook}}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-Joseph2024}
Joseph Dean, E. S. (2024). \href{}{Gender differences in unemployment
trends: Race, jobs and the economy update for february 2024}.
\emph{NCRC}.

\bibitem[\citeproctext]{ref-TOIEducation2025}
TOIEducation. (2025). \href{}{Degrees at risk: 10 US college majors with
the highest unemployment rate in 2025}. \emph{The Times Of India}.

\bibitem[\citeproctext]{ref-Oberlo2024}
\href{}{US UNEMPLOYMENT RATE BY INDUSTRY (2024)}. (2024). \emph{Oberlo}.

\bibitem[\citeproctext]{ref-ValerieWilson2022}
Wilson, V., \& Darity-Jr., W. (2022). \href{}{Understanding black-white
disparities in labor market outcomes requires models that account for
persistent discrimination and unequal bargaining power}. \emph{Economic
Policy Institute}.

\bibitem[\citeproctext]{ref-YiLiChienandPaulMorris}
YiLi Chien, P. M. (2016). \href{}{Unemployment by industry: Duration
must be considered, too}. \emph{Federal Reserve Bank of St.Lois -
Regional Economist}.

\end{CSLReferences}




\end{document}
