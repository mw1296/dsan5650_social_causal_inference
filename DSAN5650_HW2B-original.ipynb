{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cea2f7c-2dc5-43dc-a223-8a3818aaeeb7",
   "metadata": {},
   "source": [
    "## DSAN 5650 HW2B: Multilevel Regression with PyMC (Modeling Languages II)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600fccc-e1b5-4caa-b210-2e2583e47afc",
   "metadata": {},
   "source": [
    "**Assignment Corrections (Run Following Cell to Fetch)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d702141-c3bd-4aed-a3bf-ea6cd397b275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T10:20:19.935663Z",
     "iopub.status.busy": "2025-06-23T10:20:19.935507Z",
     "iopub.status.idle": "2025-06-23T10:20:20.022247Z",
     "shell.execute_reply": "2025-06-23T10:20:20.021802Z",
     "shell.execute_reply.started": "2025-06-23T10:20:19.935648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**DSAN5650 HW2B Corrections**\n",
       "\n",
       "None so far!\n",
       "\n",
       "\n",
       "Last fetched: 2025-06-23 06:20:19 EDT"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import corrections\n",
    "corrections.fetch(\"HW2B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2092dda-fa32-438a-b972-85a71c82e64e",
   "metadata": {},
   "source": [
    "**Assignment Submission Button (Coming Soon...)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0bbb3-8e9e-4892-9dc6-0b5c32b8f04c",
   "metadata": {},
   "source": [
    "## [Part 3] Two-Level (Country-Individual) Multilevel Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af1044-c5f8-4bf7-ba4a-ce96795954dc",
   "metadata": {},
   "source": [
    "This is it, the moment you've all been waiting for! Now that you've gone through the tutorial in Part 1, and the single-level regressions in Part 2, in this part you'll \"weave together\" what you've learned to estimate a **multilevel model** incorporating both **country-level** and **individual-level** information!<sup>[1]</sup>\n",
    "\n",
    "Specifically, like you saw with the **Radon** example we went over in Week 5, our ultimate goal is to be able to **adaptively pool** individual-level information across countries. In other words, we'd like to model the relationship between `antiauth` and `china` for an arbitrarily-chosen individual $i$ within country $j[i]$ as a **country-size-aware balance** between two different \"naÃ¯ve\" estimates of this effect:\n",
    "\n",
    "*   (a) The **full-pooling** estimate of the relationship between `antiauth` (`aa`) and `china` (`ch`) across all individuals in the dataset, **ignoring their countries** of residence (here $\\overline{\\texttt{aa}}$ denotes the overall mean of `antiauth` across all individuals in the dataset):\n",
    "\n",
    "    $$\n",
    "    \\texttt{ch}_i =\n",
    "    \\underbrace{\\alpha}_{\\mathclap{\n",
    "    \\substack{\n",
    "        \\text{Expected }\\texttt{ch}_i \\\\[0.2em]\n",
    "        \\text{ if }\\texttt{aa}_i = \\overline{\\texttt{aa}}\n",
    "    }\n",
    "    }}\n",
    "    +\n",
    "    \\overbrace{\\beta}^{\\mathclap{\n",
    "    \\substack{\n",
    "        \\text{Expected }\\Delta\\texttt{ch}_i\\text{ per } \\\\[0.2em]\n",
    "        \\Delta\\texttt{aa}_i\\text{ away from }\\overline{\\texttt{aa}}\n",
    "    }\n",
    "    }}\n",
    "    \\cdot \\left(\\texttt{aa}_i - \\overline{\\texttt{aa}}\\right)\n",
    "    $$\n",
    "    \n",
    "* (b) The **no-pooling** estimate of the relationship between `antiauth` and `china` among **only** individuals **within this single country $j$**:\n",
    "\n",
    "    $$\n",
    "    \\texttt{ch}_i = \\underbrace{\\alpha_{j[i]}}_{\\mathclap{\n",
    "    \\substack{\n",
    "        \\text{Expected }\\texttt{ch}_i \\\\[0.2em]\n",
    "        \\text{ if }\\texttt{aa}_i = \\overline{\\texttt{aa}}_{j[i]}\n",
    "    }\n",
    "    }}\n",
    "    +\n",
    "    \\overbrace{\\beta_{j[i]}}^{\\mathclap{\n",
    "    \\substack{\n",
    "        \\text{Expected }\\Delta\\texttt{ch}_i\\text{ per } \\\\[0.2em]\n",
    "        \\Delta\\texttt{aa}_i\\text{ away from }\\overline{\\texttt{aa}}_{j[i]}\n",
    "    }\n",
    "    }}\n",
    "    \\cdot (\\texttt{aa}_i - \\overline{aa}_{j[i]})\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "<small>\n",
    "\n",
    "1. Incorporating political party, to form a 3-level model, is a bonus problem you can do if you'd like -- once you understand how to write 2-level models in the **modeling language** used by PyMC, you can easily modify your code to handle 3-level, 4-level, $n$-level models as needed! ðŸ˜‰\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8506af-d7ee-492e-8e4b-bbfb479b3f44",
   "metadata": {},
   "source": [
    "### The Full-Pooling Estimate\n",
    "\n",
    "It turns out that you secretly **already derived an estimate of the full-pooling estimate (a)** -- congratulations! When you converted the `lm()`-based individual-level regression to an `ulam()`-estimated PGM in Part 2, estimating the effect of `antiauth` on `china` without regard for `country_name`, the slope and intercept parameters you learned were precisely the full-pooling estimate! Here, in Part 3.1, we provide the code for the same model re-written in PyMC, so you can see the similarities and differences with how you wrote it for `ulam()` estimation. (Then in Part 3.2, just so you have more than one example to draw from, we also provide re-written PyMC code for the country-level regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17dbe1-06e4-4231-af7d-6f1334fc1be9",
   "metadata": {},
   "source": [
    "### The No-Pooling Estimate\n",
    "\n",
    "Now, to derive the **no-pooling estimate (b)**, where each country $j$ has its own country-specific intercept $\\alpha_j$ and country-specific slope $\\beta_j$, your instinct may be to run and estimate a bunch of individual regressions via `lm()`. But... stop! This is the [Saying *\"Can I have a hamburger?\"* 40 times] model of computational social science, not the learning-a-language model! By learning the language of PyMC, you can intead modify the statement to e.g. *\"Can I have one hamburger per country?\"*, or *\"Can I have one hamburger per political party?\"*, or *\"Can I have one hamburger for high-income individuals and another for low-income individuals?\"*<sup>[1]</sup>\n",
    "\n",
    "In Part 3.3 below, we also provide PyMC code for a no-pooling estimator, with the goal being that you can see the forest for the trees: that you can **combine** the full-pooling PyMC model given in Part 3.1 with the no-pooling PyMC model given in Part 3.3 to derive an adaptive-pooling model in Part 3.4!\n",
    "\n",
    "---\n",
    "\n",
    "<small>\n",
    "\n",
    "1. *...The hamburger is an estimated regression in this terrible metaphor I'm trapped in, folks. Quite a pickle. The bunintended consequence of my cheesy choice of phrase in lecture. But lettuce move on to the next section. Wendy's Baconator*\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b861612-aded-416e-9e6c-76793b67350b",
   "metadata": {},
   "source": [
    "### The Adaptive-Pooling Estimate\n",
    "\n",
    "As shown in class with the Radon example, the **adaptive pooling** approach will strike a balance between No-Pooling and Full-Pooling, by:\n",
    "\n",
    "* Starting with the No-Pooling estimate as a **prior** for a given country $j$, then\n",
    "* Moving towards the Full-Pooling estimate as more and more data is observed for individuals in country $j$\n",
    "\n",
    "This means, in particular, that your model's country-$j$-specific regression line will (by construction) lie somewhere **between** the no-pooling regression line from Part 2 and the regression line you would obtain by throwing away all observations besides those from country $j$. Countries with more observations will have final adaptively-pooled regression lines closer to that country's $j$-only **no-pooling** estimate, while countries with fewer observations will have lines closer to the overall **full-pooling** regression line.\n",
    "\n",
    "With all that said, run the code cells in Parts 3.1 and 3.2 to see how the Stan models you wrote in HW2A can be converted to PyMC, run the code cells in Part 3.3 to see how a PyMC model can be written from scratch for the no-pooling estimate, then write your own implementation of adaptive pooling in Part 3.4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60109a79-af8d-40db-82f3-29a081925f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12717427-e9c7-4176-9cbc-61276bf2c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import arviz as az\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "import pymc as pm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedcdea1-8117-4518-9b9a-849bfa5dd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(\"https://jpj.georgetown.domains/dsan5650-data/ab_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83dd13f-ebab-4485-83c1-df2f0524933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts_dict = valid_df['country_name'].value_counts().to_dict()\n",
    "print(country_counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc71437-d5bc-43ca-8982-bf24b85ef4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_label(country_name):\n",
    "    country_count = country_counts_dict[country_name]\n",
    "    return f'{country_name} (N = {country_count})'\n",
    "valid_df['country_label'] = valid_df['country_name'].apply(attach_label)\n",
    "valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc489d2b-31e8-4581-8413-fd57c56aa715",
   "metadata": {},
   "source": [
    "## [Part 3.1] Individual-Level Regression Redone in PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31856dd5-bebb-4803-b5d2-0ca309bddf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "antiauth_vals = valid_df['antiauth'].values\n",
    "aa_mean = np.mean(antiauth_vals)\n",
    "china_vals = valid_df['china'].values\n",
    "china_mean = np.mean(china_vals)\n",
    "with pm.Model() as indiv_model:\n",
    "    antiauth = pm.Data(\"antiauth\", antiauth_vals, dims=\"obs_id\")\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=5)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=5)\n",
    "    sigma_y = pm.Uniform(\"sigma_y\", 0, 5)\n",
    "\n",
    "    mu_y = alpha + beta * antiauth\n",
    "\n",
    "    china = pm.Normal(\"china\", mu=mu_y, sigma=sigma_y, observed=china_vals, dims=\"obs_id\")\n",
    "pm.model_to_graphviz(indiv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be1fa0-7995-4a75-b8f1-bbf556f3c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with indiv_model:\n",
    "    indiv_trace = pm.sample(random_seed=5650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5145f94-2000-4001-b980-397a04e63303",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(indiv_trace, round_to=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac4d4e-a9d3-47eb-ad5e-4bc81d1ca55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_post_mean = indiv_trace.posterior.mean(dim=(\"chain\", \"draw\"))\n",
    "indiv_post_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8cc1e-2725-44a4-9559-261164822eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals = np.linspace(0, 1, num=20)\n",
    "qtiles = np.quantile(valid_df['antiauth'], q=qvals)\n",
    "ax = sns.regplot(\n",
    "    data=valid_df, x=\"antiauth\", y=\"china\", x_bins=qtiles, truncate=False,\n",
    "    x_ci='ci',\n",
    "    fit_reg=False,\n",
    "    # ci=None, x_ci='ci'\n",
    ");\n",
    "ax.axvline(x=aa_mean, ls=\"dashed\");\n",
    "ax.axhline(y=china_mean, ls=\"dashed\");\n",
    "ax.axline(xy1=(0, indiv_post_mean[\"alpha\"]), slope=indiv_post_mean[\"beta\"]);\n",
    "plt.title(\"PyMC-Estimated Individual-Level Linear Regression\");\n",
    "plt.show()\n",
    "\n",
    "#plt.scatter(valid_df.antiauth, valid_df.china)\n",
    "#xvals = xr.DataArray(np.linspace(-0.2, 1.2))\n",
    "#plt.plot(xvals, post_mean[\"beta\"] * xvals + post_mean[\"alpha\"], \"r--\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110cb11-d21c-499a-849a-8ffaa6645d7e",
   "metadata": {},
   "source": [
    "## [Part 3.2] Country-Level Regression Re-Written in PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2530bb9-35da-4a4a-975a-a373862526ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['ltrade_china'] = valid_df['trade_china'].apply(np.log)\n",
    "\n",
    "ltrade_vals = valid_df['ltrade_china'].values\n",
    "ltrade_mean = np.mean(ltrade_vals)\n",
    "print(ltrade_mean)\n",
    "china_vals = valid_df['china'].values\n",
    "china_mean = np.mean(china_vals)\n",
    "with pm.Model() as country_model:\n",
    "    ltrade = pm.Data(\"ltrade\", ltrade_vals, dims=\"obs_id\")\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=5)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=5)\n",
    "    sigma_y = pm.Uniform(\"sigma_y\", 0, 5)\n",
    "\n",
    "    mu_y = alpha + beta * ltrade\n",
    "\n",
    "    china = pm.Normal(\"china\", mu=mu_y, sigma=sigma_y, observed=china_vals, dims=\"obs_id\")\n",
    "pm.model_to_graphviz(country_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12f261-cd0a-480f-81ba-153ca7176e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with country_model:\n",
    "    country_trace = pm.sample(random_seed=5650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143c192-85b7-4e31-aa01-658a7e4a76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(country_trace, round_to=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6941e2-7303-41ef-ac94-cb79e3a2061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_post_mean = country_trace.posterior.mean(dim=(\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc74f70-11fa-4c12-8c02-84e765a60f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals = np.linspace(0, 1, num=10)\n",
    "qtiles = np.quantile(valid_df['ltrade_china'], q=qvals)\n",
    "ax = sns.regplot(\n",
    "    data=valid_df, x=\"ltrade_china\", y=\"china\", x_bins=qtiles, truncate=False,\n",
    "    x_ci='ci',\n",
    "    fit_reg=False\n",
    "    # ci=None, x_ci='ci'\n",
    ");\n",
    "ax.axvline(x=ltrade_mean, ls=\"dashed\");\n",
    "ax.axhline(y=china_mean, ls=\"dashed\");\n",
    "ax.axline(xy1=(0, country_post_mean[\"alpha\"]), slope=country_post_mean[\"beta\"]);\n",
    "\n",
    "#plt.scatter(valid_df.antiauth, valid_df.china)\n",
    "#xvals = xr.DataArray(np.linspace(-0.2, 1.2))\n",
    "#plt.plot(xvals, post_mean[\"beta\"] * xvals + post_mean[\"alpha\"], \"r--\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d367b4b5-eb97-4a34-96ad-35f7b2dfab4f",
   "metadata": {},
   "source": [
    "## [Part 3.3] The No-Pooling Multilevel Model\n",
    "\n",
    "Recall the difference between the **no-pooling** and **full-pooling** estimates: though we already estimated the **full-pooling** model above (in Part 3.1), here we should write the **no-pooling** model in such a way that we can easily take it and make just a few modifications to arrive at the **adaptive-pooling** model in Part 3.4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d17e3-b46d-4b20-9913-d74c84ae0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_idx, country_names = valid_df['country_name'].factorize()\n",
    "print(country_idx)\n",
    "print(country_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470abd8f-6c06-4c07-b7a5-4ead1d51e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "antiauth_vals = valid_df['antiauth'].values\n",
    "aa_mean = np.mean(antiauth_vals)\n",
    "china_vals = valid_df['china'].values\n",
    "china_mean = np.mean(china_vals)\n",
    "\n",
    "coords = {\"country\": country_names}\n",
    "with pm.Model(coords=coords) as np_model:\n",
    "    antiauth = pm.Data(\"antiauth\", antiauth_vals, dims=\"obs_id\")\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", 0, sigma=10, dims=\"country\")\n",
    "    beta = pm.Normal(\"beta\", 0, sigma=10)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    theta = alpha[country_idx] + beta * antiauth\n",
    "\n",
    "    china = pm.Normal(\"y\", theta, sigma=sigma, observed=china_vals, dims=\"obs_id\")\n",
    "pm.model_to_graphviz(np_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfb8cc-3029-4ae5-a81c-b1270c81953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np_model:\n",
    "    np_trace = pm.sample(random_seed=5650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f45e95-6623-407d-90ae-2ee59af3f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_means = np_trace.posterior.mean(dim=(\"chain\", \"draw\"))\n",
    "np_hdi = az.hdi(np_trace)\n",
    "\n",
    "np_means_iter = np_means.sortby(\"alpha\")\n",
    "np_hdi_iter = np_hdi.sortby(np_means_iter.alpha)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 6.5))\n",
    "xticks = np.arange(0, len(country_names), 1)\n",
    "np_means_iter.plot.scatter(x=\"country\", y=\"alpha\", ax=ax, alpha=0.8)\n",
    "ax.vlines(\n",
    "    np.arange(country_names.size),\n",
    "    np_hdi_iter.alpha.sel(hdi=\"lower\"),\n",
    "    np_hdi_iter.alpha.sel(hdi=\"higher\"),\n",
    "    color=\"orange\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "ax.set(ylabel=\"China sentiment at mean antiauth\", ylim=(2, 5))\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(np_means_iter.country.values[xticks])\n",
    "#ax.tick_params(rotation=45, );\n",
    "plt.setp(ax.get_xticklabels(), rotation=62.5, ha=\"right\", rotation_mode=\"anchor\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9d449-07d1-4082-87e8-e53721b346f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_countries = (\n",
    "    \"Nigeria\",\n",
    "    \"Tanzania\",\n",
    "    \"Tunisia\",\n",
    "    \"Zimbabwe\",\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6), sharey=True, sharex=True)\n",
    "axes = axes.ravel()\n",
    "m = np_means[\"beta\"]\n",
    "for i, c in enumerate(sample_countries):\n",
    "    y = valid_df.china[valid_df.country_name == c]\n",
    "    x = valid_df.antiauth[valid_df.country_name == c]\n",
    "    clabel = valid_df.country_label[valid_df.country_name == c].iloc[0]\n",
    "    # axes[i].scatter(x + np.random.randn(len(x)) * 0.01, y, alpha=0.4)\n",
    "\n",
    "    # No pooling model\n",
    "    b = np_means[\"alpha\"].sel(country=c)\n",
    "\n",
    "    # Plot both models and data\n",
    "    xvals = xr.DataArray(np.linspace(0, 4))\n",
    "    axes[i].plot(xvals, m * xvals + b)\n",
    "    axes[i].plot(xvals, indiv_post_mean[\"beta\"] * xvals + indiv_post_mean[\"alpha\"], \"r--\")\n",
    "    # axes[i].set_xticks([0, 1])\n",
    "    # axes[i].set_xticklabels([\"basement\", \"floor\"])\n",
    "    axes[i].set_ylim(2, 4.5)\n",
    "    axes[i].set_title(clabel)\n",
    "    if not i % 2: axes[i].set_ylabel(\"China sentiment\")\n",
    "    if i >= 2: axes[i].set_xlabel(\"antiauth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b47130-f68c-4cb0-b8fb-d675ccac6fd0",
   "metadata": {},
   "source": [
    "...But wait, what's this?!?\n",
    "\n",
    "<center>\n",
    "<img src=\"https://github.com/jpowerj/dsan-content/blob/main/2025-sum-dsan5650/hw2/AB_Pikachu.png?raw=true\" width=\"40%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0528e-5324-49e8-ac94-382d1b22fce0",
   "metadata": {},
   "source": [
    "A harried Research Assistant rushes into the room and drops a... some sort of physical representation of data onto your desk (idk, a flash drive, or whatever you zoomers use nowadays). The out-of-breath Research Minion (RM), as you call this grotesque yellow creature with overalls and a single goggled eye, carefully avoids direct eye contact but slowly builds up the courage to speak to you.\n",
    "\n",
    "> RM: *\"My liege, my DSAN 5650 Data Analyst, your honor, your majesty, I'm so sorry to bother you, but we just finished collecting data for two new countries in our sample! Just in time for your HW2B Part 3.3!\"*\n",
    ">\n",
    "> You: *\"But... I already started HW2B Part 3.3\"*\n",
    ">\n",
    "> RM: *\"...\"*\n",
    ">\n",
    "> You: *\"...\"*\n",
    ">\n",
    "> RM: *\"That's right, two new countries! One is called **Zudan**, and the other is called **Zudania**, and neither one has anything to do with the strange omission of Sudan from the datset you've been using!\"*\n",
    ">\n",
    "> You: *\"Ok but*\n",
    "\n",
    "Your task now is to **re-estimate** the above model using this new data, which we load for you at the beginning of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b70163-2411-4c6e-996b-32b71dc4645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.3-response\n",
    "new_df = pd.read_csv(\"https://jpj.georgetown.domains/dsan5650-data/ab_zudania.csv\")\n",
    "new_country_counts_dict = new_df['country_name'].value_counts().to_dict()\n",
    "def attach_new_label(country_name):\n",
    "    country_count = new_country_counts_dict[country_name]\n",
    "    return f'{country_name} (N = {country_count})'\n",
    "new_df['country_label'] = new_df['country_name'].apply(attach_new_label)\n",
    "new_country_idx, new_country_names = new_df['country_name'].factorize()\n",
    "print(new_country_idx)\n",
    "print(new_country_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4ba56-3f76-40e4-a1f1-c13c25880dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_antiauth_vals = new_df['antiauth'].values\n",
    "new_aa_mean = np.mean(new_antiauth_vals)\n",
    "new_china_vals = new_df['china'].values\n",
    "new_china_mean = np.mean(new_china_vals)\n",
    "\n",
    "with pm.Model() as new_indiv_model:\n",
    "    antiauth = pm.Data(\"antiauth\", new_antiauth_vals, dims=\"obs_id\")\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", mu=3, sigma=3)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=5)\n",
    "    sigma_y = pm.Uniform(\"sigma_y\", 0, 5)\n",
    "\n",
    "    mu_y = alpha + beta * (antiauth - new_aa_mean)\n",
    "\n",
    "    china = pm.Normal(\"china\", mu=mu_y, sigma=sigma_y, observed=new_china_vals, dims=\"obs_id\")\n",
    "pm.model_to_graphviz(new_indiv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d743e9-cecb-454a-ab74-74a4aa06105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_indiv_model:\n",
    "    new_indiv_trace = pm.sample(random_seed=5650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1724f-be64-4d1b-aa73-d0078dfdf864",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_indiv_post_mean = new_indiv_trace.posterior.mean(dim=(\"chain\", \"draw\"))\n",
    "new_indiv_post_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f43da4-c6d0-48aa-bf44-40c337e974ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"country\": new_country_names}\n",
    "with pm.Model(coords=coords) as new_np_model:\n",
    "    antiauth = pm.Data(\"antiauth\", new_antiauth_vals, dims=\"obs_id\")\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", 0, sigma=10, dims=\"country\")\n",
    "    beta = pm.Normal(\"beta\", 0, sigma=10)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    theta = alpha[new_country_idx] + beta * antiauth\n",
    "\n",
    "    china = pm.Normal(\"y\", theta, sigma=sigma, observed=new_china_vals, dims=\"obs_id\")\n",
    "pm.model_to_graphviz(new_np_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79623337-75f9-439a-b521-47cc51f25996",
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_np_model:\n",
    "    new_np_trace = pm.sample(random_seed=5650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60011047-64ee-4b15-afb5-17fddbb70eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_np_post_means = new_np_trace.posterior.mean(dim=(\"chain\", \"draw\"))\n",
    "new_np_hdi = az.hdi(new_np_trace)\n",
    "\n",
    "new_np_post_means_iter = new_np_post_means.sortby(\"alpha\")\n",
    "new_np_hdi_iter = new_np_hdi.sortby(new_np_post_means_iter.alpha)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 6.5))\n",
    "xticks = np.arange(0, len(new_country_names), 1)\n",
    "new_np_post_means_iter.plot.scatter(x=\"country\", y=\"alpha\", ax=ax, alpha=0.8)\n",
    "ax.vlines(\n",
    "    np.arange(new_country_names.size),\n",
    "    new_np_hdi_iter.alpha.sel(hdi=\"lower\"),\n",
    "    new_np_hdi_iter.alpha.sel(hdi=\"higher\"),\n",
    "    color=\"orange\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "ax.set(ylabel=\"China sentiment at mean antiauth\", ylim=(1, 5))\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(new_np_post_means_iter.country.values[xticks])\n",
    "#ax.tick_params(rotation=45, );\n",
    "plt.setp(ax.get_xticklabels(), rotation=62.5, ha=\"right\", rotation_mode=\"anchor\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0512ab-0c16-46e1-a83e-039d2d9a414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_countries = (\n",
    "    \"Nigeria\",\n",
    "    \"Tanzania\",\n",
    "    \"Tunisia\",\n",
    "    \"Zimbabwe\",\n",
    "    \"Zudan\",\n",
    "    \"Zudania\",\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6), sharey=True, sharex=True)\n",
    "axes = axes.ravel()\n",
    "m = new_np_post_means[\"beta\"]\n",
    "for i, c in enumerate(new_sample_countries):\n",
    "    y = new_df.china[new_df.country_name == c]\n",
    "    x = new_df.antiauth[new_df.country_name == c]\n",
    "    clabel = new_df.country_label[new_df.country_name == c].iloc[0]\n",
    "    # axes[i].scatter(x + np.random.randn(len(x)) * 0.01, y, alpha=0.4)\n",
    "\n",
    "    # No pooling model\n",
    "    b = new_np_post_means[\"alpha\"].sel(country=c)\n",
    "\n",
    "    # Plot both models and data\n",
    "    xvals = xr.DataArray(np.linspace(0, 4))\n",
    "    axes[i].plot(xvals, m * xvals + b)\n",
    "    axes[i].plot(xvals, new_indiv_post_mean[\"beta\"] * xvals + new_indiv_post_mean[\"alpha\"], \"k--\")\n",
    "    # axes[i].set_xticks([0, 1])\n",
    "    # axes[i].set_xticklabels([\"basement\", \"floor\"])\n",
    "    axes[i].set_ylim(1, 4.5)\n",
    "    axes[i].set_title(clabel)\n",
    "    if not i % 3: axes[i].set_ylabel(\"China sentiment\")\n",
    "    if i >= 3: axes[i].set_xlabel(\"antiauth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1756411-42b7-4f11-8ff7-9c3bdd9c5451",
   "metadata": {},
   "source": [
    "## [Part 3.4] Multilevel Model with Adaptive Pooling\n",
    "\n",
    "Now's your time to shine! Complete the adaptive-pooling model started for you in the following code cell. If the model is written out without any syntax errors, the `pm.model_to_graphviz()` call at the end will display your model in PGM form, so you can check that it matches what you're expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8770a-fb1d-4589-a358-f713cd2d8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.4a-response\n",
    "with pm.Model(coords=coords) as adaptive_model:\n",
    "    antiauth = pm.Data(\"antiauth\", new_antiauth_vals, dims=\"obs_id\")\n",
    "    country_idx = pm.Data(\"country_idx\", new_country_idx, dims=\"obs_id\")\n",
    "\n",
    "    # Your code here: priors for country-by-country intercepts\n",
    "    mu_a = None # Replace with prior distribution for mean of intercept\n",
    "    sigma_a = None # Replace with prior distribution for sd of intercept\n",
    "\n",
    "    # Your code here: country-specific intercepts\n",
    "    alpha = None # Replace with draw from distribution\n",
    "    \n",
    "    # Your code here: one common slope across countries\n",
    "    beta = None # Replace with draw from distribution\n",
    "\n",
    "    # Prior for the range of y values around mu_y\n",
    "    sd_y = None # Replace with prior distribution for sd of y\n",
    "\n",
    "    # Your code here: compute mu_y, the center of the distribution from which\n",
    "    # the ultimate Y value will be drawn in the last line of the model below\n",
    "    mu_y = None # Replace with (deterministic) computation of mu_y\n",
    "\n",
    "    # The final distribution of the dependent variable Y = china\n",
    "    china = pm.Normal(\"china\", mu=y_hat, sigma=sd_y, observed=new_china_vals, dims=\"obs_id\")\n",
    "pm.model_to_graphviz(adaptive_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6693f-f238-4f5a-b649-817175f321d3",
   "metadata": {},
   "source": [
    "Once your model is set up correctly, run the following code cell to estimate the model's parameters via the MCMC algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d761e4d-5726-4e4f-82a7-b0c21dcf4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Q3.4b-response\n",
    "with adaptive_model:\n",
    "    adaptive_trace = pm.sample(random_seed=5650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0767a2-b953-486a-9207-32ad3022e14b",
   "metadata": {},
   "source": [
    "This is the final step! If your model in the cell titled `Q3.4a-response` is correct, the following code will plot the **no-pooling**, **full-pooling**, and **adaptive-pooling** estimates of the relationship between `antiauth` and `china` for each of our six \"puzzle countries\"!\n",
    "\n",
    "For sanity purposes, the following image is a screenshot from my implementation -- yours should look roughly similar, though it doesn't need to be identical (since \"stricter\" prior choices for $\\sigma_\\alpha$ will \"pull\" the adaptive estimate closer to the full-pooling line, while less-strict choices will pull it closer to the no-pooling line, and the choice is up to you!)\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "<img src=\"https://github.com/jpowerj/dsan-content/blob/main/2025-sum-dsan5650/hw2/adaptive.png?raw=true\" width=\"80%\"></img>\n",
    "<figcaption><i>The general form of the result you should get from running the following code cell -- the adaptive estimate for Zudan should be somewhere right in between the no-pooling and full-pooling lines, whereas the adaptive estimate for Zudania should be almost indistinguishable from its no-pooling estimate!</i></figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4a131-5c83-46e6-bea9-626de28c20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6), sharey=True, sharex=True)\n",
    "axes = axes.ravel()\n",
    "m = new_np_post_means[\"beta\"]\n",
    "for i, c in enumerate(new_sample_countries):\n",
    "    y = new_df.china[new_df.country_name == c]\n",
    "    x = new_df.antiauth[new_df.country_name == c]\n",
    "    clabel = new_df.country_label[new_df.country_name == c].iloc[0]\n",
    "    # axes[i].scatter(x + np.random.randn(len(x)) * 0.01, y, alpha=0.4)\n",
    "\n",
    "    # No pooling model\n",
    "    b = new_np_post_means[\"alpha\"].sel(country=c)\n",
    "\n",
    "    # Plot both models and data\n",
    "    xvals = xr.DataArray(np.linspace(1, 4))\n",
    "    axes[i].plot(xvals, m.values * xvals + b.values)\n",
    "    axes[i].plot(xvals, new_indiv_post_mean[\"beta\"] * xvals + new_indiv_post_mean[\"alpha\"], \"r--\")\n",
    "\n",
    "    # varying_intercept_trace.posterior.sel(country=c).beta\n",
    "    adaptive_post = adaptive_trace.posterior.sel(country=c).mean(dim=(\"chain\", \"draw\"))\n",
    "    theta = adaptive_post.alpha.values + adaptive_post.beta.values * xvals\n",
    "    axes[i].plot(xvals, theta, \"k:\")\n",
    "    #axes[i].set_xticks([0, 1])\n",
    "    #axes[i].set_xticklabels([\"basement\", \"floor\"])\n",
    "    axes[i].set_ylim(1, 5)\n",
    "    axes[i].set_title(clabel)\n",
    "    axes[i].legend(['None','Full','Adaptive'], prop={'size': 11})\n",
    "    if not i % 3: axes[i].set_ylabel(\"China sentiment\")\n",
    "    if i >= 3: axes[i].set_xlabel(\"antiauth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c51ee5-8e4a-4b5a-9972-4a4cf2e07d18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56c544-f7b8-434a-8403-27abd261acde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29804c8-e226-46b0-81b2-ee9facc607cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
